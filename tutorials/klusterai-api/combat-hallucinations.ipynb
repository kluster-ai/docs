{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "76f1454d",
      "metadata": {},
      "source": [
        "# Combat Hallucinations with **kluster Verify**\n",
        "\n",
        "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/kluster-ai/klusterai-cookbook/blob/main/examples/verify-api.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "581c9428",
      "metadata": {},
      "source": [
        "Large language models occasionally invent facts (â€œhallucinationsâ€). **[kluster Verify](https://docs.kluster.ai/get-started/verify/reliability/overview/)** is a dropâ€‘in factâ€‘checker that scores any LLM response for reliabilityâ€”either with one click inside the kluster Playground or via a simple API call.\n",
        "\n",
        "This notebook shows you how to:\n",
        "1. Trigger a oneâ€‘click verification in the Playground (no code).\n",
        "2. Call the `POST /v1/verify/reliability` endpoint to factâ€‘check model output programmatically.\n",
        "3. Interpret the JSON response returned by kluster Verify.\n",
        "4. Apply bestâ€‘practice guardâ€‘rails in your own applications.\n",
        "\n",
        "> **Note**Â â€“ We use *mistralâ€‘smallâ€‘2506* as the demo model. Performance varies by model and prompt, so feel free to experiment."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "08080c97",
      "metadata": {},
      "source": [
        "## How kluster Verify Works Under the Hood\n",
        "\n",
        "1. **Inputs** â€“ You send at least two fields:\n",
        "   * `prompt`: the original user request.\n",
        "   * `output`: the LLMâ€™s answer you want to check.\n",
        "   * *(Optional)* `context`: a set of groundâ€‘truth docs (URLs, text, PDFs, etc.). When provided, Verify **only** looks inside this sandbox.\n",
        "2. **Retrieval & Evidence Gathering** â€“ If `context` is omitted, Verify performs realâ€‘time web search and retrieval, pulling the top public sources most likely to contain evidence.\n",
        "3. **Crossâ€‘Examination** â€“ Verify compares factual claims in `output` against the gathered evidence using an ensemble of retrievalâ€‘augmented reasoning models.\n",
        "4. **Scoring** â€“ It returns:\n",
        "   * `is_hallucination` â€“ Boolean verdict.\n",
        "   * `explanation` â€“ Naturalâ€‘language rationale.\n",
        "   * `search_results` â€“ List of URLs & snippets (if `return_search_results=true`).\n",
        "\n",
        "This pipeline adds **~1â€“2â€¯sec** latency for short answers and gives you structured evidence for audit and debugging."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "234a82cf",
      "metadata": {},
      "source": [
        "## Prerequisites\n",
        "\n",
        "- a **kluster.ai account** â€“ sign up at <https://platform.kluster.ai/signup>\n",
        "- a **kluster.ai api key** â€“ create one in **apiÂ keys** (<https://platform.kluster.ai/apikeys>)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3966a385",
      "metadata": {},
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "546df0e5",
      "metadata": {},
      "source": [
        "Install required libraries. The kluster API is OpenAIâ€‘compatible, so we reuse the `openai` Python client. Weâ€™ll also need `requests`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f6cf346",
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install -q openai requests tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c217bb35",
      "metadata": {},
      "source": [
        "Enter your kluster API key securely:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "92d1a4ae",
      "metadata": {},
      "outputs": [],
      "source": [
        "from getpass import getpass\n",
        "api_key = getpass(\"ğŸ”‘ enter kluster api key: \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "39b2411e",
      "metadata": {},
      "outputs": [],
      "source": [
        "import requests, json, textwrap"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "735b0a9e",
      "metadata": {},
      "source": [
        "## ExampleÂ 1 â€“ ArtemisÂ IV Lunar Base (future event)\n",
        "\n",
        "The *ArtemisÂ IV* mission is real but **has not launched yet** (scheduled no earlier thanÂ 2028). Asking for an â€œofficial NASA mission logâ€ dated **14Â MayÂ 2025** nudges the model to invent a detailed account, because no such log exists. This makes it an excellent stressâ€‘test for hallucination detection."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c06cff7c",
      "metadata": {},
      "outputs": [],
      "source": [
        "prompt_1 = \"Summarize the official NASA mission log for the Artemis IV lunar-base construction flight that successfully landed a four-person crew at Shackleton Crater on May 14 2025. List the crew, the main engineering milestones, and cite any new scientific instruments deployed.\"\n",
        "\n",
        "# â†˜ï¸ generate an answer with your llm of choice (here we paste a fabricated reply):\n",
        "hallucinated_answer_1 = \"\"\"\\\n",
        "Commander Alex Reyes led the Artemis IV crewâ€”Mission Specialist Liu Wen, Pilot Maya Hernandez, and Engineer Luca Rossiâ€”onto the Shackleton Rim at 18:37Â UTC, 14Â MayÂ 2025. ... (fabricated details) ...\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ed23d2ae",
      "metadata": {},
      "source": [
        "### Verify via API\n",
        "\n",
        "In the next cell we pass the prompt and model output to the Kluster Verify API, along with a flag requesting the search results it used. Kluster Verify then returns a verdict, a short explanation, and the supporting sources."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b02d137e",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "url = \"https://api.kluster.ai/v1/verify/reliability\"\n",
        "headers = {\"Authorization\": f\"Bearer {api_key}\", \"Content-Type\": \"application/json\"}\n",
        "\n",
        "payload_1 = {\n",
        "    \"prompt\": prompt_1,\n",
        "    \"output\": hallucinated_answer_1,\n",
        "    \"return_search_results\": True\n",
        "}\n",
        "\n",
        "print(\"ğŸ“¤ verifying â€¦\")\n",
        "resp = requests.post(url, headers=headers, json=payload_1, timeout=15)\n",
        "resp.raise_for_status()\n",
        "result_1 = resp.json()\n",
        "print(json.dumps(result_1, indent=2))\n",
        "\n",
        "if result_1.get(\"is_hallucination\"):\n",
        "    print(\"\\nğŸš¨ hallucination detected\")\n",
        "else:\n",
        "    print(\"\\nâœ… no hallucination\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1ac9c678",
      "metadata": {},
      "source": [
        "## ExampleÂ 2 â€“ The Fictional *Tokyo Green Pact*\n",
        "\n",
        "There is no treaty called the **Tokyo Green Pact** signed by the G20. By requesting its binding provisions and penalties, we again corner the model into making things up, which kluster Verify should flag."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2b457095",
      "metadata": {},
      "outputs": [],
      "source": [
        "prompt_2 = \"Outline the three binding provisions of the Tokyo Green Pact, signed by all G20 nations on 8 August 2024. Summarize penalties for non-compliance.\"\n",
        "hallucinated_answer_2 = \"The Tokyo Green Pact contains three core provisions:\\n1. Net\\u2011negative emissions across the G20 by 2035, enforced by yearly audits.\\n2. A $100/t carbon\\u2011border tax on non\\u2011compliant imports, adjudicated by the Kyoto Enforcement Court.\\n3. A multilateral green\\u2011bond fund financed with 0.5\\u202f% of each nation\\u2019s GDP.\\nNon\\u2011compliance triggers escalating tariffs and suspension of IMF voting rights.\\n\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "473a5381",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "payload_2 = {\n",
        "    \"prompt\": prompt_2,\n",
        "    \"output\": hallucinated_answer_2,\n",
        "    \"return_search_results\": True\n",
        "}\n",
        "print(\"ğŸ“¤ verifying second example â€¦\")\n",
        "result_2 = requests.post(url, headers=headers, json=payload_2, timeout=15).json()\n",
        "print(json.dumps(result_2, indent=2))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cb553dae",
      "metadata": {},
      "source": [
        "## Interpreting the Response\n",
        "\n",
        "| Field | Meaning |\n",
        "|-------|---------|\n",
        "| `is_hallucination` | Boolean verdict |\n",
        "| `explanation` | Plainâ€‘language rationale |\n",
        "| `search_results` | Evidence consulted (if requested) |"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8d400fb4",
      "metadata": {},
      "source": [
        "## Best Practices\n",
        "1. **Autoâ€‘verify short answers** â€“ the[kluster Playground] has an auto-verify feature that you can enable with one click\n",
        "2. **Block, regenerate, or escalate** whenever `is_hallucinationÂ ==Â true`.\n",
        "3. **Constrain with `context`** when you have trusted documents; Verify then ignores the wider web.\n",
        "4. **Log evidence** â€“ keep `search_results` so reviewers can audit decisions.\n",
        "5. **Experiment** â€“ Different LLMs hallucinate differently. Try other models (e.g., Gemma, LlamaÂ 3) and prompts to see how Verify responds."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "35c512a2",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "Whether you prefer the Playgroundâ€™s one-click Verify button or the /v1/verify/reliability API, you now have a turnkey way to validate any LLM response. Because kluster Verify pairs its verdict with an evidence-backed score and live source links, you can log proof, set automated â€œregenâ€ or escalation thresholds, and keep hallucinations from ever reaching production users."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
