{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f08513ae-21ba-4e77-9bad-2bc5c51f4d68",
   "metadata": {},
   "source": [
    "# Getting started with the kluster.ai API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9d0174-a10b-4eb0-a811-dd11deba2f6d",
   "metadata": {},
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/kluster-ai/klusterai-cookbook/blob/main/examples/getting-started.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2c4269-59e8-456c-8939-35cf0bdda3c9",
   "metadata": {},
   "source": [
    "Welcome to the kluster.ai getting started notebook!\n",
    "\n",
    "<a href=\"https://kluster.ai/\" target=\"_blank\">kluster.ai</a> is a high-performance platform designed to make large-scale AI workloads accessible, efficient, and affordable. Our Batch API is an asynchronous service with higher rate limits, predictable turnaround times, and unmatched value. It enables a variety of use cases such as summarization, classification, translation, and much more, all without the need to manage infrastructure. \n",
    "\n",
    "This notebook is designed to help you get started quickly. It walks you through the essential code snippets from the <a href=\"https://docs.kluster.ai/get-started/api/\" target=\"_blank\">Getting started guide</a>, all in one place.\n",
    "\n",
    "By running this notebook, you’ll:\n",
    "- Learn how to use the API.\n",
    "- Submit a simple batch request using our open source LLMs.\n",
    "- Understand how to handle and interpret the API’s responses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9adbe5d",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43e4c18",
   "metadata": {},
   "source": [
    "This step ensures that the openai Python library is installed or updated to the required version. This library will serve as the client for interacting with the kluster.ai API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f85f2a-4ffc-4180-b439-906493833a2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -q \"openai>=1.0.0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b089f9c-e3fd-4411-966e-fabe5d392e4c",
   "metadata": {},
   "source": [
    "## Creating inference jobs as JSONL files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291a9b10",
   "metadata": {},
   "source": [
    "This step defines a collection of requests for the API to process. Each request includes a unique identifier (`custom_id`), the HTTP method (`POST`), the chat completions endpoint (`/v1/chat/completions`) and a body field that contains the request you want to send to the chat completions endpoint toghether with the `model` to be used and the conversational context (\"messages\"). These tasks are saved as a JSON Lines (`.jsonl`) file for efficient handling of multiple requests in a single upload.\n",
    "\n",
    "You'll have to enter your personal kluster.ai API key (make sure it has no blank spaces). Remember to create a key in <a href=\"https://platform.kluster.ai/apikeys\" target=\"_blank\">platform.kluster.ai</a>, if you don't have one yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebb21d1-df49-4784-a5de-f1a7367dd481",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import json\n",
    "client = OpenAI(\n",
    "    base_url=\"https://api.kluster.ai/v1\",  \n",
    "    api_key=\"INSERT_API_KEY\", # Replace with your actual API key\n",
    ")\n",
    "\n",
    "tasks = [{\n",
    "        \"custom_id\": \"request-1\",\n",
    "        \"method\": \"POST\",\n",
    "        \"url\": \"/v1/chat/completions\",\n",
    "        \"body\": {\n",
    "            \"model\": \"klusterai/Meta-Llama-3.1-8B-Instruct-Turbo\",\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "                {\"role\": \"user\", \"content\": \"What is the capital of Argentina?\"},\n",
    "            ],\n",
    "            \"max_tokens\": 1000,\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"custom_id\": \"request-2\",\n",
    "        \"method\": \"POST\",\n",
    "        \"url\": \"/v1/chat/completions\",\n",
    "        \"body\": {\n",
    "            \"model\": \"klusterai/Meta-Llama-3.1-70B-Instruct-Turbo\",\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": \"You are a maths tutor.\"},\n",
    "                {\"role\": \"user\", \"content\": \"Explain the Pythagorean theorem.\"},\n",
    "            ],\n",
    "            \"max_tokens\": 1000,\n",
    "        },\n",
    "    }\n",
    "    # Additional tasks can be added here\n",
    "]\n",
    "\n",
    "# Save tasks to a JSONL file (newline-delimited JSON)\n",
    "file_name = \"my_inference_test.jsonl\"\n",
    "with open(file_name, \"w\") as file:\n",
    "    for task in tasks:\n",
    "        file.write(json.dumps(task) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ceb6a52-2cef-45ae-8e3e-fe31491c4ca2",
   "metadata": {},
   "source": [
    "## Uploading Batch inference job files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1518be55",
   "metadata": {},
   "source": [
    "This step uploads the input JSONL file to kluster.ai via the API. Once the file is uploaded, the API assigns a unique file ID. This ID is essential for subsequent steps, as it allows you to specify which file the batch job should use for processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6a7dd436-f8e2-4a93-ba22-fddbdc0b4aed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '67533eff1d7be1b5a7507b75',\n",
       " 'bytes': 602,\n",
       " 'created_at': 1733508863,\n",
       " 'filename': '6750b85c7da9ad513c97bea1/02d026ed-0742-46a8-9ff9-8fdaa5ea768f-4e3e0531-deab-4489-8da1-5df2466bd176',\n",
       " 'object': 'file',\n",
       " 'purpose': 'batch'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference_input_file = client.files.create(\n",
    "    file=open(file_name, \"rb\"),\n",
    "    purpose=\"batch\"\n",
    ")\n",
    "\n",
    "inference_input_file.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1d0e43-f222-4024-ba6a-8564d2aca71f",
   "metadata": {},
   "source": [
    "## Submit your Batch job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e53475",
   "metadata": {},
   "source": [
    "This step starts your job by providing the uploaded file ID and setting the endpoint and completion window, initiating the batch inference process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4537dd26-2058-415f-8b0c-cab75604e455",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '67533f6d1d7be1b5a7507be5',\n",
       " 'completion_window': '24h',\n",
       " 'created_at': 1733508973,\n",
       " 'endpoint': '/v1/chat/completions',\n",
       " 'input_file_id': '67533eff1d7be1b5a7507b75',\n",
       " 'object': 'batch',\n",
       " 'status': 'pre_schedule',\n",
       " 'completed_at': None,\n",
       " 'errors': [],\n",
       " 'expires_at': 1733595373,\n",
       " 'failed_at': None,\n",
       " 'finalizing_at': None,\n",
       " 'in_progress_at': None,\n",
       " 'metadata': None,\n",
       " 'request_counts': {'completed': 0, 'failed': 0, 'total': 0}}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference_request = client.batches.create(\n",
    "    input_file_id=inference_input_file.id,\n",
    "    endpoint=\"/v1/chat/completions\",\n",
    "    completion_window=\"24h\",\n",
    ")\n",
    "\n",
    "inference_request.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feca0141-731a-4751-8418-77dff33adadf",
   "metadata": {},
   "source": [
    "## Monitor job progress"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01ed74c",
   "metadata": {},
   "source": [
    "In this step, the job status is checked repeatedly to track its progress. You’ll see updates on the overall status and the number of completed tasks until the job is finished, failed, or cancelled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3c15527d-5bf0-48c8-b31c-53d19934e0ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job status: in_progress\n",
      "Completed tasks: 1 / 2\n",
      "Job status: in_progress\n",
      "Completed tasks: 1 / 2\n",
      "Job status: in_progress\n",
      "Completed tasks: 1 / 2\n",
      "Job status: completed\n",
      "Completed tasks: 2 / 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id': '67533f6d1d7be1b5a7507be5',\n",
       " 'completion_window': '24h',\n",
       " 'created_at': 1733508973,\n",
       " 'endpoint': '/v1/chat/completions',\n",
       " 'input_file_id': '67533eff1d7be1b5a7507b75',\n",
       " 'object': 'batch',\n",
       " 'status': 'completed',\n",
       " 'completed_at': 1733509004,\n",
       " 'errors': [],\n",
       " 'expires_at': 1733595373,\n",
       " 'failed_at': None,\n",
       " 'finalizing_at': 1733509004,\n",
       " 'in_progress_at': 1733508973,\n",
       " 'metadata': None,\n",
       " 'output_file_id': '67533f8c2ab49d0df6b4a583',\n",
       " 'request_counts': {'completed': 2, 'failed': 0, 'total': 2}}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Poll the job's status until it's complete\n",
    "while True:\n",
    "    inference_status = client.batches.retrieve(inference_request.id)\n",
    "    print(\"Job status: {}\".format(inference_status.status))\n",
    "    print(\n",
    "        f\"Completed tasks: {inference_status.request_counts.completed} / {inference_status.request_counts.total}\"\n",
    "    )\n",
    "\n",
    "    if inference_status.status.lower() in [\"completed\", \"failed\", \"cancelled\"]:\n",
    "        break\n",
    "\n",
    "    time.sleep(10)  # Wait for 10 seconds before checking again\n",
    "\n",
    "inference_status.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bfa97a0-03d6-45d7-95f8-947198a0ef8e",
   "metadata": {},
   "source": [
    "## Retrieve results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c734ea16",
   "metadata": {},
   "source": [
    "In this step, the results of the job are retrieved if it completed successfully. The output is downloaded and saved to a local file for you to review. If the job failed, the status will indicate the issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "66542b1d-85aa-4350-9551-bd40db7f56ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to inference_results.jsonl\n"
     ]
    }
   ],
   "source": [
    "# Check if the job completed successfully\n",
    "if inference_status.status.lower() == \"completed\":\n",
    "    # Retrieve the results\n",
    "    result_file_id = inference_status.output_file_id\n",
    "    results = client.files.content(result_file_id).content\n",
    "\n",
    "    # Save results to a file\n",
    "    result_file_name = \"inference_results.jsonl\"\n",
    "    with open(result_file_name, \"wb\") as file:\n",
    "        file.write(results)\n",
    "    print(f\"Results saved to {result_file_name}\")\n",
    "else:\n",
    "    print(f\"Job failed with status: {inference_status.status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73016a7-24af-47e2-aa35-a71f39300a88",
   "metadata": {},
   "source": [
    "## List all Batch jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac081d6e",
   "metadata": {},
   "source": [
    "This step lists the most recent jobs, providing an overview of their statuses and details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1063f7f1-1cc3-4501-8293-9e1962a70e81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': [{'id': '67533f6d1d7be1b5a7507be5',\n",
       "   'completion_window': '24h',\n",
       "   'created_at': 1733508973,\n",
       "   'endpoint': '/v1/chat/completions',\n",
       "   'input_file_id': '67533eff1d7be1b5a7507b75',\n",
       "   'object': 'batch',\n",
       "   'status': 'completed',\n",
       "   'completed_at': 1733509004,\n",
       "   'errors': [],\n",
       "   'expires_at': 1733595373,\n",
       "   'failed_at': None,\n",
       "   'finalizing_at': 1733509004,\n",
       "   'in_progress_at': 1733508973,\n",
       "   'metadata': None,\n",
       "   'output_file_id': '67533f8c2ab49d0df6b4a583',\n",
       "   'request_counts': {'completed': 2, 'failed': 0, 'total': 2}},\n",
       "  {'id': '67533f041d7be1b5a7507b7b',\n",
       "   'completion_window': '24h',\n",
       "   'created_at': 1733508868,\n",
       "   'endpoint': '/v1/chat/completions',\n",
       "   'input_file_id': '67533eff1d7be1b5a7507b75',\n",
       "   'object': 'batch',\n",
       "   'status': 'completed',\n",
       "   'completed_at': 1733508903,\n",
       "   'errors': [],\n",
       "   'expires_at': 1733595268,\n",
       "   'failed_at': None,\n",
       "   'finalizing_at': 1733508903,\n",
       "   'in_progress_at': 1733508868,\n",
       "   'metadata': None,\n",
       "   'output_file_id': '67533f272ab49d0df6b4a561',\n",
       "   'request_counts': {'completed': 2, 'failed': 0, 'total': 2}}],\n",
       " 'object': 'list',\n",
       " 'first_id': '67533f6d1d7be1b5a7507be5',\n",
       " 'last_id': '67533f041d7be1b5a7507b7b',\n",
       " 'has_more': True}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.batches.list(limit=2).to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f9f1db-c226-4529-850b-f07fb4f6d695",
   "metadata": {},
   "source": [
    "## Cancelling a Batch job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a61d05d",
   "metadata": {},
   "source": [
    "To cancel a job that is currently in progress, invoke the cancel endpoint by providing the request ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ba4b1a-f527-4adc-a20d-d94afacf52fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.batches.cancel(inference_request.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8926edc8-b270-4f69-94f6-7745b5606080",
   "metadata": {},
   "source": [
    "## List supported models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149225c5",
   "metadata": {},
   "source": [
    "Find the right model for your job by first checking the list models endpoint. Choose from our range of models, optimized for different performance needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5be116c1-677d-4f3a-be86-c4b76f1284dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': [{'id': 'klusterai/Meta-Llama-3.1-405B-Instruct-Turbo',\n",
       "   'created': 1731336418,\n",
       "   'object': 'model',\n",
       "   'owned_by': 'klusterai'},\n",
       "  {'id': 'klusterai/Meta-Llama-3.1-70B-Instruct-Turbo',\n",
       "   'created': 1731336610,\n",
       "   'object': 'model',\n",
       "   'owned_by': 'klusterai'},\n",
       "  {'id': 'klusterai/Meta-Llama-3.1-8B-Instruct-Turbo',\n",
       "   'created': 1731336610,\n",
       "   'object': 'model',\n",
       "   'owned_by': 'klusterai'}],\n",
       " 'object': 'list'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.models.list().to_dict()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
