{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be189fde-4e5b-4f80-bae1-ded86a5075a7",
   "metadata": {
    "id": "be189fde-4e5b-4f80-bae1-ded86a5075a7"
   },
   "source": [
    "# Image analysis with kluster.ai API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17a77d9",
   "metadata": {},
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/kluster-ai/klusterai-cookbook/blob/main/examples/sentiment-analysis-api.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1d06ea-79c1-4f28-b312-0e5aabe18ff3",
   "metadata": {
    "id": "6d1d06ea-79c1-4f28-b312-0e5aabe18ff3"
   },
   "source": [
    "AI models can be used to perform image analysis tasks, in which you feed the model an image and request it to extract meaningful information.\n",
    "\n",
    "This tutorial runs through a notebook where you'll learn how to use the <a href=\"https://kluster.ai/\" target=\"_blank\">kluster.ai</a> batch API to run image analysis on different images using both Gemma 3 27B and Qwen 2.5 7B.\n",
    "\n",
    "The example uses three separate images. For each image, we will ask the models to fetch a specific feature, and compare how they respond:\n",
    "\n",
    "1. A <a href=\"https://github.com/kluster-ai/docs/blob/main/images/tutorials/balls-image.jpg?raw=true\" target=\"_blank\">Newtown's cradle</a>, we will ask what is the device's name and how many balls are in the image (5)\n",
    "2. <a href=\"https://github.com/kluster-ai/docs/blob/main/images/tutorials/eggs-image.jpg?raw=true\" target=\"_blank\">Eggs</a> of different colors, we will ask how many total eggs and per color (10 total, 8 brown and 2 white)\n",
    "3. <a href=\"https://github.com/kluster-ai/docs/blob/main/images/tutorials/music-image.jpeg?raw=true\" target=\"_blank\">Hand written musical note</a>, we will ask what is the sequence of notes (C, D, E and F)\n",
    "\n",
    "You can adapt this example by using your own images or request. With this approach, you can effortlessly process images of any scale, big or small, and obtain image analysis powered by a state-of-the-art language model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ea62a1",
   "metadata": {},
   "source": [
    "## Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83111fd4",
   "metadata": {},
   "source": [
    "Before getting started, ensure you have the following:\n",
    "\n",
    "- **A kluster.ai account** - sign up on the <a href=\"https://platform.kluster.ai/signup\" target=\"_blank\">kluster.ai platform</a> if you don't have one\n",
    "- **A kluster.ai API key** - after signing in, go to the <a href=\"https://platform.kluster.ai/apikeys\" target=\"_blank\">**API Keys**</a> section and create a new key. For detailed instructions, check out the <a href=\"/get-started/get-api-key/\" target=\"_blank\">Get an API key</a> guide"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "xU1WBQJ7Uh09",
   "metadata": {
    "id": "xU1WBQJ7Uh09"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d580f8-67d5-45d6-915f-0f6b60d3b543",
   "metadata": {},
   "source": [
    "In this notebook, we'll use Python's `getpass` module to input the key safely. After execution, please provide your unique kluster.ai API key (ensure no spaces)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bfabc7a8-a552-4569-8a5d-660fbf8df8fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your kluster.ai API key:  ········\n"
     ]
    }
   ],
   "source": [
    "from getpass import getpass\n",
    "\n",
    "api_key = getpass(\"Enter your kluster.ai API key: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974f464e-d106-423a-a10d-88d7d9340e3c",
   "metadata": {},
   "source": [
    "Next, ensure you've installed OpenAI Python library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bcc3d475-8f49-4fc4-9a5e-c6eb6866d2b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -q openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac5381b-7f1e-46be-93e3-d5438dbc8bc3",
   "metadata": {},
   "source": [
    "With the OpenAI Python library installed, we import the necessary dependencies for the tutorial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b89a4feb-37a9-430d-a742-cd58495b4eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "import pandas as pd\n",
    "import time\n",
    "import json\n",
    "import os\n",
    "from IPython.display import clear_output, display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8324323-3273-4204-a1dd-9568ec14591a",
   "metadata": {},
   "source": [
    "And then, initialize the `client` by pointing it to the kluster.ai endpoint, and passing your API key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "zG9y_WO5rYaj",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the client\n",
    "client = OpenAI(\n",
    "    base_url=\"https://api.kluster.ai/v1\",\n",
    "    api_key=api_key,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "udPtLfTaisSw",
   "metadata": {
    "id": "udPtLfTaisSw"
   },
   "source": [
    "## Get the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "QjCVfg65jKz6",
   "metadata": {
    "id": "QjCVfg65jKz6"
   },
   "source": [
    "There are two main ways to proceed when working with images:\n",
    "\n",
    "1. You can provide the the raw image file as a URL from source, for example, GitHub\n",
    "2. You can provide Base64 encoded. These are typically represented with a blob of text, which starts with `data:image/png;base64,ENCODING_DATA_HERE...`\n",
    "\n",
    "With both metholodogies, image data needs to be provided as an object in the content array with the following format:\n",
    "\n",
    "```\n",
    "...\n",
    "{\"type\": \"image_url\", \"image_url\": {\"url\": IMAGE_DATA}}\n",
    "...\n",
    "```\n",
    "\n",
    "Just replace `IMAGE_DATA` with either the URL with the raw image file, or the Base64 encoded image. This tutorial uses the the URL of the images uploaded to GitHub:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07018f92-9a01-47d5-916a-12cd03dfa3a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://github.com/kluster-ai/docs/blob/main/images/tutorials/balls-image.jpg?raw=true\n",
      "https://github.com/kluster-ai/docs/blob/main/images/tutorials/eggs-image.jpg?raw=true\n",
      "https://github.com/kluster-ai/docs/blob/main/images/tutorials/music-image.jpeg?raw=true\n"
     ]
    }
   ],
   "source": [
    "base_url = (\n",
    "    \"https://github.com/kluster-ai/docs/blob/main/images/tutorials/IMAGE_NAME?raw=true\"\n",
    ")\n",
    "\n",
    "# Newton's cradle image\n",
    "# Expected answer: Newton's cradle, 5 balls\n",
    "image1 = \"balls-image.jpg\"\n",
    "image1_url = base_url.replace(\"IMAGE_NAME\", image1)\n",
    "print(image1_url)\n",
    "\n",
    "\n",
    "# Eggs\n",
    "# Expected answer: 10 eggs, 8 brown and 2 white\n",
    "image2 = \"eggs-image.jpg\"\n",
    "image2_url = base_url.replace(\"IMAGE_NAME\", image2)\n",
    "print(image2_url)\n",
    "\n",
    "# Musical note\n",
    "# Expected answer: notes are, in order, C, D, E and F\n",
    "image3 = \"music-image.jpeg\"\n",
    "image3_url = base_url.replace(\"IMAGE_NAME\", image3)\n",
    "print(image3_url)\n",
    "\n",
    "\n",
    "images = [image1, image2, image3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "OyGuHllZllct",
   "metadata": {
    "id": "OyGuHllZllct"
   },
   "source": [
    "## Perform batch inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c345aa-b6a7-4770-8368-b290e9e799dc",
   "metadata": {
    "id": "6-MZlfXAoiNv"
   },
   "source": [
    "To execute the batch inference job, we'll take the following steps:\n",
    "\n",
    "1. **Create the batch job file** - we'll generate a JSON lines file with the desired requests to be processed by the model\n",
    "2. **Upload the batch job file** - once it is ready, we'll upload it to the <a href=\"https://platform.kluster.ai/signup\" target=\"_blank\">kluster.ai platform</a> using the API, where it will be processed. We'll receive a unique ID associated with our file\n",
    "3. **Start the batch job** - after the file is uploaded, we'll initiate the job to process the uploaded data, using the file ID obtained before\n",
    "4. **Monitor job progress** - (optional) track the status of the batch job to ensure it has been successfully completed\n",
    "5. **Retrieve results** - once the job has completed execution, we can access and process the resultant data\n",
    "\n",
    "This notebook is prepared for you to follow along. Run the cells below to watch it all come together."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Ew-R24Ltp5EW",
   "metadata": {
    "id": "Ew-R24Ltp5EW"
   },
   "source": [
    "### Create the batch input file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qS4JXT52wGJ-",
   "metadata": {
    "id": "qS4JXT52wGJ-"
   },
   "source": [
    "This example uses two models that are more oriented to image vision/analysis: `google/gemma-3-27b-it` and `Qwen/Qwen2.5-VL-7B-Instruct`. Others model might not support providing images.\n",
    "\n",
    "In addition, please refer to the <a href=\"/get-started/start-building/batch/#supported-models\" target=\"_blank\">Supported models</a> section for a list of the models we support.\n",
    "\n",
    "The following snippets prepare the JSONL file, where each line represents a different request. Note that each separate batch request can have its own model. Also, we are using a temperature of `0.5` but feel free to change it and play around with the different outcomes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fVtwyqZ_nEq7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt based on image\n",
    "SYSTEM_PROMPTS = {\n",
    "    \"balls-image.jpg\": \"\"\"\n",
    "    You are a helpful assistant that analyzes image content.\n",
    "    Tell me the device depicted in the image, and how many balls it has.\n",
    "    \"\"\",\n",
    "    \"eggs-image.jpg\": \"\"\"\n",
    "    You are a helpful assistant that analyzes image content.\n",
    "    Count how many eggs are in total, and how many brown and white eggs separately.\n",
    "    \"\"\",\n",
    "    \"music-image.jpeg\": \"\"\"\n",
    "    You are a helpful assistant that analyzes image content.\n",
    "    Tell me the sequence of musical notes shown in the image.\n",
    "    \"\"\",\n",
    "}\n",
    "\n",
    "# Models\n",
    "models = {\n",
    "    #\"Gemma3-27B\": \"google/gemma-3-27b-it\",\n",
    "    \"Qwen2.5-7B\": \"Qwen/Qwen2.5-VL-7B-Instruct\"\n",
    "}\n",
    "\n",
    "# Ensure the directory exists\n",
    "os.makedirs(\"image_analysis\", exist_ok=True)\n",
    "\n",
    "# Create the batch job file with the prompt and content for the model and the image\n",
    "def create_batch_file(model, image):\n",
    "    image_url = base_url.replace(\"IMAGE_NAME\", image)\n",
    "    request = {\n",
    "        \"custom_id\": f\"image-{image}-{model}-analysis\",\n",
    "        \"method\": \"POST\",\n",
    "        \"url\": \"/v1/chat/completions\",\n",
    "        \"body\": {\n",
    "            \"model\": models[model],\n",
    "            \"temperature\": 0.5,\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": SYSTEM_PROMPTS[image]},\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\n",
    "                            \"type\": \"image_url\",\n",
    "                            \"image_url\": {\"url\": image_url},\n",
    "                        }\n",
    "                    ],\n",
    "                },\n",
    "            ],\n",
    "        },\n",
    "    }\n",
    "\n",
    "    return request\n",
    "\n",
    "# Save file\n",
    "def save_batch_file(batch_requests, model):\n",
    "    filename = f\"image_analysis/batch_job_{model}_request.jsonl\"\n",
    "    with open(filename, \"w\") as file:\n",
    "        for request in batch_requests:\n",
    "            file.write(json.dumps(request) + \"\\n\")\n",
    "    return filename\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f31ae8-8608-43aa-a8d2-58c71aa50cf4",
   "metadata": {},
   "source": [
    "Let's run the functions we've defined before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "qNhmrmHdnp7g",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_analysis/batch_job_Qwen2.5-7B_request.jsonl\n",
      "image_analysis/batch_job_Llama3.1-8B_request.jsonl\n"
     ]
    }
   ],
   "source": [
    "filenames = []\n",
    "\n",
    "for model in models:\n",
    "    batch_requests = []\n",
    "    for image in images:\n",
    "        batch_request = create_batch_file(model, image)\n",
    "        batch_requests.append(batch_request)\n",
    "    filename = save_batch_file(batch_requests, model)\n",
    "    filenames.append(filename)\n",
    "    print(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada26fe3-acb9-48dc-b368-b57fc380cdb8",
   "metadata": {},
   "source": [
    "Next, we can preview what one of the batch job files looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d65f5099-5add-4749-9a85-3c04a9b342bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"custom_id\": \"image-balls-image.jpg-Gemma3-analysis\", \"method\": \"POST\", \"url\": \"/v1/chat/completions\", \"body\": {\"model\": \"google/gemma-3-27b-it\", \"temperature\": 0.5, \"messages\": [{\"role\": \"system\", \"content\": \"\\n    You are a helpful assistant that analyzes image content.\\n    Tell me the device depicted in the image, and how many balls it has.\\n    \"}, {\"role\": \"user\", \"content\": [{\"type\": \"image_url\", \"image_url\": {\"url\": \"https://github.com/kluster-ai/docs/blob/main/images/tutorials/balls-image.jpg?raw=true\"}}]}]}}\n"
     ]
    }
   ],
   "source": [
    "!head -n 1 image_analysis/batch_job_Gemma3_request.jsonl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "xArKu7-sqSiR",
   "metadata": {
    "id": "xArKu7-sqSiR"
   },
   "source": [
    "### Upload inference file to kluster.ai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48b2489-99bc-431b-8cb3-de816550d524",
   "metadata": {},
   "source": [
    "Now that we've prepared our input files, it's time to upload it to the kluster.ai platform. To do so, you can use the `files.create` endpoint of the client, where the purpose is set to `batch`. This will return the file ID, which we need to log for the next steps. We will repeat the process for each batch file created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "l5eu5UyAnEtk",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_batch_file(data_dir):\n",
    "  print(f\"Creating request for {data_dir}\")\n",
    "  \n",
    "  with open(data_dir, 'rb') as file:\n",
    "    upload_response = client.files.create(\n",
    "    file=file,\n",
    "    purpose=\"batch\"\n",
    "  )\n",
    "\n",
    "  # Print job ID\n",
    "  file_id = upload_response.id\n",
    "  print(f\"File uploaded successfully. File ID: {file_id}\")\n",
    "\n",
    "  return upload_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cf65b30f-ae68-46d3-a4f3-edd4907c450b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading file image_analysis/batch_job_Qwen2.5-7B_request.jsonl\n",
      "Creating request for image_analysis/batch_job_Qwen2.5-7B_request.jsonl\n",
      "File uploaded successfully. File ID: 67e5b8dc1e8d51bcc13081c5\n",
      "Uploading file image_analysis/batch_job_Llama3.1-8B_request.jsonl\n",
      "Creating request for image_analysis/batch_job_Llama3.1-8B_request.jsonl\n",
      "File uploaded successfully. File ID: 67e5b8dce30eb5d129196eb8\n"
     ]
    }
   ],
   "source": [
    "batch_files = []\n",
    "\n",
    "# Loop through all .jsonl files in the data folder\n",
    "for data_dir in filenames:\n",
    "    print(f\"Uploading file {data_dir}\")\n",
    "    job = upload_batch_file(data_dir)\n",
    "    batch_files.append(job)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca62889-8a8f-4125-9e09-51402f704f64",
   "metadata": {},
   "source": [
    "All files are now uploaded, and we can proceed with creating the batch jobs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6438be35-1e73-4c34-9249-2dd16d102253",
   "metadata": {
    "id": "xArKu7-sqSiR"
   },
   "source": [
    "### Start the job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251a0b89-71a9-40d7-bf14-51be935afe10",
   "metadata": {},
   "source": [
    "Once all the files have been successfully uploaded, we're ready to start (create) the batch jobs by providing the file ID of each file, which we got in the previous step. To start each job, we use the `batches.create` method, for which we need to set the endpoint to `/v1/chat/completions`. This will return each batch job details, with each ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "71a24704-7190-4e24-898f-c4eff062439a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create batch job with completions endpoint\n",
    "def create_batch_job(file_id):\n",
    "  batch_job = client.batches.create(\n",
    "    input_file_id=file_id,\n",
    "    endpoint=\"/v1/chat/completions\",\n",
    "    completion_window=\"24h\"\n",
    "  )\n",
    "\n",
    "  print(f\"Batch job created with ID {batch_job.id}\")\n",
    "  return batch_job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1bb46ddf-1300-4092-9795-39c4bbbc32ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating batch job for file ID 67e5b8dc1e8d51bcc13081c5\n",
      "Batch job created with ID 67e5b8def5c2f4279cdffc5a\n",
      "Creating batch job for file ID 67e5b8dce30eb5d129196eb8\n",
      "Batch job created with ID 67e5b8e81e8d51bcc130826e\n"
     ]
    }
   ],
   "source": [
    "batch_jobs = []\n",
    "\n",
    "# Loop through all batch files ID and start each job\n",
    "for batch_file in batch_files:\n",
    "    print(f\"Creating batch job for file ID {batch_file.id}\")\n",
    "    batch_job = create_batch_job(batch_file.id)\n",
    "    batch_jobs.append(batch_job)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406e7a44",
   "metadata": {},
   "source": [
    "All requests are queued to be processed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e-ujphILqepu",
   "metadata": {
    "id": "e-ujphILqepu"
   },
   "source": [
    "### Check job progress"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "iFrDrriQqizC",
   "metadata": {
    "id": "iFrDrriQqizC"
   },
   "source": [
    "Now that your batch jobs have been created, you can track their progress.\n",
    "\n",
    "To monitor the job's progress, we can use the `batches.retrieve` method and pass the batch job ID. The response contains a `status` field that tells us if it is completed or not and the subsequent status of each job separately. We can repeat this process for every batch job ID we got in the previous step.\n",
    "\n",
    "The following snippet checks the status of all batch jobs every 10 seconds until the entire batch is completed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "SuH0CfoqjP3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def monitor_batch_jobs(batch_jobs):\n",
    "    all_completed = False\n",
    "\n",
    "    # Loop until all jobs are completed\n",
    "    while not all_completed:\n",
    "        all_completed = True\n",
    "        output_lines = []\n",
    "\n",
    "        # Loop through all batch jobs\n",
    "        for job in batch_jobs:\n",
    "            updated_job = client.batches.retrieve(job.id)\n",
    "            status = updated_job.status\n",
    "\n",
    "            # If job is completed\n",
    "            if status == \"completed\":\n",
    "                output_lines.append(\"Job completed!\")\n",
    "            # If job failed, cancelled or expired\n",
    "            elif status in [\"failed\", \"cancelled\", \"expired\"]:\n",
    "                output_lines.append(f\"Job ended with status: {status}\")\n",
    "                break\n",
    "            # If job is ongoing\n",
    "            else:\n",
    "                all_completed = False\n",
    "                completed = updated_job.request_counts.completed\n",
    "                total = updated_job.request_counts.total\n",
    "                output_lines.append(\n",
    "                    f\"Job status: {status} - Progress: {completed}/{total}\"\n",
    "                )\n",
    "\n",
    "        # Clear terminal\n",
    "        clear_output(wait=True)\n",
    "        for line in output_lines:\n",
    "            display(line)\n",
    "\n",
    "        # Check every 10 seconds\n",
    "        if not all_completed:\n",
    "            time.sleep(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "83fbd7c7-92db-4954-a6ac-a98103260daf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Job completed!'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Job ended with status: failed'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "monitor_batch_jobs(batch_jobs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "TkkhIG9HU0D9",
   "metadata": {
    "id": "TkkhIG9HU0D9"
   },
   "source": [
    "## Get the results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c1f6ac-8d60-4158-9036-de79fa274983",
   "metadata": {},
   "source": [
    "With all jobs completed, we'll retrieve the results and review the responses generated for each request. The results are parsed. To fetch the results from the platform, you need to retrieve the `output_file_id` from the batch job, and then use the `files.content` endpoint, providing that specific file ID. We will repeat this for every single batch job id. Note that the job status must be `completed` for you to retrieve the results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "806a5eb1-f6d3-491d-b051-9d44bf046a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parse results as a JSON object\n",
    "def parse_json_objects(data_string):\n",
    "  if isinstance(data_string, bytes):\n",
    "    data_string = data_string.decode('utf-8')\n",
    "\n",
    "  json_strings = data_string.strip().split('\\n')\n",
    "  json_objects = []\n",
    "\n",
    "  for json_str in json_strings:\n",
    "    try:\n",
    "      json_obj = json.loads(json_str)\n",
    "      json_objects.append(json_obj)\n",
    "    except json.JSONDecodeError as e:\n",
    "      print(f\"Error parsing JSON: {e}\")\n",
    "\n",
    "  return json_objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dfe37dba-828a-4ee8-8c18-384f2b83d118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " -------------------------- \n",
      "\n",
      "image-balls-image.jpg-Qwen2.5-7B-analysis\n",
      "\n",
      "RESULT: The image appears to be a grayscale pattern with no discernible objects or devices. It looks like a texture or a random pattern rather than a depiction of a specific device or object. There are no balls visible in this image.\n",
      "\n",
      " -------------------------- \n",
      "\n",
      "image-eggs-image.jpg-Qwen2.5-7B-analysis\n",
      "\n",
      "RESULT: The image you provided does not contain any visible eggs. It appears to be a patterned background with no discernible objects or items that resemble eggs. Therefore, it is not possible to count the number of eggs or categorize them by color based on this image.\n",
      "\n",
      " -------------------------- \n",
      "\n",
      "image-music-image.jpeg-Qwen2.5-7B-analysis\n",
      "\n",
      "RESULT: The image you provided does not contain any musical notes. It appears to be an abstract pattern with black and white lines on a dark background, which does not represent musical notation. If you have a different image or need assistance with something else, please let me know!\n",
      "\n",
      " -------------------------- \n",
      "\n",
      "image-balls-image.jpg-DeepSeekV3-0324-analysis\n",
      "\n",
      "RESULT: Since I don't have access to the image, I can't directly analyze its content. However, if you describe the device to me, I can help identify it and count the number of balls it has. \n",
      "\n",
      "For example, if the image shows:\n",
      "- A **Newton's Cradle**, it typically has 5 metal balls.\n",
      "- A **ball bearing**, the number of balls varies based on size and design.\n",
      "- A **pinball machine**, the number of balls depends on the game (usually 1–5).\n",
      "- A **lottery machine**, it could have dozens or hundreds of balls.\n",
      "\n",
      "Let me know what the device looks like or its function, and I can provide a more specific answer!\n",
      "\n",
      " -------------------------- \n",
      "\n",
      "image-eggs-image.jpg-DeepSeekV3-0324-analysis\n",
      "\n",
      "RESULT: To provide an accurate count of the total number of eggs, as well as the separate counts of brown and white eggs, I would need to analyze the image in question. Since I currently don't have access to the image, I can't perform this task directly.\n",
      "\n",
      "However, if you upload or provide the image, I can analyze it and give you the exact counts of:\n",
      "1. Total number of eggs\n",
      "2. Number of brown eggs\n",
      "3. Number of white eggs\n",
      "\n",
      "Please share the image, and I'll be happy to help!\n",
      "\n",
      " -------------------------- \n",
      "\n",
      "image-music-image.jpeg-DeepSeekV3-0324-analysis\n",
      "\n",
      "RESULT: I currently don't have the capability to analyze image content directly. However, if you describe the musical notes or upload an image file, I can help you identify the sequence of notes based on your description or the content of the uploaded file.  \n",
      "\n",
      "For example, you could describe:  \n",
      "- The clef (treble, bass, etc.)  \n",
      "- The position of the notes on the staff (e.g., \"a note on the middle line of the treble clef\")  \n",
      "- The types of notes (quarter, half, whole, etc.)  \n",
      "- Any sharps, flats, or other symbols  \n",
      "\n",
      "Alternatively, if you upload an image, I can process it and provide the sequence of notes for you. Let me know how you'd like to proceed!\n"
     ]
    }
   ],
   "source": [
    "# Go through all batch jobs, providing the output file ID\n",
    "for batch_job in batch_jobs:\n",
    "  job_status = client.batches.retrieve(batch_job.id)\n",
    "  result_file_id = job_status.output_file_id\n",
    "  result = client.files.content(result_file_id).content\n",
    "  results = parse_json_objects(result)\n",
    "\n",
    "  # For each, print the result\n",
    "  for res in results:\n",
    "    inference_id = res['custom_id']\n",
    "    result = res['response']['body']['choices'][0]['message']['content']\n",
    "    print(f'\\n -------------------------- \\n')\n",
    "    print(f\"{res['custom_id']}\\n\\nRESULT: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e0e816-6558-4ff2-bab2-f85cff00bfc8",
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1732042430093,
     "user": {
      "displayName": "Joaquin Rodríguez",
      "userId": "09993043682054067997"
     },
     "user_tz": 180
    },
    "id": "tu2R8dGYimKc"
   },
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d195dd1-1293-4407-b6ad-cab7e77b14c0",
   "metadata": {},
   "source": [
    "This tutorial used the chat completion endpoint to image analysis on multiple images using kluster.ai batch API. This particular example uploaded three specific images:\n",
    "\n",
    "1. A <a href=\"https://github.com/kluster-ai/docs/blob/main/images/tutorials/balls-image.jpg?raw=true\" target=\"_blank\">Newtown's cradle</a>, we asked what is the device's name and how many balls were in the image (5)\n",
    "2. <a href=\"https://github.com/kluster-ai/docs/blob/main/images/tutorials/eggs-image.jpg?raw=true\" target=\"_blank\">Eggs</a> of different colors, asked how many total eggs and per color (10 total, 8 brown and 2 white)\n",
    "3. <a href=\"https://github.com/kluster-ai/docs/blob/main/images/tutorials/music-image.jpeg?raw=true\" target=\"_blank\">Hand written musical note</a>, we asked what is the sequence of notes depicted (C, D, E and F)\n",
    "\n",
    "Both models performed....\n",
    "\n",
    "To submit a batch job, we've:\n",
    "\n",
    "1. Created the JSONL file, where each line of the file represented a separate request\n",
    "2. Submitted the file to the platform\n",
    "3. Started the batch job, and monitored its progress\n",
    "4. Once completed, we fetched the results\n",
    "\n",
    "All of this using the OpenAI Python library and API, no changes needed!\n",
    "\n",
    "Kluster.ai's batch API empowers you to scale your workflows seamlessly, making it an invaluable tool for processing extensive datasets. As next steps, feel free to create your own dataset, or expand on top of this existing example. Good luck!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
