---
title: Files API Reference
description: The Files endpoint simplifies file management, allowing you to upload, retrieve, delete, and list files for workflows like storing datasets or configs.
---

## Upload files

`POST https://api.kluster.ai/v1/files/`

Upload a [JSON Lines](https://jsonlines.org/){target=\_blank} file to the `files` endpoint.

You can also view all your uploaded files in the [**Files** tab](https://platform.kluster.ai/files) of the kluster.ai platform.

<div class="grid" markdown>
<div markdown>

**Request**

`file` ++"file"++ <span class="required" markdown>++"required"++</span>

The File object (not file name) to be uploaded.

---

`purpose` ++"string"++ <span class="required" markdown>++"required"++</span>

The intended purpose of the uploaded file. Use `batch` for the Batch API.

**Returns**

The uploaded [File](#file-object) object.

</div>
<div markdown>

=== "Python"

    ```python title="Example request"
    from openai import OpenAI

    # Configure OpenAI client
    client = OpenAI(
        base_url="https://api.kluster.ai/v1", 
        api_key="INSERT_API_KEY" # Replace with your actual API key
    )

    batch_input_file = client.files.create(
        file=open(file_name, "rb"),
        purpose="batch"
    )

    print(batch_input_file.to_dict())
    ```

=== "curl"

    ```bash title="Example request"
    curl -s https://api.kluster.ai/v1/files \
        -H "Authorization: Bearer $API_KEY" \
        -H "Content-Type: multipart/form-data" \
        -F "file=@mybatchtest.jsonl" \
        -F "purpose=batch"
    ```

```Json title="Response"
{
  "id": "myfile-123",
  "bytes": 2797,
  "created_at": "1733832768",
  "filename": "mybatchtest.jsonl",
  "object": "file",
  "purpose": "batch"
}
```

</div>
</div>

---

## Retrieve file

`GET https://api.kluster.ai/v1/files/{output_file_id}/content`

To retrieve the content of your Batch jobs output file, send a request to the `files` endpoint specifying the `output_file_id`. The output file will be a JSONL file, where each line contains the `custom_id` from your input file request, and the corresponding response.

<div class="grid" markdown>
<div markdown>

**Path parameters**

`file_id` ++"string"++ <span class="required" markdown>++"required"++</span>

The ID of the file to use for this request

---

**Returns**

The Batch object matching the specified file ID.

`id` ++"string"++

A unique identifier for the chat completion.

---

`custom_id` ++"string"++

A developer-provided per-request ID that will be used to match outputs to inputs.

---

`response` ++"object or null"++

??? child "Show properties"

    `status_code` ++"integer"++

    The HTTP status code of the response.

    ---

    `request_id` ++"string"++

    A unique identifier for the request. Please include this request ID when contacting support.

    ---

    `body` ++"map"++

    The JSON body of the response. In this case, the chat completion object.

    ??? child "Chat completion object"

        `id` ++"string"++

        A unique identifier for the chat completion.

        ---

        `choices` ++"array"++

        A list of chat completion choices. <!-- Can be more than one if `n` is greater than 1.-->

        ??? child "Show properties"

            `finish_reason` ++"string"++

            The reason the model stopped generating tokens. This will be `stop` if the model hit a natural stop point or a provided stop sequence, or length if the maximum number of tokens specified in the request was reached.

            ---

            `index` ++"integer"++

            The index of the choice in the list of choices.

            ---

            `message` ++"object"++

            A chat completion message generated by the model.

            ??? child "Show properties"

                `content` ++"string or null"++

                The contents of the message.

                ---

                `refusal` ++"string or null"++ <span class="future" markdown>++"future enhancement"++</span>

                ---

                `tool_calls` ++"array"++ <span class="future" markdown>++"future enhancement"++</span>

                ---
                
                `role` ++"string"++

                The role of the author of this message.

                ---

                `functional_call` ++"object"++ *deprecated*

                ---

                `audio` ++"object or null"++ <span class="future" markdown>++"future enhancement"++</span>

            ---

            `log_probs` ++"object or null"++

            Log probability information for the choice.

            ??? child "Show properties"

                `content` ++"array or null"++

                A list of message content tokens with log probability information.

                ??? child "Show properties"

                    `token` ++"string"++

                    The token.

                    ---

                    `logprob` ++"number"++

                    The log probability of this token, if it is within the top 20 most likely tokens. Otherwise, the value `-9999.0` is used to signify that the token is very unlikely.

                    ---

                    `bytes` ++"array or null"++

                    A list of integers representing the UTF-8 bytes representation of the token. Useful in instances where characters are represented by multiple tokens and their byte representations must be combined to generate the correct text representation. `null` if there is no bytes representation for the token.

                    ---

                    `top_logprobs` ++"array or null"++

                    The associated log probability for each token.

                    ??? child "Show properties"
                        
                        `token` ++"string"++

                        The token.

                        ---

                        `logprob` ++"number"++

                        The log probability of this token, if it is within the top 20 most likely tokens. Otherwise, the value `-9999.0` is used to signify that the token is very unlikely.

                        ---

                        `bytes` ++"array or null"++

                        A list of integers representing the UTF-8 bytes representation of the token. Useful in instances where characters are represented by multiple tokens and their byte representations must be combined to generate the correct text representation. `null` if there is no bytes representation for the token.

                ---

                `refusal` ++"array or null"++ <span class="future" markdown>++"future enhancement"++</span>

        ---

        `created` ++"integer"++

        The Unix timestamp (in seconds) of when the chat completion was created.

        ---

        `model`  ++"string"++
        
        The model used for the chat completion.

        ---

        `service_tier` ++"string or null"++ <span class="future" markdown>++"future enhancement"++</span>

        ---

        `system_fingerprint` ++"string"++ <span class="future" markdown>++"future enhancement"++</span>

        ---

        `object` ++"string"++

        The object type, which is always `chat.completion`.

        ---

        `usage` ++"object"++

        Usage statistics for the completion request.

        ??? child "Show properties"

            `completion_tokens` ++"integer"++

            Number of tokens in the generated completion.

            ---

            `prompt_tokens` ++"integer"++

            Number of tokens in the prompt.

            ---

            `total_tokens` ++"integer"++

            Total number of tokens used in the request (prompt + completion).

            ---

            `completion_token_details` ++"null"++ <span class="not-supported" markdown>++"Not supported"++</span>

            ---

            `prompt_token_details` ++"object"++ <span class="future" markdown>++"future enhancement"++</span>

---

`error` ++"object or null"++

For requests that failed with a non-HTTP error, this will contain more information on the cause of the failure.

??? child "Show properties"

    `code` ++"string"++ 
   
    A machine-readable error code.
   
    ---

    `message` ++"string"++
   
    A human-readable error message. 

</div>
<div markdown>

=== "Python"

    ```python title="Example request"
    from openai import OpenAI

    # Configure OpenAI client
    client = OpenAI(
        base_url="https://api.kluster.ai/v1", 
        api_key="INSERT_API_KEY" # Replace with your actual API key
    )

    # Get the status of the Batch, which returns the output_file_id
    batch_status = client.batches.retrieve(batch_request.id)

    # Check if the Batch completed successfully
    if batch_status.status.lower() == "completed":
        # Retrieve the results
        result_file_id = batch_status.output_file_id
        results = client.files.content(result_file_id).content

        # Save results to a file
        result_file_name = "batch_results.jsonl"
        with open(result_file_name, "wb") as file:
            file.write(results)
        print(f"Results saved to {result_file_name}")
    else:
        print(f"Batch failed with status: {batch_status.status}")
    ```

=== "curl"

    ```bash title="Example request"
    curl -s https://api.kluster.ai/v1/files/kluster-output-file-123/content \
        -H "Authorization: Bearer $API_KEY" > batch_output.jsonl
    ```

</div>
</div>

## File object

<div class="grid" markdown>
<div markdown>

`id` ++"string"++

The file identifier, which can be referenced in the API endpoints.

---

`object` ++"string"++

The object type, which is always `file`.

---

`bytes` ++"integer"++

The size of the file, in bytes.

---

`created_at` ++"integer"++

The Unix timestamp (in seconds) for when the file was created.

---

`filename` ++"string"++

The name of the file.

---

`purpose` ++"string"++

The intended purpose of the file. Currently, only `batch` is supported.

</div>
<div markdown>

```Json title="File object"
{
  "id": "myfile-123",
  "bytes": 2797,
  "created_at": "1733832768",
  "filename": "mybatchtest.jsonl",
  "object": "file",
  "purpose": "batch"
}
```

</div>
</div>
