# llms.txt
# Generated automatically. Do not edit directly.

Documentation: https://docs.kluster.ai/

# List of doc pages:
Doc-Page: https://docs.kluster.ai/api-reference/reference
Doc-Page: https://docs.kluster.ai/get-started/get-api-key
Doc-Page: https://docs.kluster.ai/get-started/integrations/eliza
Doc-Page: https://docs.kluster.ai/get-started/integrations/langchain
Doc-Page: https://docs.kluster.ai/get-started/integrations/sillytavern
Doc-Page: https://docs.kluster.ai/get-started/openai-compatibility
Doc-Page: https://docs.kluster.ai/get-started/start-api

# Full content for each doc page

Doc-Content: https://docs.kluster.ai/api-reference/reference
--- BEGIN CONTENT ---
---
title: API Reference
description: Explore the kluster.ai API reference to get a comprehensive overview on the available endpoints, request and response formats, and integration examples.
hide:
 - navigation
template: api.html
---

# API reference

## Chat

### Create chat completion

`POST https://api.kluster.ai/v1/chat/completions`

To create a chat completion, send a request to the `chat/completions` endpoint.

<div class="grid" markdown>
<div markdown>

**Request**

`model` ++"string"++ <span class="required" markdown>++"required"++</span>

ID of the model to use. You can use the `models` endpoint to retrieve the [list of supported models](#list-supported-models){target=\_blank}.

---

`messages` ++"array"++ <span class="required" markdown>++"required"++</span>

A list of messages comprising the conversation so far. The `messages` object can be one of `system`, `user`, or `assistant`.

??? child "Show possible types"

    System message ++"object"++
    
    ??? child "Show properties"

        `content` ++"string or array"++

        The contents of the system message.  

        ---
       
        `role` ++"string or null"++ <span class="required" markdown>++"required"++</span>

        The role of the messages author, in this case, `system`.

    ---

    User message ++"object"++

    ??? child "Show properties"

        `content` ++"string or array"++

        The contents of the user message.  

        ---
       
        `role` ++"string or null"++ <span class="required" markdown>++"required"++</span>

        The role of the messages author, in this case, `user`.

    ---

    Assistant message ++"object"++

    ??? child "Show properties"

        `content` ++"string or array"++

        The contents of the assistant message.  

        ---

        `role` ++"string or null"++ <span class="required" markdown>++"required"++</span>

        The role of the messages author, in this case, `assistant`.

`frequency_penalty` ++"number or null"++

Number between -2.0 and 2.0. Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model's likelihood of repeating the same line verbatim. Defaults to `0`.

---

`logit_bias` ++"map"++

Modify the likelihood of specified tokens appearing in the completion. Defaults to `null`.

Accepts a JSON object that maps tokens (specified by their token ID in the tokenizer) to an associated bias value from -100 to 100. Mathematically, the bias is added to the logits generated by the model prior to sampling. The exact effect will vary per model, but values between -1 and 1 should decrease or increase the likelihood of selection; values like -100 or 100 should result in a ban or exclusive selection of the relevant token.

---

`logprobs` ++"boolean or null"++
   
Whether to return log probabilities of the output tokens or not. If true, returns the log probabilities of each output token returned in the `content` of `message`. Defaults to `false`.

---

`top_logprobs` ++"integer or null"++

An integer between 0 and 20 specifying the number of most likely tokens to return at each token position, each with an associated log probability. `logprobs` must be set to `true` if this parameter is used.

---

`max_completion_tokens` ++"integer or null"++

An upper bound for the number of tokens that can be generated for a completion, including visible output tokens and reasoning tokens.

---

`presence_penalty` ++"number or null"++

Number between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the text so far, increasing the model's likelihood to talk about new topics. Defaults to `0`.

---

`seed` ++"integer or null"++

If specified, our system will make a best effort to sample deterministically, such that repeated requests with the same `seed` and parameters should return the same result. Determinism is not guaranteed.

---

`stop` ++"string or array or null"++

Up to four sequences where the API will stop generating further tokens. Defaults to `null`.

---

`stream` ++"boolean or null"++

If set, partial message deltas will be sent. Tokens will be sent as data-only server-sent events as they become available, with the stream terminated by a `data: [DONE]` message. Defaults to `false`.

---

`temperature` ++"number or null"++

The sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. Defaults to `1`.

It is generally recommended to alter this or `top_p` but not both.

---

`top_p` ++"number or null"++

An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered. Defaults to `1`.

It is generally recommended to alter this or `temperature` but not both.

---

**Returns**

The created [Chat completion](#batch-object) object.

</div>
<div markdown>

=== "Python"

    ```python title="Example request"
    from openai import OpenAI

    # Configure OpenAI client
    client = OpenAI(
        base_url="https://api.kluster.ai/v1", 
        api_key="INSERT_API_KEY" # Replace with your actual API key
    )

    chat_completion = client.chat.completions.create(
        model="klusterai/Meta-Llama-3.1-8B-Instruct-Turbo",
        messages=[
            {"role": "system", "content": "You are a helpful assistant."},
            {"role": "user", "content": "What is the capital of Argentina?"},
        ],
    )

    print(chat_completion.to_dict())
    ```

=== "curl"

    ```bash title="Example request"
    curl -s https://api.kluster.ai/v1/chat/completions \
        -H "Authorization: Bearer 4532c187-d275-4a6b-940c-5d92f9b20ea6" \
        -H "Content-Type: application/json" \
        -d '{
            "model": "klusterai/Meta-Llama-3.1-8B-Instruct-Turbo",
            "messages": [
                {
                    "role": "system",
                    "content": "You are a helpful assistant."
                },
                {
                    "role": "user",
                    "content": "What is the capital of Argentina?"
                }
            ]
        }'
    ```

```Json title="Response"
{
    "id": "chat-d187c103e189483485b3bcd3eb899c62",
    "object": "chat.completion",
    "created": 1736136422,
    "model": "klusterai/Meta-Llama-3.1-8B-Instruct-Turbo",
    "choices": [
        {
            "index": 0,
            "message": {
                "role": "assistant",
                "content": "The capital of Argentina is Buenos Aires.",
                "tool_calls": []
            },
            "logprobs": null,
            "finish_reason": "stop",
            "stop_reason": null
        }
    ],
    "usage": {
        "prompt_tokens": 48,
        "total_tokens": 57,
        "completion_tokens": 9
    },
    "prompt_logprobs": null
}
```

</div>
</div>

---

### Chat completion object

<div class="grid" markdown>
<div markdown>

`id` ++"string"++

Unique identifier for the chat completion.

---

`object` ++"string"++

The object type, which is always `chat.completion`.

---

`created` ++"integer"++

The Unix timestamp (in seconds) of when the chat completion was created.

---

`model` ++"string"++

The model used for the chat completion. You can use the `models` endpoint to retrieve the [list of supported models](#list-supported-models){target=\_blank}.

---

`choices` ++"array"++

A list of chat completion choices.

??? child "Show properties"

    `index` ++"integer"++

    The index of the choice in the list of returned choices.

    ---

    `message` ++"object"++

    A chat completion message generated by the model. Can be one of `system`, `user`, or `assistant`.

    ??? child "Show properties"

        `content` ++"string or array"++

        The contents of the message.  

        ---

        `role` ++"string or null"++

        The role of the messages author. Can be one of `system`, `user`, or `assistant`
    
    ---

    `logprobs` ++"boolean or null"++

    Whether to return log probabilities of the output tokens or not. If true, returns the log probabilities of each output token returned in the `content` of `message`. Defaults to `false`.

    ---

    `finish_reason` ++"string"++

    The reason the model stopped generating tokens. This will be `stop` if the model hit a natural stop point or a provided stop sequence, `length` if the maximum number of tokens specified in the request was reached, `content_filter` if content was omitted due to a flag from our content filters, `tool_calls` if the model called a tool, or `function_call` (_deprecated_) if the model called a function.

    --- 

    `stop_reason` ++"string or null"++

    The reason the model stopped generating text.

---

`usage` ++"object"++

Usage statistics for the completion request.

??? child "Show properties"

    `completion_tokens` ++"integer"++

    Number of tokens in the generated completion.

    ---

    `prompt_tokens` ++"integer"++

    Number of tokens in the prompt.

    ---

    `total_tokens` ++"integer"++

    Total number of tokens used in the request (prompt + completion).

</div>
<div markdown>

```Json title="Chat completion object"
{
    "id": "chat-d187c103e189483485b3bcd3eb899c62",
    "object": "chat.completion",
    "created": 1736136422,
    "model": "klusterai/Meta-Llama-3.1-8B-Instruct-Turbo",
    "choices": [
        {
            "index": 0,
            "message": {
                "role": "assistant",
                "content": "The capital of Argentina is Buenos Aires.",
                "tool_calls": []
            },
            "logprobs": null,
            "finish_reason": "stop",
            "stop_reason": null
        }
    ],
    "usage": {
        "prompt_tokens": 48,
        "total_tokens": 57,
        "completion_tokens": 9
    },
    "prompt_logprobs": null
}
```

</div>
</div>

---

## Batch

### Submit a Batch job

`POST https://api.kluster.ai/v1/batches`

To submit a Batch job, send a request to the `batches` endpoint.

<div class="grid" markdown>
<div markdown>

**Request**

`input_file_id` ++"string"++ <span class="required" markdown>++"required"++</span>

The ID of an [uploaded file](#upload-files){target=\_blank} that contains requests for the new Batch.

Your input file must be formatted as a [JSONL file](https://jsonlines.org/){target=\_blank}, and must be uploaded with the purpose `batch`. The file can contain up to 50,000 requests and currently a maximum of 6GB per file.

---

`endpoint` ++"string"++ <span class="required" markdown>++"required"++</span>

The endpoint to be used for all requests in the Batch. Currently, only `/v1/chat/completions` is supported.

---

`completion_window` ++"string"++ <span class="required" markdown>++"required"++</span>

The supported completion windows are 1, 3, 6, 12, and 24 hours to accommodate a range of use cases and budget requirements. The code samples provided utilize the 24-hour completion window.

Learn more about how completion window selection affects cost by visiting the pricing section of the [kluster.ai website](https://www.kluster.ai){target=\_blank}.

---

`metadata` ++"Object or null"++

Custom metadata for the Batch.

---

**Returns**

The created [Batch](#batch-object) object.

</div>
<div markdown>

=== "Python"

    ```python title="Example request"
    from openai import OpenAI

    # Configure OpenAI client
    client = OpenAI(
        base_url="https://api.kluster.ai/v1",
        api_key="INSERT_API_KEY",  # Replace with your actual API key
    )

    batch_request = client.batches.create(
        input_file_id="myfile-123",
        endpoint="/v1/chat/completions",
        completion_window="24h",
    )

    print(batch_request.to_dict())
    ```

=== "curl"

    ```bash title="Example request"
    curl -s https://api.kluster.ai/v1/batches \
        -H "Authorization: Bearer $API_KEY" \
        -H "Content-Type: application/json" \
        -d '{
        "input_file_id": "myfile-123",
        "endpoint": "/v1/chat/completions",
        "completion_window": "24h"
        }'
    ```

```Json title="Response"
{
    "id": "mybatch-123",
    "completion_window": "24h",
    "created_at": 1733832777,
    "endpoint": "/v1/chat/completions",
    "input_file_id": "myfile-123",
    "object": "batch",
    "status": "validating",
    "cancelled_at": null,
    "cancelling_at": null,
    "completed_at": null,
    "error_file_id": null,
    "errors": null,
    "expired_at": null,
    "expires_at": 1733919177,
    "failed_at": null,
    "finalizing_at": null,
    "in_progress_at": null,
    "metadata": {},
    "output_file_id": null,
    "request_counts": {
        "completed": 0,
        "failed": 0,
        "total": 0
    }
}
```

</div>
</div>

---

### Retrieve a Batch

`GET https://api.kluster.ai/v1/batches/{batch_id}`

To retrieve a Batch job, send a request to the `batches` endpoint with your `batch_id`.

You can also monitor jobs in the [**Batch** tab](https://platform.kluster.ai/batch){target=\_blank} of the kluster.ai platform UI.

<div class="grid" markdown>
<div markdown>

**Path parameters**

`batch_id` ++"string"++ <span class="required" markdown>++"required"++</span>

The ID of the Batch to retrieve.

---

**Returns**

The [Batch](#batch-object) object matching the specified `batch_id`.

</div>
<div markdown>

=== "Python"

    ```python title="Example request"
    from openai import OpenAI

    # Configure OpenAI client
    client = OpenAI(
        base_url="https://api.kluster.ai/v1",
        api_key="INSERT_API_KEY",  # Replace with your actual API key
    )

    client.batches.retrieve("mybatch-123")
    ```

=== "curl"

    ```bash title="Example request"
    curl -s https://api.kluster.ai/v1/batches/mybatch-123 \
        -H "Authorization: Bearer $API_KEY" \
        -H "Content-Type: application/json"
    ```

```Json title="Response"
{
  "id": "mybatch-123",
  "object": "batch",
  "endpoint": "/v1/chat/completions",
  "errors": null,
  "input_file_id": "myfile-123",
  "completion_window": "24h",
  "status": "completed",
  "output_file_id": "myfile-123-output",
  "error_file_id": null,
  "created_at": "1733832777",
  "in_progress_at": "1733832777",
  "expires_at": "1733919177",
  "finalizing_at": "1733832781",
  "completed_at": "1733832781",
  "failed_at": null,
  "expired_at": null,
  "cancelling_at": null,
  "cancelled_at": null,
  "request_counts": {
    "total": 4,
    "completed": 4,
    "failed": 0
  },
  "metadata": {}
}
```

</div>
</div>

---

### Cancel a Batch

`POST https://api.kluster.ai/v1/batches/{batch_id}/cancel`

To cancel a Batch job that is currently in progress, send a request to the `cancel` endpoint with your `batch_id`. Note that cancellation may take up to 10 minutes to complete, during which time the status will show as `cancelling`.

<div class="grid" markdown>
<div markdown>

**Path parameters**

`batch_id` ++"string"++ <span class="required" markdown>++"required"++</span>

The ID of the Batch to cancel.

---

**Returns**

The [Batch](#batch-object) object matching the specified ID.

</div>
<div markdown>

=== "Python"

    ```python title="Example"
    from openai import OpenAI

    # Configure OpenAI client
    client = OpenAI(
        base_url="https://api.kluster.ai/v1",  
        api_key="INSERT_API_KEY" # Replace with your actual API key
    )

    client.batches.cancel("mybatch-123") # Replace with your batch id
    ```

=== "curl"

    ```bash title="Example"
    curl -s https://api.kluster.ai/v1/batches/$BATCH_ID/cancel \
        -H "Authorization: Bearer $API_KEY" \
        -H "Content-Type: application/json" \
        -X POST
    ```

```Json title="Response"
{
  "id": "mybatch-123",
  "object": "batch",
  "endpoint": "/v1/chat/completions",
  "errors": null,
  "input_file_id": "myfile-123",
  "completion_window": "24h",
  "status": "cancelling",
  "output_file_id": "myfile-123-output",
  "error_file_id": null,
  "created_at": "1730821906",
  "in_progress_at": "1730821911",
  "expires_at": "1730821906",
  "finalizing_at": null,
  "completed_at": null,
  "failed_at": null,
  "expired_at": null,
  "cancelling_at": "1730821906",
  "cancelled_at": null,
  "request_counts": {
    "total": 3,
    "completed": 3,
    "failed": 0
  },
  "metadata": {}
}
```

</div>
</div>

---

### List all Batch jobs

`GET https://api.kluster.ai/v1/batches`

To list all Batch jobs, send a request to the `batches` endpoint without specifying a `batch_id`. To constrain the query response, you can also use a `limit` parameter.

<div class="grid" markdown>
<div markdown>

**Query parameters**

`after` ++"string"++

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with `obj_foo`, your subsequent call can include `after=obj_foo` in order to fetch the next page of the list.

---

`limit` ++"integer"++

A limit on the number of objects to be returned. Limit can range between 1 and 100. Default is 20.

---

**Returns**

A list of paginated [Batch](#batch-object) objects.

The status of a Batch object can be one of the following:

<style>
table th:first-child {
  width: 10em;
}
</style>

| Status        | Description                                                             |
|---------------|-------------------------------------------------------------------------|
| `validating`  | The input file is being validated.                                      |
| `failed`      | The input file failed the validation process.                           |
| `in_progress` | The input file was successfully validated and the Batch is in progress. |
| `finalizing`  | The Batch job has completed and the results are being finalized.        |
| `completed`   | The Batch has completed and the results are ready.                      |
| `expired`     | The Batch was not completed within the 24-hour time window.             |
| `cancelling`  | The Batch is being cancelled (may take up to 10 minutes).               |
| `cancelled`   | The Batch was cancelled.                                                |

</div>

<div markdown>

=== "Python"

    ```python title="Example request"
    from openai import OpenAI

    # Configure OpenAI client
    client = OpenAI(
        base_url="https://api.kluster.ai/v1", 
        api_key="INSERT_API_KEY" # Replace with your actual API key
    )

    print(client.batches.list(limit=2).to_dict())
    ```

=== "curl"

    ```bash title="Example request" 
    curl -s https://api.kluster.ai/v1/batches \
        -H "Authorization: Bearer $API_KEY"
    ```

```Json title="Response"
{
"object": "list",
"data": [
    {
    "id": "mybatch-123",
    "object": "batch",
    "endpoint": "/v1/chat/completions",
    "errors": null,
    "input_file_id": "myfile-123",
    "completion_window": "24h",
    "status": "completed",
    "output_file_id": "myfile-123-output",
    "error_file_id": null,
    "created_at": "1733832777",
    "in_progress_at": "1733832777",
    "expires_at": "1733919177",
    "finalizing_at": "1733832781",
    "completed_at": "1733832781",
    "failed_at": null,
    "expired_at": null,
    "cancelling_at": null,
    "cancelled_at": null,
    "request_counts": {
        "total": 4,
        "completed": 4,
        "failed": 0
    },
    "metadata": {}
    },
{ ... },
],
"first_id": "mybatch-123",
"last_id": "mybatch-789",
"has_more": false,
"count": 1,
"page": 1,
"page_count": -1,
"items_per_page": 9223372036854775807
}
```

</div>
</div>

---

### Batch object

<div class="grid" markdown>
<div markdown>

`id` ++"string"++

The ID of the Batch.

---

`object` ++"string"++

The object type, which is always `batch`.

---

`endpoint` ++"string"++

The kluster.ai API endpoint used by the Batch.

---

`errors` ++"object"++

??? child "Show properties"
    
    `object` ++"string"++

    The object type, which is always `list`.

    ---

    `data` ++"array"++

    ??? child "Show properties"

        `code` ++"string"++

        An error code identifying the error type.

        ---

        `message` ++"string"++

        A human-readable message providing more details about the error.

        ---

        `param` ++"string or null"++

        The name of the parameter that caused the error, if applicable.

        ---
    
        `line` ++"integer or null"++

        The line number of the input file where the error occurred, if applicable.
---

`input_file_id` ++"string"++

The ID of the input file for the Batch.

---

`completion_window` ++"string"++

The time frame within which the Batch should be processed.

---

`status` ++"string"++

The current status of the Batch.

---

`output_file_id` ++"string"++

The ID of the file containing the outputs of successfully executed requests.

---

`error_file_id` ++"string"++

The ID of the file containing the outputs of requests with errors.

---

`created_at` ++"integer"++

The Unix timestamp (in seconds) for when the Batch was created.

---

`in_progress_at` ++"integer"++

The Unix timestamp (in seconds) for when the Batch started processing.

---

`expires_at` ++"integer"++

The Unix timestamp (in seconds) for when the Batch will expire.

---

`finalizing_at` ++"integer"++

The Unix timestamp (in seconds) for when the Batch started finalizing.

---

`completed_at` ++"integer"++

The Unix timestamp (in seconds) for when the Batch was completed.

---

`failed_at` ++"integer"++

The Unix timestamp (in seconds) for when the Batch failed.

---

`expired_at` ++"integer"++

The Unix timestamp (in seconds) for when the Batch expired.

---

`cancelling_at` ++"integer"++

The Unix timestamp (in seconds) for when the Batch started cancelling.

---

`cancelled_at` ++"integer"++

The Unix timestamp (in seconds) for when the Batch was cancelled.

---

`request_counts` ++"object"++

The request counts for different statuses within the Batch.

??? child "Show properties"

    `total` ++"integer"++

    Total number of requests in the Batch.

    ---

    `completed` ++"integer"++

    Number of requests that have been completed successfully.

    ---

    `failed` ++"integer"++

    Number of requests that have failed.   


<!--
---

`metadata` ++"Object or null"++

Set of 16 key-value pairs that can be attached to an object. This is useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long, and values can be a maximum of 512 characters long.
-->

</div>
<div markdown>

```Json title="Batch object"
{
    "id": "mybatch-123",
    "completion_window": "24h",
    "created_at": 1733832777,
    "endpoint": "/v1/chat/completions",
    "input_file_id": "myfile-123",
    "object": "batch",
    "status": "validating",
    "cancelled_at": null,
    "cancelling_at": null,
    "completed_at": null,
    "error_file_id": null,
    "errors": null,
    "expired_at": null,
    "expires_at": 1733919177,
    "failed_at": null,
    "finalizing_at": null,
    "in_progress_at": null,
    "metadata": {},
    "output_file_id": null,
    "request_counts": {
        "completed": 0,
        "failed": 0,
        "total": 0
    }
}
```

</div>
</div>

---

### The request input object

<div class="grid" markdown>
<div markdown>

The per-line object of the Batch input file.

`custom_id` ++"string"++

A developer-provided per-request ID.

---

`method` ++"string"++

The HTTP method to be used for the request. Currently, only POST is supported.

---

`url` ++"string"++

The `/v1/chat/completions` endpoint.

---

`body` ++"map"++

The JSON body of the input file.

</div>
<div markdown>

```Json title="Request input object"
[
    {
        "custom_id": "request-1",
        "method": "POST",
        "url": "/v1/chat/completions",
        "body": {
            "model": "klusterai/Meta-Llama-3.1-8B-Instruct-Turbo",
            "messages": [
                {
                    "role": "system",
                    "content": "You are a helpful assistant."
                },
                {
                    "role": "user",
                    "content": "What is the capital of Argentina?"
                }
            ],
            "max_tokens": 1000
        }
    }
]
```

</div>
</div>

---

### The request output object

<div class="grid" markdown>
<div markdown>

The per-line object of the Batch output files.

`id` ++"string"++

A unique identifier for the batch request.

---

`custom_id` ++"string"++

A developer-provided per-request ID that will be used to match outputs to inputs.

---

`response` ++"object or null"++

??? child "Show properties"

    `status_code` ++"integer"++

    The HTTP status code of the response.

    ---

    `request_id` ++"string"++

    A unique identifier for the request. You can reference this request ID if you need to contact support for assistance.

    ---

    `body` ++"map"++

    The JSON body of the response.

---

`error` ++"object or null"++

For requests that failed with a non-HTTP error, this will contain more information on the cause of the failure.

??? child "Show properties"

    `code` ++"string"++ 
   
    A machine-readable error code.
   
    ---

    `message` ++"string"++
   
    A human-readable error message. 

</div>
<div markdown>

```Json title="Request output object"
{
    "id": "batch-req-123",
    "custom_id": "request-1",
    "response": {
        "status_code": 200,
        "request_id": "req-123",
        "body": {
            "id": "chatcmpl-5a5ba6c6-2f95-4136-815b-23275c4f1efb",
            "object": "chat.completion",
            "created": 1737472126,
            "model": "klusterai/Meta-Llama-3.1-8B-Instruct-Turbo",
            "choices": [
                {
                    "index": 0,
                    "message": {
                        "role": "assistant",
                        "content": "The capital of Argentina is Buenos Aires.",
                        "tool_calls": []
                    },
                    "logprobs": null,
                    "finish_reason": "stop",
                    "stop_reason": null
                }
            ],
            "usage": {
                "prompt_tokens": 48,
                "total_tokens": 57,
                "completion_tokens": 9,
                "prompt_tokens_details": null
            },
            "prompt_logprobs": null
        }
    }
}
```

</div>
</div>

---

## Files

### Upload files

`POST https://api.kluster.ai/v1/files/`

Upload a [JSON Lines](https://jsonlines.org/){target=\_blank} file to the `files` endpoint.

You can also view all your uploaded files in the [**Files** tab](https://platform.kluster.ai/files){target=\_blank} of the kluster.ai platform.

<div class="grid" markdown>
<div markdown>

**Request**

`file` ++"file"++ <span class="required" markdown>++"required"++</span>

The File object (not file name) to be uploaded.

---

`purpose` ++"string"++ <span class="required" markdown>++"required"++</span>

The intended purpose of the uploaded file. Use `batch` for the Batch API.

---

**Returns**

The uploaded [File](#file-object) object.

</div>
<div markdown>

=== "Python"

    ```python title="Example request"
    from openai import OpenAI

    # Configure OpenAI client
    client = OpenAI(
        base_url="https://api.kluster.ai/v1", 
        api_key="INSERT_API_KEY" # Replace with your actual API key
    )

    batch_input_file = client.files.create(
        file=open(file_name, "rb"),
        purpose="batch"
    )

    print(batch_input_file.to_dict())
    ```

=== "curl"

    ```bash title="Example request"
    curl -s https://api.kluster.ai/v1/files \
        -H "Authorization: Bearer $API_KEY" \
        -H "Content-Type: multipart/form-data" \
        -F "file=@mybatchtest.jsonl" \
        -F "purpose=batch"
    ```

```Json title="Response"
{
  "id": "myfile-123",
  "bytes": 2797,
  "created_at": "1733832768",
  "filename": "mybatchtest.jsonl",
  "object": "file",
  "purpose": "batch"
}
```

</div>
</div>

---

### Retrieve file content

`GET https://api.kluster.ai/v1/files/{output_file_id}/content`

To retrieve the content of your Batch jobs output file, send a request to the `files` endpoint specifying the `output_file_id`. The output file will be a JSONL file, where each line contains the `custom_id` from your input file request, and the corresponding response.

<div class="grid" markdown>
<div markdown>

**Path parameters**

`file_id` ++"string"++ <span class="required" markdown>++"required"++</span>

The ID of the file to use for this request

---

**Returns**

The file content. Refer to the [input](/api-reference/reference/#the-request-input-object){target=\_blank} and [output](/api-reference/reference/#the-request-output-object){target=\_blank} format specifications for batch requests.

</div>
<div markdown>

=== "Python"

    ```python title="Example request"
    from openai import OpenAI

    # Configure OpenAI client
    client = OpenAI(
        base_url="https://api.kluster.ai/v1", 
        api_key="INSERT_API_KEY" # Replace with your actual API key
    )

    # Get the status of the Batch, which returns the output_file_id
    batch_status = client.batches.retrieve(batch_request.id)

    # Check if the Batch completed successfully
    if batch_status.status.lower() == "completed":
        # Retrieve the results
        result_file_id = batch_status.output_file_id
        results = client.files.content(result_file_id).content

        # Save results to a file
        result_file_name = "batch_results.jsonl"
        with open(result_file_name, "wb") as file:
            file.write(results)
        print(f"Results saved to {result_file_name}")
    else:
        print(f"Batch failed with status: {batch_status.status}")
    ```

=== "curl"

    ```bash title="Example request"
    curl -s https://api.kluster.ai/v1/files/kluster-output-file-123/content \
        -H "Authorization: Bearer $API_KEY" > batch_output.jsonl
    ```

</div>
</div>

---

### File object

<div class="grid" markdown>
<div markdown>

`id` ++"string"++

The file identifier, which can be referenced in the API endpoints.

---

`object` ++"string"++

The object type, which is always `file`.

---

`bytes` ++"integer"++

The size of the file, in bytes.

---

`created_at` ++"integer"++

The Unix timestamp (in seconds) for when the file was created.

---

`filename` ++"string"++

The name of the file.

---

`purpose` ++"string"++

The intended purpose of the file. Currently, only `batch` is supported.

</div>
<div markdown>

```Json title="File object"
{
  "id": "myfile-123",
  "bytes": 2797,
  "created_at": "1733832768",
  "filename": "mybatchtest.jsonl",
  "object": "file",
  "purpose": "batch"
}
```

</div>
</div>

---

## Models

### List supported models

`GET https://api.kluster.ai/v1/models`

Lists the currently available models.

You can use this endpoint to retrieve a list of all available models for the kluster.ai API. Currently supported models include:

- `klusterai/Meta-Llama-3.1-8B-Instruct-Turbo`
- `klusterai/Meta-Llama-3.1-405B-Instruct-Turbo`
- `klusterai/Meta-Llama-3.3-70B-Instruct-Turbo`
- `deepseek-ai/DeepSeek-R1`

<div class="grid" markdown>
<div markdown>

**Returns**

`id` ++"string"++

The model identifier, which can be referenced in the API endpoints.

---

`created` ++"integer"++

The Unix timestamp (in seconds) when the model was created.

---

`object` ++"string"++

The object type, which is always `model`.

---

`owned_by` ++"string"++

The organization that owns the model.

</div>
<div markdown>

=== "Python"

    ```python title="Example request"
    from openai import OpenAI

    # Configure OpenAI client
    client = OpenAI(
        base_url="http://api.kluster.ai/v1",
        api_key="INSERT_API_KEY" # Replace with your actual API key
    )

    print(client.models.list().to_dict())
    ```

=== "curl"

    ```bash title="Example request"
    curl https://api.kluster.ai/v1/models \
        -H "Authorization: Bearer $API_KEY" 
    ```

```Json title="Response"
{
  "object": "list",
  "data": [
    {
      "id": "klusterai/Meta-Llama-3.1-405B-Instruct-Turbo",
      "created": 1731336418,
      "object": "model",
      "owned_by": "klusterai"
    },
    {
      "id": "klusterai/Meta-Llama-3.1-8B-Instruct-Turbo",
      "created": 1731336610,
      "object": "model",
      "owned_by": "klusterai"
    },
    {
      "id": "klusterai/Meta-Llama-3.3-70B-Instruct-Turbo",
      "created": 1733777629,
      "object": "model",
      "owned_by": "klusterai"
    },
    {
      "id": "deepseek-ai/DeepSeek-R1",
      "created": 1737385699,
      "object": "model",
      "owned_by": "klusterai"
    }
  ],
}
```

</div>
</div>

---

## Fine-tuning

Fine-tuning is the process of refining a pre-trained model on specialized data. By adjusting the parameters with new, domain-specific examples, the model performs better on targeted tasks while retaining the general knowledge learned in its original training.

### Supported models

Currently, two base models are supported for Fine-tuning:

- **`klusterai/Meta-Llama-3.1-8B-Instruct-Turbo`** - has a `64,000` tokens max context window, best for long-context tasks, cost-sensitive scenarios
- **`klusterai/Meta-Llama-3.3-70B-Instruct-Turbo`** - has a `32,000` tokens max context window, best for complex reasoning, high-stakes accuracy

### Create a Fine-tuning job

`POST https://api.kluster.ai/v1/fine_tuning/jobs`

To initiate a Fine-tuning job for one of the supported models, first upload the dataset file (see [Files section](#files) for instructions).

<div class="grid" markdown> 
<div markdown>

**Request**

`training_file` ++"string"++ <span class="required" markdown>++"required"++</span>

ID of an [uploaded file](#files) that will serve as training data. This file must have `purpose="fine-tune"`.

---

`model` ++"string"++ <span class="required" markdown>++"required"++</span>

The base model ID to fine-tune. Must be a fine-tunable model, for example `meta-llama/Meta-Llama-3.1-8B-Instruct` or `meta-llama/Meta-Llama-3.3-70B-Instruct-Turbo`.

---

`validation_file` ++"string or null"++

Optionally specify a separate file to serve as your validation dataset.

---

`hyperparameters` ++"object or null"++

Optionally specify an object containing hyperparameters for Fine-tuning:

??? child "Show properties"

    `batch_size` ++"number"++

    The number of training examples processed in one forward/backward pass. Larger batch sizes reduce the frequency of weight updates per epoch, leading to more stable gradients but slower updates. Gradient accumulation is used, so larger batches may increase the duration of the job.

    ---

    `learning_rate_multiplier` ++"number"++

    A multiplier for the base step size used in model weight updates. Lower values slow training but improve precision (helping avoid overshooting optimal weights or overfitting). Higher values speed up convergence but risk instability. Adjust carefully to balance training efficiency and model performance.

    ---

    `n_epochs` ++"number"++

    The number of times the entire training dataset is passed through the model. More epochs can improve learning but risk overfitting if the model memorizes training data. Monitor validation metrics to determine the optimal number.


---

`nickname` ++"string or null"++

Add a custom suffix that will be appended to the output model name. This can help identify a fine tuned model.

---

**Returns**

A [Fine-tuning job object](#fine-tuning-job-object).

</div> 
<div markdown>

=== "Python"

    ```python title="Example request"
    from openai import OpenAI
    
    # Configure OpenAI client
    client = OpenAI(
        base_url="https://api.kluster.ai/v1",
        api_key="INSERT_API_KEY"  # Replace with your actual API key
    )
    
    job = client.fine_tuning.jobs.create(
        training_file="INSERT_TRAINING_FILE_ID",  # ID from uploaded training file
        model="meta-llama/Meta-Llama-3.1-8B-Instruct",
        hyperparameters={
            "batch_size": 4,
            "learning_rate_multiplier": 1,
            "n_epochs": 3
        }
    )
    print(job.to_dict())
    ```

=== "curl"

    ```bash title="Example request"
    curl -X POST https://api.kluster.ai/v1/fine_tuning/jobs \
        -H "Authorization: Bearer INSERT_API_KEY" \
        -H "Content-Type: application/json" \
        -d '{
            "training_file": "INSERT_TRAINING_FILE_ID",
            "model": "meta-llama/Meta-Llama-3.1-8B-Instruct",
            "hyperparameters": {
                "batch_size": 4,
                "learning_rate_multiplier": 1,
                "n_epochs": 3
            }
        }'
    ```

```json title="Response"
{
  "object": "fine_tuning.job",
  "id": "67ae81b59b08392687ea5f69",
  "model": "meta-llama/Llama-3.1-8B-Instruct",
  "created_at": 1739489717,
  "result_files": [],
  "status": "queued",
  "training_file": "67ae81587772e8a89c8fd5cf",
  "hyperparameters": {
    "batch_size": 4,
    "learning_rate_multiplier": 1,
    "n_epochs": 3
  },
  "method": {
    "type": "supervised",
    "supervised": {
      "batch_size": 4,
      "learning_rate_multiplier": 1,
      "n_epochs": 3
    }
  },
  "integrations": []
}
```

</div> 
</div>

### Retrieve a Fine-tuning job

`GET https://api.kluster.ai/v1/fine_tuning/jobs/{fine_tuning_job_id}`

Fetch details of a single Fine-tuning job by specifying its `fine_tuning_job_id`.

<div class="grid" markdown> 
<div markdown>

**Path parameters**

`fine_tuning_job_id` ++"string"++ <span class="required" markdown>++"required"++</span>

The ID of the Fine-tuning job to retrieve.

---

**Returns**

A [Fine-tuning job object](#fine-tuning-job-object).

</div> 
<div markdown>

=== "Python"

    ```python title="Example request"
    from openai import OpenAI
    client = OpenAI(
        base_url="https://api.kluster.ai/v1",
        api_key="INSERT_API_KEY"
    )
    job_details = client.fine_tuning.jobs.retrieve("INSERT_JOB_ID")
    print(job_details.to_dict())
    ```
=== "curl"

    ```bash title="Example request"
    curl -s https://api.kluster.ai/v1/fine_tuning/jobs/INSERT_JOB_ID \
        -H "Authorization: Bearer INSERT_API_KEY"
    ```

```json title="Response"
{
  "object": "fine_tuning.job",
  "id": "67ae81b59b08392687ea5f69",
  "model": "meta-llama/Llama-3.1-8B-Instruct",
  "created_at": 1739489717,
  "result_files": [],
  "status": "running",
  "training_file": "67ae81587772e8a89c8fd5cf",
  "hyperparameters": {
    "batch_size": 4,
    "learning_rate_multiplier": 1,
    "n_epochs": 3
  },
  "method": {
    "type": "supervised",
    "supervised": {
      "batch_size": 4,
      "learning_rate_multiplier": 1,
      "n_epochs": 3
    }
  },
  "integrations": []
}
```

</div> 
</div>

### List all Fine-tuning jobs

`GET https://api.kluster.ai/v1/fine_tuning/jobs`

Retrieve a paginated list of all Fine-tuning jobs.

<div class="grid" markdown> 
<div markdown>

**Query parameters**

`after` ++"string"++

A cursor for use in pagination.

---

`limit` ++"integer"++

A limit on the number of objects returned (1 to 100). Default is 20.

---

**Returns**

A paginated list of [Fine-tuning job objects](#fine-tuning-job-object).

</div> 
<div markdown>

=== "Python"

    ```python title="Example request"
    from openai import OpenAI

    client = OpenAI(
        base_url="https://api.kluster.ai/v1",
        api_key="INSERT_API_KEY"
    )

    jobs = client.fine_tuning.jobs.list(limit=3)
    print(jobs.to_dict())
    ```

=== "curl"

    ```bash title="Example request"
    curl -s https://api.kluster.ai/v1/fine_tuning/jobs \
        -H "Authorization: Bearer $API_KEY"
    ```

```Json title="Response"
{
  "object": "list",
  "data": [
    {
      "object": "fine_tuning.job",
      "id": "67ae81b59b08392687ea5f69",
      "model": "meta-llama/Llama-3.1-8B-Instruct",
      "created_at": 1739489717,
      "result_files": [],
      "status": "running",
      "training_file": "67ae81587772e8a89c8fd5cf",
      "hyperparameters": {
        "batch_size": 4,
        "learning_rate_multiplier": 1,
        "n_epochs": 3
      },
      "method": {
        "type": "supervised",
        "supervised": {
          "batch_size": 4,
          "learning_rate_multiplier": 1,
          "n_epochs": 3
        }
      },
      "integrations": []
    },
    {
      "object": "fine_tuning.job",
      "id": "67ae7f7d965c187d5cda039f",
      "model": "meta-llama/Llama-3.1-8B-Instruct",
      "created_at": 1739489149,
      "result_files": [],
      "status": "cancelled",
      "training_file": "67ae7f7c965c187d5cda0397",
      "hyperparameters": {
        "batch_size": 1,
        "learning_rate_multiplier": 1,
        "n_epochs": 10
      },
      "method": {
        "type": "supervised",
        "supervised": {
          "batch_size": 1,
          "learning_rate_multiplier": 1,
          "n_epochs": 10
        }
      },
      "integrations": []
    }
  ],
  "first_id": "67ae81b59b08392687ea5f69",
  "last_id": "67abefddbee1f22fb0a742ef",
  "has_more": true
}
```

</div> 
</div>

### Cancel a Fine-tuning job

`POST https://api.kluster.ai/v1/fine_tuning/jobs/{fine_tuning_job_id}/cancel`

To cancel a job that is in progress, send a `POST` request to the `cancel` endpoint with the job ID.

<div class="grid" markdown> 
<div markdown>

**Path parameters**

`fine_tuning_job_id` ++"string"++ <span class="required" markdown>++"required"++</span> 

The ID of the Fine-tuning job to cancel.

---

**Returns**

The [Fine-tuning job object](#fine-tuning-job-object) with updated status.

</div> 
<div markdown>

=== "Python"

    ```python title="Example request"
    from openai import OpenAI
    client = OpenAI(
        base_url="https://api.kluster.ai/v1",
        api_key="INSERT_API_KEY"
    )
    cancelled_job = client.fine_tuning.jobs.cancel("67ae7f7d965c187d5cda039f")
    print(cancelled_job.to_dict())
    ```
=== "curl"

    ```bash title="Example request"
    curl -X POST https://api.kluster.ai/v1/fine_tuning/jobs/67ae7f7d965c187d5cda039f/cancel \
        -H "Authorization: Bearer INSERT_API_KEY" \
        -H "Content-Type: application/json"
    ```

```json title="Response"
{
  "id": "67ae7f7d965c187d5cda039f",
  "object": "fine_tuning.job",
  "model": "meta-llama/Meta-Llama-3.1-8B-Instruct",
  "fine_tuned_model": null,
  "status": "cancelling",
  "created_at": 1738382911,
  "training_file": "file-123abc",
  "validation_file": null,
  "hyperparameters": {
    "batch_size": 4,
    "learning_rate_multiplier": 1,
    "n_epochs": 3
  },
  "metrics": {},
  "error": null
}
```

</div> 
</div>

### Fine-tuning job object 

<div class="grid" markdown> 
<div markdown>

`object` ++"string"++

The object type, which is always `fine_tuning.job`.

---

`id` ++"string"++

Unique identifier for the Fine-tuning job.

---

`model` ++"string"++

ID of the base model being fine-tuned.

---

`created_at` ++"integer"++

Unix timestamp (in seconds) when the Fine-tuning job was created.

---

`finished_at` ++"integer"++

Unix timestamp (in seconds) when the Fine-tuning job was completed.

---

`fine_tuned_model` ++"string or null"++

The ID of the resulting fine-tuned model if the job succeeded; otherwise `null`.

---

`result_files` ++"array"++

Array of file IDs associated with the Fine-tuning job results.

---

`status` ++"string"++

The status of the Fine-tuning job, e.g. `pending`, `running`, `succeeded`, `failed`, or `cancelled`.

---

`training_file` ++"string"++

ID of the uploaded file used for training data.

---

`hyperparameters` ++"object"++

Training hyperparameters used in the job (e.g., `batch_size`, `n_epochs`, `learning_rate_multiplier`).

---

`method` ++"object"++

Details about the Fine-tuning method used, including type and specific parameters.

---

`trained_tokens` ++"integer"++

The total number of tokens processed during training.

---

`integrations` ++"array"++

Array of integrations associated with the Fine-tuning job.

</div> 
<div markdown>

```json title="Example"
{
  "object": "fine_tuning.job",
  "id": "67ad3877720af9f9ba78b684",
  "model": "meta-llama/Llama-3.1-8B-Instruct",
  "created_at": 1739405431,
  "finished_at": 1739405521,
  "fine_tuned_model": "ft:meta-llama:Llama-3.1-8B-Instruct:personal:805b5d69",
  "result_files": [],
  "status": "succeeded",
  "training_file": "67ad38760272045e7006171b",
  "hyperparameters": {
    "batch_size": 4,
    "learning_rate_multiplier": 1,
    "n_epochs": 2
  },
  "method": {
    "type": "supervised",
    "supervised": {
      "batch_size": 4,
      "learning_rate_multiplier": 1,
      "n_epochs": 2
    }
  },
  "trained_tokens": 3065,
  "integrations": []
}
```

</div> 
</div>
--- END CONTENT ---

Doc-Content: https://docs.kluster.ai/get-started/get-api-key
--- BEGIN CONTENT ---
---
title: Get a kluster.ai API key
description: Follow step-by-step instructions to generate and manage API keys, enabling secure access to kluster's services and seamless integration with your applications.
---

# Generate your kluster.ai API key

The API key is a unique identifier that authenticates requests associated with your account. You must have at least one API key to access [kluster.ai](https://www.kluster.ai/){target=\_blank}'s services.

This guide will help you obtain an API key, the first step to leveraging kluster.ai's powerful and cost-effective AI capabilities.

## Create an account

If you haven't already created an account with kluster.ai, visit the [registration page](https://platform.kluster.ai/signup){target=\_blank} and take the following steps:

1. Enter your full name
2. Provide a valid email address
3. Create a secure password
4. Click the **Sign up** button

![Signup Page](/images/get-started/get-api-key/get-api-key-1.webp)

## Generate a new API key

After you've signed up or logged into the platform through the [login page](https://platform.kluster.ai/login){target=\_blank}, take the following steps:

1. Select **API Keys** on the left-hand side menu
2. In the [**API Keys**](https://platform.kluster.ai/apikeys){target=\_blank} section, click the **Issue New API Key** button

    ![Issue New API Key](/images/get-started/get-api-key/get-api-key-2.webp)

3. Enter a descriptive name for your API key in the popup, then click **Create Key**

    ![Generate API Key](/images/get-started/get-api-key/get-api-key-3.webp)

## Copy and secure your API key

1. Once generated, your API key will be displayed
2. Copy the key and store it in a secure location, such as a password manager

    !!! warning "Warning"
        For security reasons, you won't be able to view the key again. If lost, you will need to generate a new one.

![Copy API key](/images/get-started/get-api-key/get-api-key-4.webp)

!!! abstract "Security tips"
    - **Keep it secret** - do not share your API key publicly or commit it to version control systems
    - **Use environment variables** - store your API key in environment variables instead of hardcoding them
    - **Regenerate if compromised** - if you suspect your API key has been exposed, regenerate it immediately from the **API Keys** section

## Managing your API keys

The **API Key Management** section allows you to efficiently manage your kluster.ai API keys. You can create, view, and delete API keys by navigating to the [**API Keys**](https://platform.kluster.ai/apikeys){target=\_blank} section. Your API keys will be listed in the **API Key Management** section.

To delete an API key, take the following steps:

1. Locate the API key you wish to delete in the list
2. Click the trash bin icon ( :octicons-trash-24: ) in the **Actions** column
3. Confirm the deletion when prompted

![Delete API key](/images/get-started/get-api-key/get-api-key-5.webp)

!!! warning "Warning"
    Once deleted, the API key cannot be used again and you must generate a new one if needed.

## Next steps

Now that you have your API key, you can start integrating kluster.ai's LLMs into your applications. Refer to our [Getting Started](/get-started/start-api/){target=\_blank} guide for detailed instructions on using the API.
--- END CONTENT ---

Doc-Content: https://docs.kluster.ai/get-started/integrations/eliza
--- BEGIN CONTENT ---
---
title: Using eliza with the kluster.ai API
description: Learn how to integrate kluster.ai with eliza, a fast, lightweight, and flexible AI agent framework, to launch and configure your own AI agent chatbot. 
---

# Using eliza with the kluster.ai API

[eliza](https://elizaos.github.io/eliza/){target=\_blank} is an open-source framework designed to create and manage AI agents that can handle a variety of tasks, from simple chat interactions to more complex automation.

In this guide, you'll learn how to integrate [kluster.ai](https://www.kluster.ai/) into eliza so you can leverage its powerful models and quickly set up your AI-driven workflows.

## Prerequisites

Before starting, ensure you have the following kluster prerequisites:

- **A kluster.ai account** - sign up on the [kluster.ai platform](https://platform.kluster.ai/signup){target=\_blank} if you don't have one
- **A kluster.ai API key** - after signing in, go to the [**API Keys**](https://platform.kluster.ai/apikeys){target=\_blank} section and create a new key. For detailed instructions, check out the [Get an API key](/get-started/get-api-key/){target=\_blank} guide

Next, you can clone and install the eliza repository by following the installation instructions on the [eliza Quick Start guide](https://elizaos.github.io/eliza/docs/quickstart/){target=\_blank}. Pay careful attention to the eliza prerequisites, including the minimum supported versions of Node.js and pnpm. You can pause at the **Configure Environment** section in the Quick Start guide, as those steps will be addressed in this guide.

## Configure your environment

After you have eliza installed, it's simple to utilize kluster.ai with eliza. Only three main changes to the `.env` file are required. You can run the following command to generate a `.env` file from the provided example. 

```bash
cp .env.example .env
```

Then, set the following variables in the `.env` file: 

  - **OPENAI_API_KEY** - replace `INSERT_API_KEY` in the code below with your own kluster.ai API key. If you don't have one yet, refer to the [Get an API key guide](/get-started/get-api-key/){target=\_blank}
  - **OPENAI_API_URL** - use `https://api.kluster.ai/v1` to send requests to the kluster.ai endpoint
  - **OPENAI_DEFAULT_MODEL** - choose one of kluster.ai's available models based on your use case. Ensure that the model's full name starting with `klusterai/` is listed. For more details, see [kluster.ais models](/api-reference/reference/#list-supported-models){target=\_blank}

The OpenAI configuration section of your `.env` file should resemble the following:

```bash
# OpenAI Configuration
OPENAI_API_KEY=INSERT_KLUSTER_API_KEY
OPENAI_API_URL=https://api.kluster.ai/v1

# Community Plugin for OpenAI Configuration
OPENAI_DEFAULT_MODEL=klusterai/Meta-Llama-3.3-70B-Instruct-Turbo
```

## Run and interact with your first agent

Now that you've configured your environment properly you're ready to run your first agent! eliza comes with a number of characters that you can interact with by prompting or that can autonomously perform tasks like tweeting. This guide relies on the `Dobby` character for its minimal setup requirements. Other agents, particularly those that handle tweets, would necessitate additional steps, such as X login and similar information. 

By default, `Dobby` uses the `openai` model, which has been properly configured to rely on the kluster.ai API, but it doesn't hurt to double-check the `dobby.character.json` file under the `characters` folder. You should see the configuration start with the following:

```json
{
    "name": "Dobby",
    "clients": [],
    "modelProvider": "openai",
```

To run the `Dobby` agent, run the following command from the project root directory:

```bash
pnpm start --character="characters/dobby.character.json"
``` 

In another terminal window, run the following command to launch the web UI: 

```bash
pnpm start:client
```

You can now interact with Dobby by clicking on the **Chat** button and starting the conversation: 

![Chat with Dobby AI agent](/images/get-started/integrations/eliza/eliza-1.webp)

That's it! You've successfully integrated eliza with the kluster.ai API. You're now ready to harness the power of AI agents with the kluster.ai API!
--- END CONTENT ---

Doc-Content: https://docs.kluster.ai/get-started/integrations/langchain
--- BEGIN CONTENT ---
---
title: Integrate LangChain with kluster.ai
description: This guide walks you through integrating LangChain, a framework designed to simplify development of LLM powered-applications, with the kluster.ai API.
---

# Using LangChain with the kluster.ai API

This guide demonstrates how to integrate the `ChatOpenAI` class from the `langchain_openai` package with the [kluster.ai](https://www.kluster.ai/){target=\_blank} API. By combining [LangChain](https://www.langchain.com/){target=\_blank}s capabilities with kluster.ais large language models, you can seamlessly create powerful applications.

## Prerequisites

Before starting, ensure you have the following:

- **LangChain installed** - install the [`langchain` library](https://github.com/langchain-ai/langchain){target=\_blank}:

    ```bash
    pip install langchain
    ```

- **A kluster.ai account** - sign up on the [kluster.ai platform](https://platform.kluster.ai/signup){target=\_blank} if you don't have one
- **A kluster.ai API key** - after signing in, go to the [**API Keys**](https://platform.kluster.ai/apikeys){target=\_blank} section and create a new key. For detailed instructions, check out the [Get an API key](/get-started/get-api-key/){target=\_blank} guide

## Integrate with LangChain

It is very simple to integrate kluster.ai with LangChainjust point your `ChatOpenAI` instance to the correct base URL and configure a few settings.

  - **Base URL** - use `https://api.kluster.ai/v1` to send requests to the kluster.ai endpoint
  - **API key** - replace `INSERT_API_KEY` in the code below with your own kluster.ai API key. If you dont have one yet, refer to the [Get an API key guide](/get-started/get-api-key/){target=\_blank}
  - **Select your model** - choose one of kluster.ais available models based on your use case. For more details, see [kluster.ais models](/api-reference/reference/#list-supported-models){target=\_blank}

```python
from langchain_openai import ChatOpenAI

llm = ChatOpenAI(
    base_url="https://api.kluster.ai/v1",
    api_key="INSERT_API_KEY", # Replace with your actual API key
    model="klusterai/Meta-Llama-3.1-8B-Instruct-Turbo",
)

llm.invoke("What is the capital of Nepal?")
```

That's it! Youve successfully integrated LangChain with the kluster.ai API. Your configured LLM is now ready to deliver the full range of LangChain capabilities.
--- END CONTENT ---

Doc-Content: https://docs.kluster.ai/get-started/integrations/sillytavern
--- BEGIN CONTENT ---
---
title: Integrate SillyTavern with kluster.ai
description: This guide walks you through setting up SillyTavern, a customizable LLM interface, with the kluster.ai API to enable AI-powered conversations.
---

# How to integrate SillyTavern with kluster.ai

This guide will help you set up and configure [SillyTavern](https://sillytavernai.com/){target=\_blank}, a customizable LLM interface, with the [kluster.ai](https://www.kluster.ai/){target=\_blank} API. Follow the steps below to integrate these tools seamlessly.

## Prerequisites

Before starting, ensure you have the following:

- **SillyTavern installed** - for installation instructions, refer to the SillyTavern [Installation](https://docs.sillytavern.app/installation/){target=\_blank} guide
- **A kluster.ai account** - sign up on the [kluster.ai platform](https://platform.kluster.ai/signup){target=\_blank} if you don't have one
- **A kluster.ai API key** - after signing in, go to the [**API Keys**](https://platform.kluster.ai/apikeys){target=\_blank} section and create a new key. For detailed instructions, check out the [Get an API key](/get-started/get-api-key/){target=\_blank} guide

## Configure SillyTavern to use kluster.ai

1. Launch SillyTavern and open it in your browser at `http://127.0.0.1:8000/` (default port)
2. Click on the **API Connections** icon (plug) in the top navigation menu
3. In the **API** drop-down menu, select **Chat Completion**
4. In the **Chat Completion Source** option, choose **Custom (OpenAI-compatible)**
5. Enter the **kluster.ai** API endpoint in the **Custom Endpoint (Base URL)** field:

    ```text
    https://api.kluster.ai/v1
    ```

    There should be no trailing slash (`/`) at the end of the URL

6. Paste your **kluster.ai** API Key into the designated field
7. **Enter a Model ID**. For this example, you can enter:

    ```text
    klusterai/Meta-Llama-3.3-70B-Instruct-Turbo
    ```

8. Click the **Connect** button. If you've configured the API correctly, you should see a ** Valid** message next to the button
9. Select one of the kluster.ai-supported models from the **Available Models** drop-down menu

![](/images/get-started/integrations/sillytavern/sillytavern-1.webp)

That's it! You're now ready to start chatting with your bot powered by kluster.ai.

## Test the connection

Now that you've configured kluster.ai with SillyTavern, you can test the API connection by starting a new conversation.

Follow these steps to get started:

1. Click the menu icon on the bottom-left corner of the page
2. Select **Start New Chat** to open a new chat with the model
3. Type a message in the **Type a message** bar at the bottom and send it
4. Verify that the chatbot has returned a response successfully

![](/images/get-started/integrations/sillytavern/sillytavern-2.webp)

!!! tip "Troubleshooting"
    If you encounter errors, revisit the [configuration instructions](#configure-sillytavern-to-use-klusterai) and double-check your API key and base URL and that you've received a **Valid** response after connecting the API (see step 8).
--- END CONTENT ---

Doc-Content: https://docs.kluster.ai/get-started/openai-compatibility
--- BEGIN CONTENT ---
---
title: Compatibility with OpenAI client libraries
description: Learn how kluster.ai is fully compatible with OpenAI client libraries, enabling seamless integration with your existing applications.
---

# OpenAI compatibility

The [kluster.ai](https://www.kluster.ai/){target=\_blank} API is compatible with [OpenAI](https://platform.openai.com/docs/api-reference/introduction){target=\_blank}'s API and SDKs, allowing seamless integration into your existing applications.

If you already have an application running with the OpenAI client library, you can easily switch to kluster.ai's API with minimal changes. This ensures a smooth transition without the need for significant refactoring or rework.

## Configuring OpenAI to use kluster.ai's API

To start using kluster.ai with OpenAI's client libraries, set your [API key](/get-started/get-api-key/){target=\_blank} and change the base URL to `https://api.kluster.ai/v1`:

=== "Python"

    ```python
    from openai import OpenAI
    import json

    client = OpenAI(
        base_url="https://api.kluster.ai/v1",
        api_key="INSERT_API_KEY",  # Replace with your actual API key
    )
    ```

## Unsupported OpenAI features

While kluster.ai's API is largely compatible with OpenAI's, the following sections outline the specific features and fields that are currently unsupported.

### Chat completions endpoint

When creating a chat completion via the [`POST https://api.kluster.ai/v1/chat/completions` endpoint](/api-reference/reference#create-chat-completion){target=\_blank}, the following request parameters are not supported:

- `messages[].name` - attribute in `system`, `user`, and `assistant` type message objects
- `messages[].refusal` - attribute in `assistant` type message objects
- `messages[].audio` - attribute in `assistant` type message objects
- `messages[].tool_calls` - attribute in `assistant` type message objects
- `store`
- `n`
- `modalities`
- `response_format`
- `service_tier`
- `stream_options`
- `tools`
- `tool_choice`
- `parallel_tool_calls`

The following request parameters are *deprecated*:

- `messages[].function_call` - attribute in `assistant` type message objects <!-- TODO: Once `messages[].tool_calls` is supported, this should be updated to use `messages[].tool_calls instead -->
- `max_tokens` - use `max_completion_tokens` instead
- `function_call` <!-- TODO: Once `tool_choice` is supported, this should be updated to use `tool_choice` instead -->
- `functions` <!-- TODO: Once `tools` is supported, this should be updated to use `tools` instead -->

For more information on these parameters, refer to [OpenAI's API documentation on creating chat completions](https://platform.openai.com/docs/api-reference/chat/create){target=_blank}.

### Chat completion object

The following fields of the [chat completion object](/api-reference/reference/#chat-completion-object) are not supported:

- `system_fingerprint`
- `usage.completion_tokens_details`
- `usage.prompt_tokens_details`

For more information on these parameters, refer to [OpenAI's API documentation on the chat completion object](https://platform.openai.com/docs/api-reference/chat/object){target=_blank}.
--- END CONTENT ---

Doc-Content: https://docs.kluster.ai/get-started/start-api
--- BEGIN CONTENT ---
---
title: Start building with the kluster.ai API
description: The kluster.ai API getting started guide provides examples and instructions for submitting and managing Batch jobs using kluster.ai's OpenAI-compatible API.
---

# Start using the kluster.ai API

The [kluster.ai](https://www.kluster.ai/){target=\_blank} API provides a straightforward way to work with Large Language Models (LLMs) at scale. It is compatible with OpenAI's API and SDKs, making it easy to integrate into your existing workflows with minimal code changes.

This guide provides copy-and-paste examples for both Python and curl (although all OpenAI's SDKs are supported) and detailed explanations to help you get started quickly.

## Install prerequisites

The OpenAI Python library (version 1.0.0 or higher) is recommended, which can be installed with:

```bash
pip install "openai>=1.0.0"
```

## Get your API key

Navigate to the kluster.ai developer console [**API Keys**](https://platform.kluster.ai/apikeys){target=\_blank} section and create a new key from there. You'll need this for all API requests.

For step-by-step instructions, refer to the [Get an API key](/get-started/get-api-key){target=\_blank} guide.

## Batch job workflow overview

Working with Batch jobs in the kluster.ai API involves the following steps:

1. **Create Batch job file** - prepare a JSON Lines file containing one or more chat completion requests to be executed in the batch
2. **Upload Batch job file** - upload the file to kluster.ai to receive a unique file ID
3. **Start the Batch job** - initiate a new Batch job using the file ID
4. **Monitor job progress** - track the status of your Batch job to ensure successful completion
5. **Retrieve results** - once the job finishes, access and process the results as needed

This streamlined process enables efficient handling of large-scale requests.

In addition to these core steps, this guide will give you hands-on experience with:

- **Cancel a Batch job** - cancel an ongoing Batch job if necessary before it completes
- **List all Batch jobs** - review all of your Batch jobs

## Create Batch jobs as JSON files

To take the first step in the Batch job workflow, you'll need to assemble your Batch requests and add them to a [JSON Lines](https://jsonlines.org/) file (`.jsonl`).

Each request needs to include the following arguments:

- `custom_id` ++"string"++ - a unique request ID that will be used to match outputs to inputs
- `method` ++"string"++ - the HTTP method to be used for the request. Currently, only `POST` is supported
- `url` ++"string"++ -  the `/v1/chat/completions` endpoint
- `body` ++"object"++ - a request body containing:
    - `model` ++"string"++ <span class="required" markdown>++"required"++</span> - name of the `model` to use, can be one of:
        - `klusterai/Meta-Llama-3.1-8B-Instruct-Turbo`
        - `klusterai/Meta-Llama-3.1-405B-Instruct-Turbo`
        - `klusterai/Meta-Llama-3.3-70B-Instruct-Turbo`
        - `deepseek-ai/DeepSeek-R1`

        !!! tip
            You can see the full list of available models programmatically using the [list supported models](#list-supported-models) endpoint.

    - `messages` ++"array"++ <span class="required" markdown>++"required"++</span> - a list of chat messages (`system`, `user`, or `assistant` roles)
    - Any optional [chat completion parameters](/api-reference/reference/#create-chat-completion){target=\_blank}, such as `temperature`, `max_completion_tokens`, etc.

The following examples generate requests and save them in a JSONL file, ready for upload and processing.

=== "Python"

    ```python
    from openai import OpenAI
    import json

    client = OpenAI(
        base_url="https://api.kluster.ai/v1",
        api_key="INSERT_API_KEY",  # Replace with your actual API key
    )

    requests = [
        {
            "custom_id": "request-1",
            "method": "POST",
            "url": "/v1/chat/completions",
            "body": {
                "model": "klusterai/Meta-Llama-3.1-8B-Instruct-Turbo",
                "messages": [
                    {"role": "system", "content": "You are a helpful assistant."},
                    {"role": "user", "content": "What is the capital of Argentina?"},
                ],
                "max_completion_tokens": 1000,
            },
        },
        {
            "custom_id": "request-2",
            "method": "POST",
            "url": "/v1/chat/completions",
            "body": {
                "model": "klusterai/Meta-Llama-3.3-70B-Instruct-Turbo",
                "messages": [
                    {"role": "system", "content": "You are a maths tutor."},
                    {"role": "user", "content": "Explain the Pythagorean theorem."},
                ],
                "max_completion_tokens": 1000,
            },
        },
        {
            "custom_id": "request-4",
            "method": "POST",
            "url": "/v1/chat/completions",
            "body": {
                "model": "klusterai/Meta-Llama-3.3-70B-Instruct-Turbo",
                "messages": [
                    {
                        "role": "system",
                        "content": "You are a multilingual, experienced maths tutor.",
                    },
                    {
                        "role": "user",
                        "content": "Explain the Pythagorean theorem in Spanish",
                    },
                ],
                "max_completion_tokens": 1000,
            },
        },
        # Additional tasks can be added here
    ]

    # Save tasks to a JSONL file (newline-delimited JSON)
    file_name = "mybatchtest.jsonl"
    with open(file_name, "w") as file:
        for request in requests:
            file.write(json.dumps(request) + "\n")
    ```

=== "curl"

    ```bash
    cat << EOF > mybatchtest.jsonl
    {"custom_id": "request-1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "klusterai/Meta-Llama-3.1-8B-Instruct-Turbo", "messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "What is the capital of Argentina?"}],"max_completion_tokens":1000}}
    {"custom_id": "request-2", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "klusterai/Meta-Llama-3.3-70B-Instruct-Turbo", "messages": [{"role": "system", "content": "You are an experienced maths tutor."}, {"role": "user", "content": "Explain the Pythagorean theorem."}],"max_completion_tokens":1000}}
    {"custom_id": "request-3", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "klusterai/Meta-Llama-3.1-405B-Instruct-Turbo", "messages": [{"role": "system", "content": "You are an astronomer."}, {"role": "user", "content": "What is the distance between the Earth and the Moon"}],"max_completion_tokens":1000}}
    {"custom_id": "request-4", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "klusterai/Meta-Llama-3.3-70B-Instruct-Turbo", "messages":[{"role": "system", "content": "You are a multilingual, experienced maths tutor."}, {"role": "user", "content": "Explain the Pythagorean theorem in Spanish"}],"max_completion_tokens":1000}}
    EOF
    ```

## Upload Batch job files

Upload your [JSON Lines](https://jsonlines.org/){target=\_blank} file to the `files` endpoint along with the intended purpose of the upload. For Batch jobs, set the `purpose` value to `"batch"`.

The response will contain an `id` field; save this value as you'll need it in the next step, where it's referred to as `input_file_id`.

!!! note
    You can also view all your uploaded files in the [**Files** tab](https://platform.kluster.ai/files){target=\_blank} of the kluster.ai platform.

=== "Python"

    ```python title="Example request"

    batch_input_file = client.files.create(
        file=open(file_name, "rb"),
        purpose="batch"
    )
    ```

=== "curl"

    ```bash title="Example request"
    curl -s https://api.kluster.ai/v1/files \
        -H "Authorization: Bearer $API_KEY" \
        -H "Content-Type: multipart/form-data" \
        -F "file=@mybatchtest.jsonl" \
        -F "purpose=batch"
    ```

```Json title="Response"
{
    "id": "myfile-123",
    "bytes": 2797,
    "created_at": "1733832768",
    "filename": "mybatchtest.jsonl",
    "object": "file",
    "purpose": "batch"
}
```

## Submit a Batch job

Next, submit a Batch job by calling the `batches` endpoint and providing the `id` of the uploaded Batch job file (from the previous section) as the [`input_file_id`, and additional parameters](/api-reference/reference/#submit-a-batch-job){target=\_blank} to specify the job's configuration.

The response includes an `id` that can be used to monitor the job's progress, as demonstrated in the next section.

=== "Python"

    ```python title="Example request"

    batch_request = client.batches.create(
        input_file_id=batch_input_file.id,
        endpoint="/v1/chat/completions",
        completion_window="24h",
    )
    ```

=== "curl"

    ```bash title="Example request"
    curl -s https://api.kluster.ai/v1/batches \
        -H "Authorization: Bearer $API_KEY" \
        -H "Content-Type: application/json" \
        -d '{
        "input_file_id": "myfile-123",
        "endpoint": "/v1/chat/completions",
        "completion_window": "24h"
        }'
    ```

```Json title="Response"
{
    "id": "mybatch-123",
    "completion_window": "24h",
    "created_at": 1733832777,
    "endpoint": "/v1/chat/completions",
    "input_file_id": "myfile-123",
    "object": "batch",
    "status": "validating",
    "cancelled_at": null,
    "cancelling_at": null,
    "completed_at": null,
    "error_file_id": null,
    "errors": null,
    "expired_at": null,
    "expires_at": 1733919177,
    "failed_at": null,
    "finalizing_at": null,
    "in_progress_at": null,
    "metadata": {},
    "output_file_id": null,
    "request_counts": {
        "completed": 0,
        "failed": 0,
        "total": 0
    }
}
```

## Monitor job progress

To monitor your Batch job's progress, make periodic requests to the `batches` endpoint using the `id` of the Batch request (from the previous section) as the [`batch_id`](/api-reference/reference/#retrieve-a-batch){target=\_blank} to check its status. The job is complete when the `status` field returns `"completed"`.

To see a complete list of the supported statuses, refer to the [Retrieve a batch](/api-reference/reference/#retrieve-a-batch){target=\_blank} API reference page.

!!! note
    You can also monitor jobs in the [**Batch** tab](https://platform.kluster.ai/batch) of the kluster.ai platform UI.

=== "Python"

    ```python title="Example request"
    import time

    # Poll the Batch status until it's complete
    while True:
        batch_status = client.batches.retrieve(batch_request.id)
        print("Batch status: {}".format(batch_status.status))
        print(
            f"Completed tasks: {batch_status.request_counts.completed} / {batch_status.request_counts.total}"
        )

        if batch_status.status.lower() in ["completed", "failed", "cancelled"]:
            break

        time.sleep(10)  # Wait for 10 seconds before checking again
    ```

=== "curl"

    ```bash title="Example request"
    curl -s https://api.kluster.ai/v1/batches/mybatch-123 \
        -H "Authorization: Bearer $API_KEY" \
        -H "Content-Type: application/json"
    ```

```Json title="Response"
{
    "id": "mybatch-123",
    "object": "batch",
    "endpoint": "/v1/chat/completions",
    "errors": null,
    "input_file_id": "myfile-123",
    "completion_window": "24h",
    "status": "completed",
    "output_file_id": "myfile-123-output",
    "error_file_id": null,
    "created_at": "1733832777",
    "in_progress_at": "1733832777",
    "expires_at": "1733919177",
    "finalizing_at": "1733832781",
    "completed_at": "1733832781",
    "failed_at": null,
    "expired_at": null,
    "cancelling_at": null,
    "cancelled_at": null,
    "request_counts": {
        "total": 4,
        "completed": 4,
        "failed": 0
    },
    "metadata": {}
}
```

## Retrieve results

To retrieve the content of your Batch jobs output file, send a request to the `files` endpoint specifying the `output_file_id`, which is returned from querying the Batch's status (from the previous section).

The output file will be a JSONL file, where each line contains the `custom_id` from your input file request and the corresponding response.

=== "Python"

    ```python title="Example request"
    # Check if the Batch completed successfully
    if batch_status.status.lower() == "completed":
        # Retrieve the results
        result_file_id = batch_status.output_file_id
        results = client.files.content(result_file_id).content

        # Save results to a file
        result_file_name = "batch_results.jsonl"
        with open(result_file_name, "wb") as file:
            file.write(results)
        print(f"Results saved to {result_file_name}")
    else:
        print(f"Batch failed with status: {batch_status.status}")
    ```

=== "curl"

    ```bash title="Example request"
    curl -s https://api.kluster.ai/v1/files/kluster-output-file-123/content \
        -H "Authorization: Bearer $API_KEY" > batch_output.jsonl
    ```

## List all Batch jobs

To list all of your Batch jobs, send a request to the `batches` endpoint without specifying a `batch_id`. To constrain the query response, you can also use a `limit` parameter.

=== "Python"

    ```python title="Example request"
    from openai import OpenAI

    # Configure OpenAI client
    client = OpenAI(
        base_url="https://api.kluster.ai/v1", 
        api_key="INSERT_API_KEY" # Replace with your actual API key
    )

    print(client.batches.list(limit=2).to_dict())
    ```

=== "curl"

    ```bash title="Example request" 
    curl -s https://api.kluster.ai/v1/batches \
        -H "Authorization: Bearer $API_KEY"
    ```

```Json title="Response"
{
"object": "list",
"data": [
    {
    "id": "mybatch-123",
    "object": "batch",
    "endpoint": "/v1/chat/completions",
    "errors": null,
    "input_file_id": "myfile-123",
    "completion_window": "24h",
    "status": "completed",
    "output_file_id": "myfile-123-output",
    "error_file_id": null,
    "created_at": "1733832777",
    "in_progress_at": "1733832777",
    "expires_at": "1733919177",
    "finalizing_at": "1733832781",
    "completed_at": "1733832781",
    "failed_at": null,
    "expired_at": null,
    "cancelling_at": null,
    "cancelled_at": null,
    "request_counts": {
        "total": 4,
        "completed": 4,
        "failed": 0
    },
    "metadata": {}
    },
{ ... },
],
"first_id": "mybatch-123",
"last_id": "mybatch-789",
"has_more": false,
"count": 1,
"page": 1,
"page_count": -1,
"items_per_page": 9223372036854775807
}
```

## Cancel a Batch job

To cancel a Batch job currently in progress, send a request to the `cancel` endpoint with your `batch_id`. Note that cancellation may take up to 10 minutes to complete, during which time the status will show as `cancelling`. Once complete, the status will show as `cancelled`.

=== "Python"

    ```python title="Example"
    from openai import OpenAI

    client = OpenAI(
        base_url="https://api.kluster.ai/v1",  
        api_key="INSERT_API_KEY" # Replace with your actual API key
    )
    client.batches.cancel("mybatch-123") # Replace with your Batch id
    ```

=== "curl"

    ```bash title="Example"
    curl -s https://api.kluster.ai/v1/batches/$BATCH_ID/cancel \
        -H "Authorization: Bearer $API_KEY" \
        -H "Content-Type: application/json" \
        -X POST
    ```

```Json title="Response"
{
    "id": "mybatch-123",
    "object": "batch",
    "endpoint": "/v1/chat/completions",
    "errors": null,
    "input_file_id": "myfile-123",
    "completion_window": "24h",
    "status": "cancelling",
    "output_file_id": "myfile-123-output",
    "error_file_id": null,
    "created_at": "1730821906",
    "in_progress_at": "1730821911",
    "expires_at": "1730821906",
    "finalizing_at": null,
    "completed_at": null,
    "failed_at": null,
    "expired_at": null,
    "cancelling_at": "1730821906",
    "cancelled_at": null,
    "request_counts": {
        "total": 3,
        "completed": 3,
        "failed": 0
    },
    "metadata": {}
}
```

## Summary

Congratulations! You now have all the tools needed to work with the kluster.ai Batch API. In this guide, you've learned how to:

- Prepare and submit Batch jobs with structured request inputs
- Track your jobs' progress in real-time
- Retrieve and handle job results
- View and manage your Batch jobs
- Cancel jobs when needed
- View supported models

The kluster.ai Batch API is designed to efficiently and reliably handle your large-scale LLM workloads. Do you have questions or suggestions? The [support](mailto:support@kluster.ai){target=\_blank} team would love to hear from you.
--- END CONTENT ---

