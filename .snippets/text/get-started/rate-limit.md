The following limits apply to API requests based on [your plan](https://platform.kluster.ai/plans){target=\_blank}:

=== "Trial"

    |             Model             | Context size<br>[tokens] | Max output<br>[tokens] | Max batch<br>requests | Concurrent<br>requests | Requests<br>per minute | Hosted fine-tuned<br>models |
    |:-----------------------------:|:------------------------:|:----------------------:|:---------------------:|:----------------------:|:----------------------:|:---------------------------:|
    |**DeepSeek-R1**|32k|4k|1000|20|30|1|
    |**DeepSeek-V3-0324**|32k|4k|1000|20|30|1|
    |**Gemma 3 27B**|32k|4k|1000|20|30|1|
    |**Meta Llama 3.1 8B**|32k|4k|1000|20|30|1|
    |**Meta Llama 3.3 70B**|32k|4k|1000|20|30|1|
    |**Meta Llama 4 Maverick**|32k|4k|1000|20|30|1|
    |**Meta Llama 4 Scout**|32k|4k|1000|20|30|1|
    |**Mistral NeMo**|32k|4k|1000|20|30|1|
    |**Qwen2.5-VL 7B**|32k|4k|1000|20|30|1|
    |**Qwen3-235B-A22B**|32k|4k|1000|20|30|1|



=== "Core"

    |             Model             | Context size<br>[tokens] | Max output<br>[tokens] | Max batch<br>requests | Concurrent<br>requests | Requests<br>per minute | Hosted fine-tuned<br>models |
    |:-----------------------------:|:------------------------:|:----------------------:|:---------------------:|:----------------------:|:----------------------:|:---------------------------:|
    |**DeepSeek-R1**|163k|163k|100k|100|600|10|
    |**DeepSeek-V3-0324**|163k|163k|100k|100|600|10|
    |**Gemma 3 27B**|64k|8k|100k|100|600|10|
    |**Meta Llama 3.1 8B**|131k|131k|100k|100|600|10|
    |**Meta Llama 3.3 70B**|131k|131k|100k|100|600|10|
    |**Meta Llama 4 Maverick**|1M|1M|100k|100|600|10|
    |**Meta Llama 4 Scout**|131k|131k|100k|100|600|10|
    |**Mistral NeMo**|131k|131k|100k|100|600|10|
    |**Qwen2.5-VL 7B**|32k|32k|100k|100|600|10|
    |**Qwen3-235B-A22B**|40k|40k|100k|100|600|10|



=== "Scale"

    |             Model             | Context size<br>[tokens] | Max output<br>[tokens] | Max batch<br>requests | Concurrent<br>requests | Requests<br>per minute | Hosted fine-tuned<br>models |
    |:-----------------------------:|:------------------------:|:----------------------:|:---------------------:|:----------------------:|:----------------------:|:---------------------------:|
    |**DeepSeek-R1**|163k|163k|500k|100|1200|25|
    |**DeepSeek-V3-0324**|163k|163k|500k|100|1200|25|
    |**Gemma 3 27B**|64k|8k|500k|100|1200|25|
    |**Meta Llama 3.1 8B**|131k|131k|500k|100|1200|25|
    |**Meta Llama 3.3 70B**|131k|131k|500k|100|1200|25|
    |**Meta Llama 4 Maverick**|1M|1M|500k|100|1200|25|
    |**Meta Llama 4 Scout**|131k|131k|500k|100|1200|25|
    |**Mistral NeMo**|131k|131k|500k|100|1200|25|
    |**Qwen2.5-VL 7B**|32k|32k|500k|100|1200|25|
    |**Qwen3-235B-A22B**|40k|40k|500k|100|1200|25|



=== "Enterprise"

    |             Model             | Context size<br>[tokens] | Max output<br>[tokens] | Max batch<br>requests | Concurrent<br>requests | Requests<br>per minute | Hosted fine-tuned<br>models |
    |:-----------------------------:|:------------------------:|:----------------------:|:---------------------:|:----------------------:|:----------------------:|:---------------------------:|
    |**DeepSeek-R1**|163k|163k|Unlimited|100|Unlimited|Unlimited|
    |**DeepSeek-V3-0324**|163k|163k|Unlimited|100|Unlimited|Unlimited|
    |**Gemma 3 27B**|64k|8k|Unlimited|100|Unlimited|Unlimited|
    |**Meta Llama 3.1 8B**|131k|131k|Unlimited|100|Unlimited|Unlimited|
    |**Meta Llama 3.3 70B**|131k|131k|Unlimited|100|Unlimited|Unlimited|
    |**Meta Llama 4 Maverick**|1M|1M|Unlimited|100|Unlimited|Unlimited|
    |**Meta Llama 4 Scout**|131k|131k|Unlimited|100|Unlimited|Unlimited|
    |**Mistral NeMo**|131k|131k|Unlimited|100|Unlimited|Unlimited|
    |**Qwen2.5-VL 7B**|32k|32k|Unlimited|100|Unlimited|Unlimited|
    |**Qwen3-235B-A22B**|40k|40k|Unlimited|100|Unlimited|Unlimited|

