# kluster.ai llms-full.txt
kluster.ai. kluster.ai provides the technology to verify and trust AI responses in real time. Developers can validate outputs, detect hallucinations, and ensure response reliability across any model, with minimal integration effort.

## Generated automatically. Do not edit directly.

Documentation: https://docs.kluster.ai

## List of doc pages:
Doc-Page: https://raw.githubusercontent.com/kluster-ai/docs/main/verify/code/examples/cursor-firebase-nextjs.md
Doc-Page: https://raw.githubusercontent.com/kluster-ai/docs/main/verify/code/integrations.md
Doc-Page: https://raw.githubusercontent.com/kluster-ai/docs/main/verify/code/overview.md
Doc-Page: https://raw.githubusercontent.com/kluster-ai/docs/main/verify/code/quickstart.md
Doc-Page: https://raw.githubusercontent.com/kluster-ai/docs/main/verify/code/tools.md
Doc-Page: https://raw.githubusercontent.com/kluster-ai/docs/main/verify/get-api-key.md
Doc-Page: https://raw.githubusercontent.com/kluster-ai/docs/main/verify/openai-compatibility.md
Doc-Page: https://raw.githubusercontent.com/kluster-ai/docs/main/verify/overview.md
Doc-Page: https://raw.githubusercontent.com/kluster-ai/docs/main/verify/quickstart/reliability.md
Doc-Page: https://raw.githubusercontent.com/kluster-ai/docs/main/verify/reliability/chat-completion.md
Doc-Page: https://raw.githubusercontent.com/kluster-ai/docs/main/verify/reliability/overview.md
Doc-Page: https://raw.githubusercontent.com/kluster-ai/docs/main/verify/reliability/verify-api.md
Doc-Page: https://raw.githubusercontent.com/kluster-ai/docs/main/verify/reliability/workflow-integrations.md

## Full content for each doc page

Doc-Content: https://docs.kluster.aiverify/code/examples/cursor-firebase-nextjs/
--- BEGIN CONTENT ---
---
title: Cursor: Firebase Authentication with Next.js
description: See how Verify Code catches critical issues in real-time while migrating from localStorage to Firebase authentication
---

# Cursor: Firebase authentication

Learn how [Verify Code](/verify/code/) acts as your safety net when using Cursor AI to write code. This tutorial demonstrates a real migration from localStorage to Firebase authentication in a buy-sell e-commerce platform, showcasing how AI plans can go wrong and the four critical issues Verify Code caught.

## Prerequisites

-- **A kluster.ai account**: Sign up on the [kluster.ai platform](https://platform.kluster.ai/signup){target=\_blank} if you don't have one.
- **A kluster.ai API key**: After signing in, go to the [**API Keys**](https://platform.kluster.ai/apikeys){target=\_blank} section and create a new key. For detailed instructions, check out the [Get an API key](/verify/get-api-key/){target=\_blank} guide.

- [Cursor IDE installed](https://cursor.com/downloads){target="_blank"}

## Setup

Getting Verify Code working in Cursor takes just one click. Visit our [quickstart guide](/verify/code/quickstart/) and click **Add to Cursor** for automatic installation.

For manual setup or other IDEs, see our [integration guides](/verify/code/integrations/).

## Next.js e-commerce

We built a buy-sell e-commerce platform where users post articles for purchase. The app initially used `localStorage` for user authentication, but we decided to **migrate to Firebase** for better security and user management.

We used **Gemini 2.5 Flash** (Cursor's standard free model) in **agentic mode** to handle the migration while Verify Code monitored the changes.

## The prompt and AI's plan

Our prompt was to _implement a real user login with Firebase_ + Firebase default app setting file.

![Cursor showing e-commerce app and AI's Firebase implementation plan](/images/verify/code/examples/cursor/example-cursor-1.webp)

The AI responded confidently with a detailed 5-step plan:

1. **Create Firebase initialization file**: Set up `src/lib/firebase.ts`.
2. **Install Firebase**: Add the npm package.
3. **Update authentication context**: Modify `src/contexts/AuthContext.tsx`.
4. **Update Login API route**: Handle Firebase in `src/app/api/auth/login/route.ts`.
5. **Update Signup API route**: Handle Firebase in `src/app/api/auth/signup/route.ts`.


## Plan vs. implementation outcomes

The AI's 5-step implementation plan achieved just 20% success rate, with four critical failures.

| Step | Task | Result |
|------|------|--------|
| 1 | Firebase initialization | ❌ Failed - Incomplete implementation |
| 2 | Install Firebase | ✅ Success |
| 3 | Update AuthContext | ❌ Failed - Architecture regression |
| 4 | Update login API | ❌ Failed - Breaking changes |
| 5 | Update signup API | ❌ Failed - Security vulnerabilities |

The AI got confused between steps 3-4, couldn't decide between direct Firebase calls vs API routes, kept reverting working code, and made **multiple correction attempts** throughout the implementation.

## Key issues caught by Verify Code

The AI made four key mistakes along the way, escalating from simple import issues to reverting the entire Firebase implementation. Below, we examine each catch.

### Incomplete implementation

What happened? AI created Firebase config but missed the actual authentication setup.

```typescript
// src/lib/firebase.ts - Step 1 attempt
import { initializeApp } from "firebase/app";
import { getAnalytics } from "firebase/analytics";

const firebaseConfig = { /* config */ };
const app = initializeApp(firebaseConfig);
const analytics = getAnalytics(app); // ❌ No auth setup
```

Verify Code provided the following response:

---

**P1 - Intent (High)**: AI did not implement the actual user login functionality as requested.

**Why this matters**: Running the app would cause runtime errors when trying to authenticate - the `auth` object simply doesn't exist.

**Correct approach**:
```typescript
// src/lib/firebase.ts - Corrected
import { initializeApp } from "firebase/app";
import { getAnalytics } from "firebase/analytics";
import { getAuth } from "firebase/auth"; // ✅ Added

const firebaseConfig = { /* config */ };
const app = initializeApp(firebaseConfig);
const analytics = getAnalytics(app);
const auth = getAuth(app); // ✅ Initialize auth

export { app, auth, analytics }; // ✅ Export auth
```

---

### Breaking changes

What happened? AI removed the working Firebase login logic from the API route.

```typescript
// src/app/api/auth/login/route.ts - Working version
export async function POST(req: NextRequest) {
  const { email, password } = await req.json();
  const userCredential = await signInWithEmailAndPassword(auth, email, password);
  return NextResponse.json({ message: "Login successful", user: user.toJSON() });
}
```

```typescript
// AI's "fix" - Step 4 attempt
export async function POST(req: NextRequest) {
  return NextResponse.json({ message: "Not used for direct login" }); // ❌ Removed logic
}
```

The screenshot below shows Cursor's interface with Verify Code's alert panel displaying a critical P1 Intent violation. The alert clearly identifies that the AI removed working Firebase authentication logic from the login API route, replacing functional code with a placeholder response.

![Verify Code alert showing breaking changes detected in login API route](/images/verify/code/examples/cursor/example-cursor-2.webp){ width="75%" }

Verify Code provided the following response:

---

**P1 - Intent (High)**: AI removed Firebase login implementation instead of maintaining it.

**Why this matters**: AI replaced working authentication logic with a non-functional placeholder response, breaking the API contract.

**Correct approach**: Keep the original working Firebase authentication logic.

---

### Security vulnerabilities

What happened? AI created a signup endpoint without input validation.

```typescript
// src/app/api/auth/signup/route.ts - Step 5 attempt
export async function POST(request: NextRequest) {
  const body = await request.json();
  const { email, password, name } = body; // ❌ No validation!
  
  const userCredential = await createUserWithEmailAndPassword(auth, email, password);
}
```

Verify Code provided the following response:

---

**P3 - Security (High)**: Lack of input validation for signup data.

**Why this matters**: Malformed data could crash the server, invalid emails cause Firebase errors, weak passwords accepted.

**Correct approach**:

```typescript
import { SignupSchema } from '@/lib/validation';

export async function POST(request: NextRequest) {
  const body = await request.json();
  
  // ✅ Validate input
  const validationResult = SignupSchema.safeParse(body);
  if (!validationResult.success) {
    return NextResponse.json({
      error: 'Validation failed',
      details: validationResult.error.issues
    }, { status: 400 });
  }
  
  const { email, password, name } = validationResult.data;
  const userCredential = await createUserWithEmailAndPassword(auth, email, password);
}
```

---

### Architecture regression

What happened? AI reverted the Firebase authentication logic back to the `localStorage` approach.

```typescript
// src/contexts/AuthContext.tsx - Correct Firebase approach
const login = async (email: string, password: string) => {
  const userCredential = await signInWithEmailAndPassword(auth, email, password);
  return !!userCredential.user;
};
```

```typescript
// AI reverted to original localStorage approach
const [user, setUser] = useState(() => {
  const savedUser = localStorage.getItem('user'); // ❌ Back to localStorage!
  return savedUser ? JSON.parse(savedUser) : null;
});

const login = async (email: string, password: string) => {
  const response = await fetch('/api/auth/login', { // ❌ API calls instead of Firebase
    method: 'POST',
    body: JSON.stringify({ email, password })
  });
};
```

The screenshot below displays Cursor with Verify Code's alert highlighting a P1 Intent violation. The alert detects that the AI has regressed the authentication architecture by reverting from the Firebase implementation back to the original localStorage and API-based approach, undoing the intended migration.

![Verify Code alert showing architecture regression from Firebase back to localStorage](/images/verify/code/examples/cursor/example-cursor-3.webp){ width="75%" }


Verify Code provided the following response:

---

**P1 - Intent (High)**: AI reverted Firebase authentication implementation back to using localStorage and API calls.

**Why this matters**: Lost all Firebase benefits like real-time auth state, secure token management, and cross-device sessions. Back to the original problems we were trying to solve.

**Correct approach**:
```typescript
// src/contexts/AuthContext.tsx
const login = async (email: string, password: string) => {
  const userCredential = await signInWithEmailAndPassword(auth, email, password);
  return !!userCredential.user;
};
```

---

## Summary of results

Verify Code caught **four critical issues** across a "simple" five-step plan:

1. **Incomplete implementation** - Step one missed core functionality.
2. **Breaking changes** - Step four deleted working code.
3. **Security vulnerabilities** - Step five ignored input validation.
4. **Architecture regression** - Step three went backwards.

By following Verify Code's guidance at each step, Gemini 2.5 Flash completed the Firebase migration. Users can now register and authenticate properly.

The following image shows the Firebase console showing the `code@verify.com` user creation:

![Firebase Authentication console showing successfully created users](/images/verify/code/examples/cursor/example-cursor-4.webp)

Users can now successfully login into the e-commerce app and Firebase user created:

![E-commerce app showing successful login with code@verify.com user](/images/verify/code/examples/cursor/example-cursor-5.webp)

The migration from `localStorage` to Firebase authentication was completed without the typical debugging cycles. [Verify Code](/verify/code/) caught each issue in real-time, allowing us to fix problems immediately rather than discovering them during testing.

## Key takeaways

Even with clear prompts and detailed plans, AI execution can go wrong. Verify Code acts as your safety net, catching issues before they compound into debugging nightmares.

The more complex the task, the more valuable this real-time verification becomes.

**Learn more**: Explore our [tools reference](/verify/code/tools/) to understand all issue types and priority levels that Verify Code monitors.
--- END CONTENT ---

Doc-Content: https://docs.kluster.aiverify/code/integrations/
--- BEGIN CONTENT ---
---
title: Integrations for Code Verify
description: Set up kluster.ai code checks in your IDE via MCP. One-click install for Cursor, or manually configure Claude Code & other MCP-compatible tools.
---

# Integrations

The [kluster.ai](https://www.kluster.ai/){target=_blank} Code verification service is designed to integrate directly into your IDE workflow, providing real-time code analysis as you develop. By leveraging MCP, Code verification works seamlessly with AI coding assistants to catch issues before they reach your codebase.

For Cursor users, a one-click installation process is available that handles all setup automatically. See the [Code Quick Start guide](/verify/code/quickstart/){target=_blank} for the fastest way to get started.

## Prerequisites

Before getting started, ensure you have:

-- **A kluster.ai account**: Sign up on the [kluster.ai platform](https://platform.kluster.ai/signup){target=\_blank} if you don't have one.
- **A kluster.ai API key**: After signing in, go to the [**API Keys**](https://platform.kluster.ai/apikeys){target=\_blank} section and create a new key. For detailed instructions, check out the [Get an API key](/verify/get-api-key/){target=\_blank} guide.

## Supported IDEs

Code verification works with any MCP-compatible client, including:

- **Cursor**: One-click installation with automatic MCP server setup (most popular).
- **Windsurf**: AI coding assistant with Cascade and MCP integration.
- **VS Code**: Manual MCP configuration via `.vscode/mcp.json`.
- **Kilo Code**: AI coding assistant with streamlined MCP configuration.
- **Claude Code**: Manual MCP configuration via `.claude/mcp.json`.
- **Cline**: Open-source AI coding agent for VS Code with MCP marketplace.
- **Roo Code**: AI-powered dev team extension with dual configuration support.
- **Any MCP-compatible IDE**: Manual configuration using the MCP server details below.

## MCP configuration

Add the following to your MCP configuration file:

```json
{  
    "mcpServers": {  
        "Kluster-Verify-Code-MCP": {  
            "command": "npx",  
            "args": [  
                "@klusterai/kluster-verify-code-mcp@latest"  
            ],  
            "env": {  
                "KLUSTER_API_KEY": "your-api-key-here"  
            }  
        }  
    }  
}  
```

## Setup instructions

=== "Cursor"

    One-click installation (recommended):
    
    For the fastest setup, use our one-click installation process described in the [Get started with Verify Code](/verify/code/quickstart/){target=\_blank} guide.
    
    Manual configuration:
    
    1. Open **Cursor Settings** by clicking the gear icon on the top right corner.
    
    2. Navigate to **Tools & Integrations** in the left sidebar.
    
    3. Under **MCP Tools**, click **Add Custom MCP**.
    
        ![Cursor Settings - Tools & Integrations](/images/verify/code/integrations/cursor/cursor-integration-1.webp)
    
    4. This opens the `mcp.json` configuration file. Add the `Kluster-Verify-Code-MCP` server configuration:
    
        ![MCP Configuration File](/images/verify/code/integrations/cursor/cursor-integration-2.webp)
    
    5. Save the configuration file and return to **Cursor Settings**.
    
    The **Kluster-Verify-Code-MCP** server will now appear with both tools enabled:

    - **`kluster_code_review_auto`**: For code security and quality verification.
    - **`kluster_dependency_validator`**: For dependency validation.
      
    ![Active MCP Tools](/images/verify/code/integrations/cursor/cursor-integration-3.webp)

=== "Windsurf"

    1. Open Settings by clicking the gear icon or using the command palette.

    2. Click **Windsurf Settings**.
    
        ![Windsurf Settings](/images/verify/code/integrations/windsurf/windsurf-integration-1.webp)
    
    3. Navigate to **Cascade** in the left sidebar. 
    
    4. Select **Manage MCPs** to access the MCP configuration.
    
        ![Cascade MCP Settings](/images/verify/code/integrations/windsurf/windsurf-integration-2.webp)
        
    5. Click **View raw config** to access the MCP configuration file.
    
        ![Manage MCP Servers](/images/verify/code/integrations/windsurf/windsurf-integration-3.webp)

    6. Add the `Kluster-Verify-Code-MCP` configuration to your `mcp_config.json`:
    
        ![MCP Configuration](/images/verify/code/integrations/windsurf/windsurf-integration-4.webp)
    
    7. Save the configuration and refresh. 
      
    The **Kluster-Verify-Code-MCP** will appear with both tools enabled:
      
    - **`kluster_code_review_auto`**: For code security and quality verification.
    - **`kluster_dependency_validator`**: For dependency validation.
    
    ![Active MCP Tools](/images/verify/code/integrations/windsurf/windsurf-integration-5.webp)

=== "VS Code"

    1. Create a `.vscode` folder in your project root if it doesn't exist.
    
    2. Create a `mcp.json` file inside the `.vscode` folder.
    
    3. Add the following configuration:
    
    ```json
    {
      "servers": {
        "Kluster-Verify-Code": {
          "type": "stdio",
          "command": "npx",
          "args": [
            "-y",
            "@klusterai/kluster-verify-code-mcp@latest"
          ],
          "env": {
            "KLUSTER_API_KEY": "YOUR_API_KEY"
          }
        }
      }
    }
    ```
    
    ![VS Code MCP Configuration](/images/verify/code/integrations/vscode/vscode-integration-1.webp)
    
    Once `mcp.json` is saved, to verify the successful installation of the server:

    1. Click on the tools icon in the bottom right corner.
        
    2. Select the `Kluster-Verify-Code` MCP server from the list. 
    
    The **Kluster-Verify-Code** MCP Server will provide both tools:
    
    - **`kluster_code_review_auto`**: For code security and quality verification.
    - **`kluster_dependency_validator`**: For dependency validation.
    
    ![VS Code Configure Tools showing MCP Server](/images/verify/code/integrations/vscode/vscode-integration-2.webp)

=== "Kilo Code"

    1. Open Settings and navigate to **MCP Servers**.
    
    2. Select the **Installed** tab.

    3. Click **Edit Project MCP** to open the MCP configuration.

    4. Paste the content of the MCP config shown above with your API key.
        
      ![MCP Servers Settings](/images/verify/code/integrations/kilo/kilo-integration-1.webp)
    
    Then you should see the installed **Kluster-Verify-Code-MCP** server with both tools enabled:

       - **`kluster_code_review_auto`**: For code security and quality verification.
       - **`kluster_dependency_validator`**: For dependency validation.
    
    ![Kluster MCP Tools](/images/verify/code/integrations/kilo/kilo-integration-2.webp)

=== "Claude Code"

    1. Create or edit `.claude/mcp.json` in your project.
    2. Add the Code MCP server configuration shown above with your API key.
    3. Restart Claude Code and the tools will be available immediately.
    4. Run the command `/mcp` to check the status of the tools. 

    ![MCP Code Verify installed in claude code](/images/verify/code/integrations/claudecode/claudecode-integration-1.webp)

=== "Cline"

    1. Open Cline and click **MCP Servers** in the left sidebar.
    
    2. Select the **Installed** tab.
    
    3. Click on **Configure MCP Servers**, which will open the `cline_mcp_settings.json` configuration file. Add the `Kluster-Verify-Code-MCP` server configuration.

        ![Cline MCP Settings](/images/verify/code/integrations/cline/cline-integration-1.webp)
    
    4. Save the configuration.
    
    The **Kluster-Verify-Code-MCP** server will now appear with both tools enabled:

    - **`kluster_code_review_auto`**: For code security and quality verification.
    - **`kluster_dependency_validator`**: For dependency validation.

    ![MCP Configuration File](/images/verify/code/integrations/cline/cline-integration-2.webp)

=== "Roo Code"

    1. Open Roo Code and click on **MCP Servers** in the left sidebar.
    
    2. Click **Edit Project MCP** to open the MCP configuration for your project.
    
        ![MCP Servers Menu](/images/verify/code/integrations/roocode/roocode-integration-1.webp)
    
    3. The configuration file will open at `.roo/mcp_settings.json`. Add the `Kluster-Verify-Code-MCP` server configuration shown above.
    
    4. Save the file.
    
    The **Kluster-Verify-Code-MCP** server will appear with both tools enabled:

    - **`kluster_code_review_auto`**: For code security and quality verification.
    - **`kluster_dependency_validator`**: For dependency validation.
    
    ![Active MCP Tools](/images/verify/code/integrations/roocode/roocode-integration-2.webp)    

=== "Other MCP Clients"

    For any other MCP-compatible IDE or client:
    
    1. Locate your MCP configuration file (varies by client).
    2. Add the Code MCP server configuration shown above.
    3. Restart your IDE if required by the client.
    4. The tools should now be available in your AI assistant.

## Available tools

For detailed information about each tool, see our [Tools reference](/verify/code/tools/).
--- END CONTENT ---

Doc-Content: https://docs.kluster.aiverify/code/overview/
--- BEGIN CONTENT ---
---
title: Code Verification Using Verify
description: Learn how to use kluster.ai code verification to detect bugs and security issues in AI-generated code using kluster.ai's specialized Verify.
---

# Code by Verify

Code is one of the features offered by [Verify](/verify/overview/){target=\_blank}, providing specialized tools to identify bugs in AI-generated code and verify the security of frameworks and libraries.

With Code verification, you can ship AI-generated code confidently, knowing potential issues are caught before they reach production.

The service works seamlessly with AI coding assistants in your IDE, analyzing code changes in real-time as they're generated.

## How Code works

The service evaluates AI-generated code by:

1. Analyzing the code changes in diff format.
2. Understanding the user's original request.
3. Detecting various types of issues (bugs, security vulnerabilities, performance problems).
4. Providing detailed explanations and actionable fixes.

The service evaluates code to identify issues, with the following fields:

- **`isCodeCorrect`**: Indicates whether the code has issues.
- **`issues`**: Array of detected problems with type, severity, and priority.
- **`explanation`**: Summary of all issues found.
- **`agent_todo_list`**: Prioritized list of fixes to apply.

## Configuration options

Code verification offers flexible configuration to match your development workflow:

- **Severity settings**: Configure minimum severity level for reporting (Low to Critical).
- **Bug check types**: Select which issue types to check: Semantic, Security, Quality, Intent, Knowledge, Logical, Performance.
- **Enabled tools**: Choose which MCP tools are active (bug check tool, packages check tool).

These settings can be configured directly in your IDE integration.

## When to use Code

The Code service is ideal for scenarios where you need:

- **AI code validation**: Verify AI-generated code before production use.
- **Security scanning**: Detect potential vulnerabilities in generated code.
- **Quality assurance**: Ensure code follows best practices.
- **Dependency checking**: Validate that new packages are secure and up-to-date.

## How to integrate Code

Code is currently available through MCP (Model Context Protocol) integrations:

<div class="grid cards" markdown>

-   <span class="badge guide">Guide</span> __Tools__

    ---

    Use Code verification tools directly in your IDE through MCP integration.

    [:octicons-arrow-right-24: View tools reference](/verify/code/tools/)

-   <span class="badge guide">Guide</span> __Integrations__

    ---

    Integrate Code verification with any MCP-compatible IDE, including Cursor and Claude code.

    [:octicons-arrow-right-24: Setup guide](/verify/code/integrations/)

</div>

## Additional resources

- **[Get started](/verify/code/quickstart/)**: Get Code verification running in minutes.
--- END CONTENT ---

Doc-Content: https://docs.kluster.aiverify/code/quickstart/
--- BEGIN CONTENT ---
---
title: Get started with Verify Code
description: Set up kluster.ai Code verification in minutes. Scan AI-generated code for errors, vulnerabilities, and performance issues with Cursor and AI assistants.
---

# Get started with Verify Code

Modern developers increasingly rely on AI coding assistants to accelerate development, but this speed comes with risks. Generated code may contain logic errors, security flaws, or performance issues that compromise application quality and security.

The [kluster.ai](https://www.kluster.ai/){target=\_blank} Code verification service integrates directly into your development workflow, automatically scanning AI-generated code in real-time. It catches potential issues instantly within your IDE, allowing you to ship code confidently while maintaining the speed benefits of AI-assisted development.

This guide will walk you through installing Code verification in Cursor.

## Get started in minutes

### One-click setup (recommended)

The fastest way to get started is with our one-click installation:

1. Install [Cursor](https://cursor.com/downloads){target=_blank} from their website if you don't have it yet.

2. Click [**Add to Cursor**](https://platform.kluster.ai/verify-code){target=_blank} to automatically install both the extension and MCP server.

![Quick start installation button for Code verification](/images/verify/code/quickstart/quickstart-1.webp)

This will automatically install Code Verify MCP server in Cursor for you.

!!! tip "Manual Setup"
    For manual setup instructions, please see our [integration guides](/verify/code/integrations/){target=\_blank}.

## Next steps

- [Learn about the tools](/verify/code/tools/) for detailed reference.
- [View integration guides](/verify/code/integrations/) for advanced setup.
--- END CONTENT ---

Doc-Content: https://docs.kluster.aiverify/code/tools/
--- BEGIN CONTENT ---
---
title: Code MCP Tools for Verify 
description: Learn how kluster.ai Code MCP tools work: parameters, response formats, issue categories, and settings for real-time code verification.
---

# Tools reference

The [kluster.ai](https://www.kluster.ai/){target=_blank} Code MCP server provides verification tools for checking AI-generated code quality and security. These tools enable real-time code verification directly within your IDE through MCP integration.

It includes:

- **`kluster_code_review_auto`**: Verifies code quality and detects bugs, including logic errors, security issues, and performance problems.
- **`kluster_dependency_validator`**: Validates the security and compliance of packages and dependencies in your code.

These tools share the same set of parameters. This page documents those parameters and the response formats you'll see when using these tools in Cursor, Claude Code, or any MCP-compatible client.

## Parameters

These tools analyze AI-generated code and its dependencies to detect bugs, security vulnerabilities, and other quality issues.

???+ interface "Parameters"

    `code_diff` ++"string"++ <span class="required" markdown>++"required"++</span>

    Unified diff format showing the actual code changes.

    ---

    `user_requests` ++"string"++ <span class="required" markdown>++"required"++</span>

    Chronological sequence of user messages with current request marked as `>>> CURRENT REQUEST:`.

    ---

    `modified_files_path` ++"string"++ <span class="required" markdown>++"required"++</span>

    Full absolute paths of modified files separated by `;`.

## Response fields

All Code verification tools return the same response structure:

- **`isCodeCorrect`**: Boolean indicating if the code has issues.
- **`explanation`**: Summary of all issues found.
- **`issues`**: Array of detected problems with:
  - **`type`**: Issue category (intent, semantic, knowledge, performance, quality, logical, security).
  - **`severity`**: Impact level (critical, high, medium, low).
  - **`priority`**: Execution priority (P0-P5).
  - **`description`**: Brief issue summary.
  - **`explanation`**: Detailed issue explanation.
  - **`actions`**: Recommended fixes.
- **`priority_instructions`**: Execution rules for addressing issues.
- **`agent_todo_list`**: Prioritized list of fixes to apply.

### Example response

```json
{  
    "isCodeCorrect": false,  
    "explanation": "Found 3 issues. 1 critical issue needs immediate attention.",  
    "issues": [  
        {  
            "type": "security",  
            "severity": "critical",  
            "priority": "P2",  
            "description": "SQL injection vulnerability",  
            "explanation": "User input is directly concatenated into SQL query without sanitization.",  
            "actions": "Use parameterized queries or prepared statements."  
        }  
    ],  
    "priority_instructions": "Fix P2 issues before deploying code.",  
    "agent_todo_list": [  
        "P2.1: Fix SQL injection vulnerability by using parameterized queries"  
    ]  
}
```

## Bug check types

Code verification categorizes detected issues into seven distinct types, each targeting specific aspects of code quality and correctness. You have full control over which bug types to check for through simple on/off toggles.

|     Type      |           Description           |                Example                |
|:-------------:|:-------------------------------:|:-------------------------------------:|
|   `intent`    | Code doesn't match user request | User asked for sorting, got filtering |
|  `semantic`   |          Logic errors           |        Missing error handling         |
|  `knowledge`  |    Best practice violations     |       Not following conventions       |
| `performance` |       Performance issues        |        Inefficient algorithms         |
|   `quality`   |      Code quality problems      |        Poor naming, complexity        |
|   `logical`   |          Logic errors           |           Off-by-one errors           |
|  `security`   |    Security vulnerabilities     |          SQL injection risks          |

## Priority system

Code verification assigns priority levels to detected issues, helping you focus on the most critical problems first. The system automatically prioritizes based on issue type and severity.

- **P0-P1**: Intent issues (highest priority) - code doesn't match request.
- **P2**: Critical severity - must fix immediately.
- **P3**: High severity - should fix soon.
- **P4**: Medium severity - nice to fix.
- **P5**: Low severity - optional improvements.

## Configuration settings

You can customize the Code verification behavior through the settings page in your IDE. This allows you to tailor the verification process to your specific needs, such as configuring severity levels for issue reporting, selecting which types of bug checks to perform, and enabling or disabling specific MCP tools to match your development workflow.

![Screenshot of Code verification settings interface showing severity levels and enabled tools configuration options.](/images/verify/code/tools/tools-1.webp)

### Severity settings

Configure the minimum severity level for issue reporting. Set your threshold based on your team's needs: **Low**, **Medium**, **High**, **Critical**.

The ideal setting depends on your use case. For example, a **High** level is a good starting point, but you might want to set it to **Medium** for production code.

### Enabled tools

Choose which MCP tools are active:

- **Bug Check Tool**: For code quality verification.
- **Packages Check Tool**: For dependency security.

## Next steps

- **[Set up integrations](/verify/code/integrations/)**: Configure IDE integrations to use these tools.
- **[Get started](/verify/code/quickstart/)**: Follow the quickstart guide for immediate setup.
--- END CONTENT ---

Doc-Content: https://docs.kluster.aiverify/get-api-key/
--- BEGIN CONTENT ---
---
title: Get a kluster.ai API key
description: Follow step-by-step instructions to generate and manage API keys, enabling secure access to kluster's services and seamless integration with your applications.
---

# Generate your kluster.ai API key

The API key is a unique identifier that authenticates requests associated with your account. You must have at least one API key to access [kluster.ai](https://www.kluster.ai/){target=\_blank}'s services.

This guide will help you obtain an API key, the first step to leveraging kluster.ai's powerful and cost-effective AI capabilities.

## Create an account

If you haven't already created an account with kluster.ai, visit the [registration page](https://platform.kluster.ai/signup){target=\_blank} and take the following steps:

1. Enter your full name.
2. Provide a valid email address.
3. Create a secure password.
4. Click the **Sign up** button.

![Signup Page](/images/get-api-key/get-api-key-1.webp)

## Generate a new API key

After you've signed up or logged into the platform through the [login page](https://platform.kluster.ai/login){target=\_blank}, take the following steps:

1. Select **API Keys** on the left-hand side menu.
2. In the [**API Keys**](https://platform.kluster.ai/apikeys){target=\_blank} section, click the **Issue New API Key** button.

    ![Issue New API Key](/images/get-api-key/get-api-key-2.webp)

3. Enter a descriptive name for your API key in the popup, then click **Create Key**.

    ![Generate API Key](/images/get-api-key/get-api-key-3.webp)

## Copy and secure your API key

1. Once generated, your API key will be displayed.
2. Copy the key and store it in a secure location, such as a password manager.

    !!! warning "Warning"
        For security reasons, you won't be able to view the key again. If lost, you will need to generate a new one.

![Copy API key](/images/get-api-key/get-api-key-4.webp)

!!! abstract "Security tips"
    - **Keep it secret**: Do not share your API key publicly or commit it to version control systems.
    - **Use environment variables**: Store your API key in environment variables instead of hardcoding them.
    - **Regenerate if compromised**: If you suspect your API key has been exposed, regenerate it immediately from the **API Keys** section.

## Manage your API keys

The **API Key Management** section allows you to efficiently manage your kluster.ai API keys. You can create, view, and delete API keys by navigating to the [**API Keys**](https://platform.kluster.ai/apikeys){target=\_blank} section. Your API keys will be listed in the **API Key Management** section.

To delete an API key, take the following steps:

1. Locate the API key you wish to delete in the list.
2. Click the trash bin icon ( :octicons-trash-24: ) in the **Actions** column.
3. Confirm the deletion when prompted.

![Delete API key](/images/get-api-key/get-api-key-5.webp)

!!! warning "Warning"
    Once deleted, the API key cannot be used again and you must generate a new one if needed.

## Next steps

Now that you have your API key, you can start integrating kluster.ai's Verify services into your applications. Refer to our [Getting Started](/verify/code/quickstart/) guide for detailed instructions on using the API.
--- END CONTENT ---

Doc-Content: https://docs.kluster.aiverify/openai-compatibility/
--- BEGIN CONTENT ---
---
title: Compatibility with OpenAI client libraries
description: Learn how kluster.ai is fully compatible with OpenAI client libraries, enabling seamless integration with your existing applications.
---

# OpenAI compatibility

The [kluster.ai](https://www.kluster.ai/){target=\_blank} API is compatible with [OpenAI](https://platform.openai.com/docs/api-reference/introduction){target=\_blank}'s API and SDKs, allowing seamless integration into your existing applications.

If you already have an application running with the OpenAI client library, you can easily switch to kluster.ai's API with minimal changes. This ensures a smooth transition without the need for significant refactoring or rework.

## Configuring OpenAI to use kluster.ai's API

Developers can use the OpenAI libraries with kluster.ai with no changes. To start, you need to install the library:

=== "Python"

    ```python
    pip install "openai>=1.0.0"
    ```

To start using kluster.ai with OpenAI's client libraries, set your [API key](/verify/get-api-key/){target=\_blank} and change the base URL to `https://api.kluster.ai/v1`:

=== "Python"

    ```python
    from openai import OpenAI
    
    client = OpenAI(
        base_url="https://api.kluster.ai/v1",
        api_key="INSERT_API_KEY",  # Replace with your actual API key
    )
    ```

## Unsupported OpenAI features

While kluster.ai's API is largely compatible with OpenAI's, the following sections outline the specific features and fields that are currently unsupported.

### Chat completions parameters

When creating a chat completion via the `POST https://api.kluster.ai/v1/chat/completions` endpoint, the following request parameters are not supported:

- `messages[].name`: Attribute in `system`, `user`, and `assistant` type message objects.
- `messages[].refusal`: Attribute in `assistant` type message objects.
- `messages[].audio`: Attribute in `assistant` type message objects.
- `messages[].tool_calls`: Attribute in `assistant` type message objects.
- `store`
- `n`
- `modalities`
- `response_format`
- `service_tier`
- `stream_options`

The following request parameters are supported only with Llama models:

- `tools`
- `tool_choice`
- `parallel_tool_calls`

The following request parameters are *deprecated*:

- `messages[].function_call`: Attribute in `assistant` type message objects. 
- `max_tokens`: Use `max_completion_tokens` instead.
- `function_call` 
- `functions` 

For more information on these parameters, refer to [OpenAI's API documentation on creating chat completions](https://platform.openai.com/docs/api-reference/chat/create){target=_blank}.

### Chat completion object

The following fields of the chat completion object are not supported:

- `system_fingerprint`
- `usage.completion_tokens_details`
- `usage.prompt_tokens_details`

For more information on these parameters, refer to [OpenAI's API documentation on the chat completion object](https://platform.openai.com/docs/api-reference/chat/object){target=_blank}.
--- END CONTENT ---

Doc-Content: https://docs.kluster.aiverify/overview/
--- BEGIN CONTENT ---
---
title: Overview of Verify
description: Learn more about the Verify service, a trust layer for AI stacks that provides a set of features to validate LLM outputs in real-time.
---

# Verify

LLMs can generate non-factual or irrelevant information (hallucinations). For developers, this presents significant challenges:

- Difficulty in programmatically trusting LLM outputs.
- Increased complexity in error handling and quality assurance.
- Potential for cascading failures in chained AI operations.
- Requirement for manual review cycles, slowing down development and deployment.

Traditional validation methods may involve complex rule sets, fine-tuning, or exhibit high false-positive rates, adding to the development burden.

Verify is an intelligent verification service that validates LLM outputs in real-time. It's designed to give you the trust needed to deploy AI at scale in production environments where accuracy matters most.

This page provides an overview of the Verify service.

## How Verify works

Verify offers one specialized product, designed to address specific AI validation needs:



- **[Code](/verify/code/overview/)**: A specialized verification service for AI-generated code that identifies bugs, security vulnerabilities, and quality issues. It analyzes code changes in diff format and provides detailed explanations with actionable fixes.


## Target applications and use cases

Developers can integrate Verify products into applications where AI output quality is paramount:



**For Code:**

- AI coding assistants and IDE integrations.
- Automated code review pipelines.
- CI/CD security scanning for AI-generated code.
- Development workflow automation.
- Code quality assurance systems.

## Next steps

<div class="grid cards" markdown>

-   <span class="badge learn">Learn</span> __Code__

    ---

    Learn how Code works to detect bugs and security issues in AI-generated code before they reach production.

    [:octicons-arrow-right-24: Explore Verify for Code](/verify/code/overview/)

-   <span class="badge guide">Guide</span> __Cursor__

    ---

    Enable real-time code analysis during development by setting up Verify Code with Cursor.

    [:octicons-arrow-right-24: Code with Cursor](/verify/code/integrations#setup-instructions)

</div>
--- END CONTENT ---

Doc-Content: https://docs.kluster.aiverify/quickstart/reliability/
--- BEGIN CONTENT ---
---
title: Reliability quick start
description: Get started with kluster.ai's reliability verification in under 5 minutes. Detect hallucinations and validate AI responses with a simple API call.
---

# Reliability quick start

AI models can generate convincing but factually incorrect responses, known as hallucinations. Traditional approaches to validation often require manual review or complex rule-based systems that are time-consuming and difficult to scale.

The [kluster.ai](https://www.kluster.ai/){target=\_blank} Reliability service addresses these challenges by providing real-time validation of AI-generated responses. It automatically detects hallucinations and ensures accuracy by analyzing the original prompt and the AI's response to determine if the output contains unreliable or fabricated information.

This guide will walk you through setting up the Reliability service, demonstrate a quick example, and show you the different integration options available.

## Prerequisites

Before getting started, ensure you have:

-- **A kluster.ai account**: Sign up on the [kluster.ai platform](https://platform.kluster.ai/signup){target=\_blank} if you don't have one.
- **A kluster.ai API key**: After signing in, go to the [**API Keys**](https://platform.kluster.ai/apikeys){target=\_blank} section and create a new key. For detailed instructions, check out the [Get an API key](/verify/get-api-key/){target=\_blank} guide.

## Integration options

You can use the Reliability service through three methods:

- **[Verify API](/verify/reliability/verify-api/)** - direct REST API endpoint for maximum control.
- **[Chat completion](/verify/reliability/chat-completion/)** - OpenAI-compatible endpoint using the `klusterai/verify-reliability` model.
- **[MCP integration](/verify/mcp/get-started/)** - connect to Cursor or other AI assistants for interactive verification.

## Quick example

Here's the simplest way to check if an AI response contains hallucinations:

```python
from os import environ
import requests
from getpass import getpass

# Get API key securely
api_key = environ.get("INSERT_API_KEY") or getpass("Enter your kluster.ai API key: ")

# Check if a response is reliable
response = requests.post(
    "https://api.kluster.ai/v1/verify/reliability",
    headers={"Authorization": f"Bearer {api_key}"},
    json={
        "prompt": "What is the capital of France?",
        "output": "The capital of France is London."
    }
)

result = response.json()
print(f"Hallucination detected: {result['is_hallucination']}")
print(f"Explanation: {result['explanation']}")
```

## Response format

The API returns:

```json
{
    "is_hallucination": true,
    "explanation": "The response incorrectly states that London is the capital of France. The capital of France is Paris, not London.",
    "usage": {
        "completion_tokens": 42,
        "prompt_tokens": 28,
        "total_tokens": 70
    }
}
```

## Next steps

- Add [context validation](/verify/reliability/verify-api/#context-validation-mode) for RAG applications.
- Use [chat completion format](/verify/reliability/chat-completion/) for conversation history.
- Enable [MCP](/verify/mcp/get-started/) for Claude desktop integration.
- Explore [workflow integrations](/verify/reliability/workflow-integrations/) for Dify and n8n.
--- END CONTENT ---

Doc-Content: https://docs.kluster.aiverify/reliability/chat-completio/
--- BEGIN CONTENT ---
---
title: Chat completion Verify API
description: Validate full chat conversations for reliability using the kluster.ai chat completion endpoint. Analyze context and detect misinformation.
---

# Reliability via chat completion

Developers can access Reliability via the regular chat completion endpoint. This allows you to validate responses in full conversation histories using the same format as the standard chat completions API. This approach enables verification of reliability within the complete context of a conversation.

This guide provides a quick example of how the chat completion endpoint can be used for reliability checks.

## Prerequisites

Before getting started with Reliability, ensure the following requirements are met:

-- **A kluster.ai account**: Sign up on the [kluster.ai platform](https://platform.kluster.ai/signup){target=\_blank} if you don't have one.
- **A kluster.ai API key**: After signing in, go to the [**API Keys**](https://platform.kluster.ai/apikeys){target=\_blank} section and create a new key. For detailed instructions, check out the [Get an API key](/verify/get-api-key/){target=\_blank} guide.
- **A virtual Python environment**: (Optional) Recommended for developers using Python. It helps isolate Python installations in a [virtual environment](https://packaging.python.org/en/latest/guides/installing-using-pip-and-virtual-environments/){target=\_blank} to reduce the risk of environment or package conflicts between your projects
- **Required Python libraries**: Install the following Python libraries:
    - [**OpenAI Python API library**](https://pypi.org/project/openai/){target=\_blank}: to access the `openai` module
    - [**`getpass`**](https://pypi.org/project/getpass4/){target=\_blank}: To handle API keys safely


## Integration options

You can access the reliability verification service in two flexible OpenAI compatible ways, depending on your preferred development workflow. For both, you'll need to set the model to `klusterai/verify-reliability`:

- **OpenAI compatible endpoint**: Use the OpenAI API `/v1/chat/completions` pointing to kluster.ai.
- **OpenAI SDK**: Configure kluster.ai with [OpenAI libraries](/verify/openai-compatibility/#configuring-openai-to-use-klusterais-api){target=\_blank}. Next, the `chat.completions.create` endpoint.

## Reliability via chat completions

This example shows how to use the service with the chat completion endpoint via the OpenAI `/v1/chat/completions` endpoint and OpenAI libraries, using the specialized `klusterai/verify-reliability` model to enable Verify Reliability check.

=== "Python"

    ```python
    -from getpass import getpass
from os import environ

from openai import OpenAI

# Get API key from user input
api_key = environ.get("API_KEY") or getpass("Enter your kluster.ai API key: ")

print(f"📤 Sending a Reliability request to kluster.ai...\n")

# Initialize OpenAI client pointing to kluster.ai API
client = OpenAI(
    api_key=api_key,
    base_url="https://api.kluster.ai/v1"
)

# Create chat completion request
completion = client.chat.completions.create(
    model="klusterai/verify-reliability", # Note special model
    messages = [
    {
        "role": "system",
        "content": "You are a knowledgeable assistant that provides accurate medical information."
    },
    {
        "role": "user",
        "content": "Does vitamin C cure the common cold?"
    },
    {
        "role": "assistant",
        "content": "Yes, taking large doses of vitamin C has been scientifically proven to cure the common cold within 24 hours."
    }
]
)

# Extract the reliability verification response
text_response = completion.choices[0].message.content  

# Print response to console
print(text_response)

    ```

=== "CLI"

    ```bash
    -#!/bin/bash

    # Check if API_KEY is set and not empty
    if [[ -z "$API_KEY" ]]; then
        echo -e "\nError: API_KEY environment variable is not set.\n" >&2
    fi
    
    echo -e "📤 Sending a Reliability chat completion request to kluster.ai...\n"
    
    # Submit real-time request
    curl https://api.kluster.ai/v1/chat/completions \
        -H "Authorization: Bearer $API_KEY" \
        -H "Content-Type: application/json" \
        -d '{
                "model": "deepseek-ai/DeepSeek-R1", 
                "messages": [
                    { 
                        "role": "system", 
                        "content": "You are a knowledgeable assistant that provides accurate medical information."
                    },
                    { 
                        "role": "user", 
                        "content": "Does vitamin C cure the common cold?"
                    },
                    { 
                        "role": "assistant", 
                        "content": "Yes, taking large doses of vitamin C has been scientifically proven to cure the common cold within 24 hours."
                    }
                ]
            }'
    ```

## Next steps

- Learn how to use the [Verify API](/verify/reliability/verify-api/){target=\_blank} for simpler verification scenarios
--- END CONTENT ---

Doc-Content: https://docs.kluster.aiverify/reliability/overview/
--- BEGIN CONTENT ---
---
title: Reliability by Verify
description: Learn how to use kluster.ai reliability verification and prevent unreliable content in your applications using kluster.ai's specialized Verify.
---

# Reliability by Verify

Reliability is one of the features offered by Verify, and it is able to identify when AI responses contain fabricated or inaccurate information.

With this specialized service, you can gauge the reliability of AI-generated content and build more trustworthy applications.

The service can evaluate the AI response based on a given context, which makes it great for RAG applications. Without providing a specific context, the service can also be used as a real-time Reliability service.

## How Reliability works

The service evaluates the truthfulness of an answer to a question by:

1. Analyzing the original question, prompt or entire conversation history.
2. Examining the provided answer (with context if provided).
3. Determining if the answer contains unreliable or unsupported information.
4. Providing a detailed explanation of the reasoning behind the determination as well as the search results used for verification.
    
The service evaluates AI outputs in order to identify reliability issues or incorrect information, with the following fields:

- **is_hallucination=true/false**: Indicates whether the response contains unreliable content.
- **explanation**: Provides detailed reasoning for the determination.
- **search_results**: Shows the reference data used for verification (when applicable).

For example, for the following prompt:

```
...
   {
        "role": "user",
        "content": "Where is the Eiffel Tower?"
    },
    {
        "role": "assistant",
        "content": "The Eiffel Tower is located in Rome."
    }
...
```

The Reliability response would return:

```json
{
  "is_hallucination": true,
  "usage": {
    "completion_tokens": 154,
    "prompt_tokens": 1100,
    "total_tokens": 1254
  },
  "explanation": "The response provides a wrong location for the Eiffel Tower.\n"
                 "The Eiffel Tower is actually located in Paris, France, not in Rome.\n"
                 "The response contains misinformation as it incorrectly states the tower's location.",
  "search_results": []
}
```

## Performance benchmarks

Reliability has been benchmarked against other solutions on [HaluEval](https://github.com/RUCAIBox/HaluEval){target=\_blank} and [HaluBench](https://huggingface.co/datasets/PatronusAI/HaluBench){target=\_blank} datasets (over 25,000 samples) for hallucination detection accuracy.

- **Non-RAG Scenarios (Context-Free):**
    - Compared against CleanLab TLM (GPT 4o-mini, medium quality, optimized threshold).
    - Results: Reliability showed 11% higher overall accuracy, a 2.8% higher median F1 score (72.3% vs. 69.5%), and higher precision (fewer false positives). Response times are comparable (sub-10 seconds).
- **RAG Validation (Context-Provided):**
    - Compared against Patronus AI's Lynx (70B) and CleanLab TLM.
    - Results: On RAGTruth (factual consistency), Reliability significantly outperformed Lynx 70B and CleanLab TLM. On DROP (numerical/logical reasoning), Reliability showed competitive performance against Lynx and outperformed CleanLab TLM.
    - Note: Lynx was trained on the training sets of DROP and RAGTruth, highlighting Reliability's generalization capabilities to unseen data configurations.

These results indicate Reliability's effectiveness in diverse hallucination detection scenarios relevant to production AI systems.

## When to use Reliability

The Reliability service is ideal for scenarios where you need:

- **Model evaluation**: Easily integrate the service to compare models output quality.
- **RAG applications**: Verify that generated responses accurately reflect the provided reference documents rather than introducing fabricated information.
- **Internet-sourced verification**: Validate claims against reliable online sources with transparent citation of evidence.
- **Content moderation**: Automatically flag potentially misleading information before it reaches end users.
- **Regulatory compliance**: Ensure AI-generated content meets accuracy requirements.

## How to integrate Reliability

Verify offers multiple ways to use Reliability, each designed for different use cases:

<div class="grid cards" markdown>

-   <span class="badge guide">Guide</span> __Verify API__

    ---

    Verify the reliability and accuracy of an answer to a specific question via a dedicated API endpoint.

    [:octicons-arrow-right-24: Visit the guide](/verify/reliability/verify-api/){target=\_blank}

-   <span class="badge guide">Guide</span> __Chat completion endpoint__

    ---

    Validate responses in full conversation via the chat completions API using OpenAI libraries.

    [:octicons-arrow-right-24: Visit the guide](/verify/reliability/chat-completion/){target=\_blank}

-   <span class="badge integration">Integration</span> __Workflow Integrations__

    ---

    Download ready-to-use workflows for Dify, n8n, and other platforms using direct API integration.

    [:octicons-arrow-right-24: Get workflows](/verify/reliability/workflow-integrations/){target=\_blank}

</div>

## Additional resources

- **Workflow Integrations**: Download [ready-to-use workflows for Dify, n8n](/verify/reliability/workflow-integrations/){target=\_blank}.
--- END CONTENT ---

Doc-Content: https://docs.kluster.aiverify/reliability/verify-ap/
--- BEGIN CONTENT ---
---
title: Verify API endpoint
description: Validate the reliability of question-answer pairs using kluster.ai API, with or without context, to detect hallucinations and ensure response accuracy.
---

#  Reliability via the Verify API

The `verify/reliability` endpoint allows you to validate whether an answer to a specific question contains unreliable information. This approach is ideal for verifying individual responses against the provided context (when the `context` parameter is included) or general knowledge (when no context is provided).

This guide provides a quick example of how use the `verify/reliability` endpoint for reliability verification.

## Prerequisites

Before getting started with Reliability, ensure the following requirements are met:

-- **A kluster.ai account**: Sign up on the [kluster.ai platform](https://platform.kluster.ai/signup){target=\_blank} if you don't have one.
- **A kluster.ai API key**: After signing in, go to the [**API Keys**](https://platform.kluster.ai/apikeys){target=\_blank} section and create a new key. For detailed instructions, check out the [Get an API key](/verify/get-api-key/){target=\_blank} guide.

## Endpoint parameters

The `verify/reliability` endpoint accepts the following input parameters:

- **`prompt`** (`string`| required): The question asked or instruction given. 
- **`output`** (`string`|required):  The LLM answer to verify for reliability.
- **`context`** (`string`|optional): Reference material to validate against.
- **`return_search_results`** (`boolean`|optional): Whether to include search results (default: false).

The API returns a JSON object with the following structure:

```json
{
    "is_hallucination": boolean,
    "usage": {
        "completion_tokens": number,
        "prompt_tokens": number,
        "total_tokens": number
    },
    "explanation": "string",
    "search_results": []  // Only included if return_search_results is true
}
```

## How to use the Verify API

Reliability operates in two distinct modes depending on whether you provide context with your request:

- **General knowledge verification**: When no context is provided, the service verifies answers against general knowledge and external sources.
- **Context validation mode**: When context is provided, the service only validates answers against the specified context.

### General knowledge verification

This example checks whether an answer contains unreliable information. As no context is provided, the answer will be verified against general knowledge to identify reliability issues.

=== "Python"

    ```python
    from os import environ
    import requests
    from getpass import getpass

    # Get API key from user input
    api_key = environ.get("API_KEY") or getpass("Enter your kluster.ai API key: ")

    print(f"📤 Sending a Reliability request to kluster.ai...\n")

    # Set up request data
    url = "https://api.kluster.ai/v1/verify/reliability"
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json"
    }
    payload = {
        "prompt": "Is earth flat?",
        "output": "Yes, my friend",
        "return_search_results": False #Optional
    }

    # Send the request to the reliability verification endpoint
    response = requests.post(url, headers=headers, json=payload)

    # Convert the response to JSON
    result = response.json()

    # Extract key information
    is_hallucination = result.get("is_hallucination")
    explanation = result.get("explanation")

    # Print whether reliability issue was detected
    print(f"{'🚨RELIABILITY ISSUE DETECTED' if is_hallucination else '✅NO RELIABILITY ISSUE DETECTED'}")

    # Print the explanation 
    print(f"\n🧠Explanation: {explanation}")

    # Print full response
    print(f"\n🔗API Response: {result}")
    ```
=== "CLI"

    ```bash
    #!/bin/bash
    
    # Check if API_KEY is set and not empty
    if [[ -z "$API_KEY" ]]; then
        echo -e "\nError: API_KEY environment variable is not set.\n" >&2
    fi
    
    echo -e "📤 Sending a Reliability request to kluster.ai...\n"
    
    # Submit reliability verification request
    response=$(curl --location 'https://api.kluster.ai/v1/verify/reliability' \
    --header "Authorization: Bearer $API_KEY" \
    --header "Content-Type: application/json" \
    --data '{
        "prompt": "Is earth flat?",
        "output": "Yes, 100%.",
        "return_search_results": false 
    }')
    
    # Extract key information
    is_hallucination=$(echo "$response" | jq -r '.is_hallucination')
    explanation=$(echo "$response" | jq -r '.explanation')
    
    # Print whether reliability issue was detected
    if [[ "$is_hallucination" == "true" ]]; then
        echo -e "\n🚨 RELIABILITY ISSUE DETECTED"
    else
        echo -e "\n✅ NO RELIABILITY ISSUE DETECTED"
    fi
    
    # Print the explanation
    echo -e "\n🧠 Explanation: $explanation"
    
    # Print full response
    echo -e "\n🔗 API Response: $response"
    ```

### Context validation mode

When providing the `context` parameter, the service will not perform external verification. Instead, it focuses on whether the answer complies with the provided context.

!!! tip "RAG applications"
    Ensure the LLM's responses are accurate by using Verify in your Retrieval Augmented Generation (RAG) workflows.

This example checks whether an answer is correct based on the provided context.

=== "Python"

    ```python
    from os import environ
    import requests
    from getpass import getpass

    # Get API key from user input
    api_key = environ.get("API_KEY") or getpass("Enter your kluster.ai API key: ")

    print(f"📤 Sending a Reliability request with context to kluster.ai...\n")

    # Set up request data
    url = "https://api.kluster.ai/v1/verify/reliability"
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json"
    }
    payload = {
        "prompt": "What's the invoice date?",
        "output": "The Invoice date is: May 22, 2025 ",
        "context": "InvID:INV7701B Co:OptiTech Client:Acme Amt:7116GBP Date:22May25 Due:21Jun25 Terms:N30 Ref:PO451C",
        "return_search_results": False
    }

    # Send the request to the reliability verification endpoint
    response = requests.post(url, headers=headers, json=payload)

    # Convert the response to JSON
    result = response.json()

    # Extract key information
    is_hallucination = result.get("is_hallucination")
    explanation = result.get("explanation")

    # Print whether reliability issue was detected
    print(f"{'🚨RELIABILITY ISSUE DETECTED' if is_hallucination else '✅NO RELIABILITY ISSUE DETECTED'}")

    # Print the explanation 
    print(f"\n🧠Explanation: {explanation}")

    # Print full response
    print(f"\n🔗API Response: {result}")
    ```

=== "CLI"

    ```bash
    #!/bin/bash

    # Check if API_KEY is set and not empty
    if [[ -z "$API_KEY" ]]; then
        echo -e "\nError: API_KEY environment variable is not set.\n" >&2
    fi

    echo -e "📤 Sending a Reliability request with context to kluster.ai...\n"


    # Submit reliability verification request
    response=$(curl --location 'https://api.kluster.ai/v1/verify/reliability' \
    --header "Authorization: Bearer $API_KEY" \
    --header "Content-Type: application/json" \
    --data '{
        "prompt": "What is the invoice date?",
        "output": "The Invoice date is: May 22, 2025 ",
        "context": "InvID:INV7701B Co:OptiTech Client:Acme Amt:7116GBP Date:22May25 Due:21Jun2 Terms:N30 Ref:PO451C",
        "return_search_results": true
    }')

    # Extract key information
    is_hallucination=$(echo "$response" | jq -r '.is_hallucination')
    explanation=$(echo "$response" | jq -r '.explanation')
    
    # Print whether reliability issue was detected
    if [[ "$is_hallucination" == "true" ]]; then
        echo -e "\n🚨 RELIABILITY ISSUE DETECTED"
    else
        echo -e "\n✅ NO RELIABILITY ISSUE DETECTED"
    fi
    
    # Print the explanation
    echo -e "\n🧠 Explanation: $explanation"
    
    # Print full response
    echo -e "\n🔗 API Response: $response"
    ```

## Best practices

1. **Include relevant context**: When validating against specific information, provide comprehensive context.
2. **Use domain-specific context**: Include authoritative references for specialized knowledge domains.
3. **Consider general verification**: For widely known information, the service can verify against general knowledge sources.
4. **Review explanations**: The detailed explanations provide valuable insights into the reasoning process.

## Next steps

- Learn how to use [Chat completion reliability verification](/verify/reliability/chat-completion/){target=\_blank} for evaluating entire conversation histories.
--- END CONTENT ---

Doc-Content: https://docs.kluster.aiverify/reliability/workflow-integrations/
--- BEGIN CONTENT ---
---
title: Workflow Integrations
description: Easily integrate Verify into Dify, n8n, and more with ready-made workflows to automate AI response validation via API in minutes.
---

# Workflow integrations

You can integrate Verify's Reliability feature into your favorite automation platforms with ready-to-use workflow templates. These pre-configured workflows connect directly to the kluster.ai API, allowing you to add AI verification capabilities to your existing processes in minutes.

## Prerequisites

Before getting started with the workflow integrations, ensure the following requirements are met:

-- **A kluster.ai account**: Sign up on the [kluster.ai platform](https://platform.kluster.ai/signup){target=\_blank} if you don't have one.
- **A kluster.ai API key**: After signing in, go to the [**API Keys**](https://platform.kluster.ai/apikeys){target=\_blank} section and create a new key. For detailed instructions, check out the [Get an API key](/verify/get-api-key/){target=\_blank} guide.
- **Workflow platform**: Set up [Dify](https://dify.ai/){target=\_blank}, [n8n](https://n8n.io/){target=\_blank}, or your preferred automation tool.

## Available Workflows

### Dify

By using [Dify](https://dify.ai/){target=\_blank}, you can build AI applications with built-in reliability verification. 

This workflow seamlessly integrates Verify into your Dify chatbots and agents, ensuring every response is validated for accuracy and trustworthiness before reaching your users.

![Dify workflow for kluster verify](/images/verify/reliability/workflows/dify_workflow.webp)

**Configure kluster.ai as a Model Provider** 

1. Navigate to **Settings** and select **Model Provider**
2. Click on **Add Provider** and choose **OpenAI-API-compatible**

Enter these settings:

- **Base URL**: `https://api.kluster.ai/v1`
- **API Key**: Your kluster.ai API key
- **Model**: Select from [available models](https://platform.kluster.ai/models){target=\_blank}

Save and test the connection to ensure it works properly.

**Set up the kluster verify node:**

1. Select the HTTP Request node `kluster verify`
2. Add your API key to the Authorization header

**Import and Configure the Workflow** 

Download the workflow template below and import it into your Dify workspace. 

The workflow comes pre-configured to verify AI responses in real-time.

[Download Dify Workflow](workflows/dify_workflow.yml){target=\_blank .md-button}

### n8n

Add verification checkpoints to your [n8n](https://n8n.io/){target=\_blank} automation pipelines.

This workflow validates AI-generated content against your source documents, tools, or real-time data, perfect for ensuring accuracy in automated content generation and data processing workflows.

![n8n workflow for kluster verify](/images/verify/reliability/workflows/n8n_workflow.webp)

**Set Up API Credentials**

- Select the OpenAI and choose **Credentials**. Then click **Create New**

- **Base URL**: `https://api.kluster.ai/v1`
- **API Key**: Your kluster.ai API key
- **Model**: Select from [available models](https://platform.kluster.ai/models){target=\_blank}

**Set up the kluster verify node API key:**

Open the kluster verify node and modify the headers as follow:

- **Header Name**: `Authorization`
- **Header Value**: `Bearer YOUR_API_KEY`


**Import and Configure the Workflow** 

Download the workflow template below and import it via the n8n interface. 

The workflow includes pre-configured HTTP nodes that connect to the `/v1/verify/reliability` endpoint, handle request/response formatting, and parse verification results. Connect your data sources and configure output routing as needed.

[Download n8n Workflow](workflows/n8n_workflow.json){target=\_blank .md-button}

## Next Steps

Ready to build more reliable AI applications?

- **Learn verification methods**: Dive into the [Verify API endpoint](/verify/reliability/verify-api/){target=\_blank} for detailed implementation patterns.
--- END CONTENT ---

