# kluster llms-full.txt
kluster. kluster is the developer AI cloud platform to deploy, scale, and fine-tune models at lightning speed.

## Generated automatically. Do not edit directly.

Documentation: https://docs.kluster.ai/

## List of doc pages:
[API reference](No categories available.): (https://raw.githubusercontent.com/kluster-ai/docs/refs/heads/main/api-reference/reference.md) (The kluster.ai API reference includes endpoints, available methods, required parameters, and response format information for kluster.ai's OpenAI-compatible API.)
[MCP client integrations](No categories available.): (https://raw.githubusercontent.com/kluster-ai/docs/refs/heads/main/verify/mcp/client-integrations.md) (Connect Claude desktop, VS Code, Cursor, and Claude Code to kluster.ai verification tools with ready-to-use configuration examples.)
[Cloud MCP API usage](No categories available.): (https://raw.githubusercontent.com/kluster-ai/docs/refs/heads/main/verify/mcp/cloud/api.md) (Complete guide to using kluster.ai's Cloud MCP API with JSON-RPC requests. How to check it's status, enable, disable and test it.)
[Cloud MCP platform management](No categories available.): (https://raw.githubusercontent.com/kluster-ai/docs/refs/heads/main/verify/mcp/cloud/platform.md) (Enable and manage kluster.ai's Cloud MCP endpoints through the platform UI with one-click setup and visual client examples.)
[Get started with MCP](No categories available.): (https://raw.githubusercontent.com/kluster-ai/docs/refs/heads/main/verify/mcp/get-started.md) (Get kluster.ai verification tools integrated into Claude desktop in five minutes using Cloud MCP. No setup required, just enable and connect.)
[MCP integration overview](No categories available.): (https://raw.githubusercontent.com/kluster-ai/docs/refs/heads/main/verify/mcp/overview.md) (Connect AI apps to kluster.ai services using MCP for seamless development workflow integration with verification tools and automated reliability checking.)
[Integrate OpenAI Agents SDK with kluster Verify](No categories available.): (https://raw.githubusercontent.com/kluster-ai/docs/refs/heads/main/verify/mcp/sdk-integrations/openai-agents.md) (Integrate OpenAI Agents SDK with kluster Verify to create AI agents that detect hallucinations and validate facts with real-time verification.)
[Self-hosted MCP](No categories available.): (https://raw.githubusercontent.com/kluster-ai/docs/refs/heads/main/verify/mcp/self-hosted.md) (Deploy kluster.ai's MCP server locally using Docker or Node.js for development and testing with full control over your infrastructure.)
[MCP tools reference](No categories available.): (https://raw.githubusercontent.com/kluster-ai/docs/refs/heads/main/verify/mcp/tools.md) (Reference guide for kluster.ai's MCP verification tools - verify claims and documents with detailed parameters and response formats.)
[Compatibility with OpenAI client libraries](No categories available.): (https://raw.githubusercontent.com/kluster-ai/docs/refs/heads/main/verify/openai-compatibility.md) (Learn how kluster.ai is fully compatible with OpenAI client libraries, enabling seamless integration with your existing applications.)
[Overview of Verify](No categories available.): (https://raw.githubusercontent.com/kluster-ai/docs/refs/heads/main/verify/overview.md) (Learn more about the Verify service, a trust layer for AI stacks that provides a set of features to validate LLM outputs in real-time.)
[Reliability quick start](No categories available.): (https://raw.githubusercontent.com/kluster-ai/docs/refs/heads/main/verify/quickstart/reliability.md) (Get started with kluster.ai's reliability verification in under 5 minutes. Detect hallucinations and validate AI responses with a simple API call.)
[Chat completion Verify API](No categories available.): (https://raw.githubusercontent.com/kluster-ai/docs/refs/heads/main/verify/reliability/chat-completion.md) (Validate full chat conversations for reliability using the kluster.ai chat completion endpoint. Analyze context and detect misinformation.)
[Reliability by Verify](No categories available.): (https://raw.githubusercontent.com/kluster-ai/docs/refs/heads/main/verify/reliability/overview.md) (Learn how to use kluster.ai reliability verification and prevent unreliable content in your applications using kluster.ai's specialized Verify.)
[Verify API endpoint](No categories available.): (https://raw.githubusercontent.com/kluster-ai/docs/refs/heads/main/verify/reliability/verify-api.md) (Validate the reliability of question-answer pairs using kluster.ai API, with or without context, to detect hallucinations and ensure response accuracy.)
[Workflow Integrations](No categories available.): (https://raw.githubusercontent.com/kluster-ai/docs/refs/heads/main/verify/reliability/workflow-integrations.md) (Easily integrate Verify into Dify, n8n, and more with ready-made workflows to automate AI response validation via API in minutes.)

## Full content for each doc page

Doc-Content: https://docs.kluster.ai/api-reference/reference/
--- BEGIN CONTENT ---
---
title: API reference
description: The kluster.ai API reference includes endpoints, available methods, required parameters, and response format information for kluster.ai's OpenAI-compatible API.
hide:
- nav
- footer
template: portal.html
---
--- END CONTENT ---

Doc-Content: https://docs.kluster.ai/verify/mcp/client-integrations/
--- BEGIN CONTENT ---
---
title: MCP client integrations
description: Connect Claude desktop, VS Code, Cursor, and Claude Code to kluster.ai verification tools with ready-to-use configuration examples.
---

# Client integrations

Connect any compatible client to [kluster.ai's](https://www.kluster.ai/){target=\_blank} MCP Verify server. This guide provides configuration examples for popular clients using [Cloud MCP](/verify/mcp/cloud/platform/).

!!! info "Self-hosted deployment"
    For [self-hosted MCP](/verify/mcp/self-hosted/){target=\_blank}, replace the URL with `http://localhost:3001/stream` and use your kluster.ai API key.

## Prerequisites
      
Before integrating with any client, ensure you have the required credentials:
      
- **A kluster.ai account**: Sign up on the [kluster.ai platform](https://platform.kluster.ai/signup){target=\_blank} if you don't have one.
- **A kluster.ai API key**: After signing in, go to the [**API Keys**](https://platform.kluster.ai/apikeys){target=\_blank} section and create a new key. For detailed instructions, check out the [Get an API key](/get-api-key/){target=\_blank} guide.
- **MCP token** (for some clients): Follow the [platform guide](/verify/mcp/cloud/platform/){target=\_blank} to enable MCP and obtain your token.

!!! info "Which credential do I need?"
    Depending on the client and configuration method, you may need either your kluster.ai API key or your MCP token. Each configuration section below specifies which credential to use.

## Configuration by client

=== "Claude desktop (.dxt file)"

    The easiest way to add kluster Verify to Claude desktop is using the `.dxt` extension file:

    1. **Download the extension**: [kluster-verify-mcp.dxt](/verify/mcp/resources/kluster-verify-mcp.dxt)

    2. **Install the Verify MCP**: Go to the **Extensions** tab in the settings menu and drag and drop the `.dxt` file, then click **Install**.

        ![](/images/verify/mcp/integrations/integrations-3.webp){ style="width:80%;" }

    3. **Add your API key**: When prompted, enter your kluster.ai API key (follow the [Get an API key guide](/get-api-key/){target=\_blank} to obtain one).

        ![](/images/verify/mcp/integrations/integrations-4.webp){ style="width:80%;" }

    4. **Enable the extension and start using**: The kluster Verify tools will be available immediately in your conversations.

        ![](/images/verify/mcp/integrations/integrations-5.webp){ style="width:80%;" }

=== "Claude desktop (JSON config)"

    If you prefer manual configuration, you can add kluster Verify by editing Claude desktop's configuration file:

    1. Locate the configuration file:
        - **macOS**: `~/Library/Application Support/Claude/claude_desktop_config.json`
        - **Windows**: `%APPDATA%/Claude/claude_desktop_config.json`

    2. Add the MCP server configuration:
    
        ```json
        {
    "mcpServers": {
        "kluster-verify-mcp": {
            "command": "npx",
            "args": [
                "mcp-remote",
                "https://api.kluster.ai/v1/mcp",
                "--header",
                "Authorization: Bearer YOUR_MCP_TOKEN"
            ]
        }
    }
}
        ```

    3. Replace `YOUR_MCP_TOKEN` with your actual MCP token (obtained after [enabling MCP](/verify/mcp/cloud/platform/){target=\_blank}) on the kluster.ai platform.

    4. Save the file and restart Claude desktop to load the kluster Verify tools.

        ![](/images/verify/mcp/get-started/get-started-1.webp){ style="width:80%;" }

=== "VS Code"

    1. Install [GitHub Copilot](https://marketplace.visualstudio.com/items?itemName=GitHub.copilot){target=\_blank} extension.
    2. Open the Chat view and click on the tools icon.

        ![](/images/verify/mcp/integrations/integrations-1.webp){ style="width:50%;" }

    3. Choose **Add More Tools...** and click on **Add MCP Server...**.
    4. Select **Command (stdio)** and enter the following command, replacing `YOUR_MCP_TOKEN` with your actual MCP token:

        ```bash
        npx mcp-remote https://api.kluster.ai/v1/mcp \
        --header "Authorization: Bearer YOUR_MCP_TOKEN"
        ```

    5. Restart VS Code.

=== "Cursor"

    Open Cursor settings and:
    
    1. Select **Tools & Integrations**.

    2. To add your first MCP, click **Add Custom MCP**. To add additional MCPs later, use **New MCP Server**. Then enter the following configuration:
            
        ```json
        {
            "mcpServers": {
                "kluster-verify-mcp": {
                    "url": "https://api.kluster.ai/v1/mcp",
                    "headers": {
                        "Authorization": "Bearer YOUR_MCP_TOKEN"
                    }
                }
            }
        }
        ```

    3. Restart Cursor.

    ![](/images/verify/mcp/integrations/integrations-2.webp){ style="width:80%;" }

=== "Claude code"

    Run this command in your terminal:

    ```bash
    claude mcp add kluster-verify-mcp \
      npx mcp-remote https://api.kluster.ai/v1/mcp \
      --header "Authorization: Bearer YOUR_MCP_TOKEN"
    ```

## Available tools

- **`verify`**: Validates prompt and response pairs against reliable sources.
- **`verify_document`**: Verifies prompt and response pairs in relation to uploaded documents.
<!-- Commenting this for safekeeping -->
<!--See [Tools reference](/verify/mcp/tools/){target=\_blank} for parameters and examples.-->

## SDK integrations

Looking to integrate MCP tools into your own applications? Check out the SDK integration guides:

- **[OpenAI Agents SDK](/verify/mcp/sdk-integrations/openai-agents/)**: Build Python agents with built-in verification capabilities using OpenAI's Agents framework.

## Next steps

- [Complete setup guide](/verify/mcp/get-started/) with usage examples.
- [Self-hosted deployment](/verify/mcp/self-hosted/) for local development.
--- END CONTENT ---

Doc-Content: https://docs.kluster.ai/verify/mcp/cloud/api/
--- BEGIN CONTENT ---
---
title: Cloud MCP API usage
description: Complete guide to using kluster.ai's Cloud MCP API with JSON-RPC requests. How to check it's status, enable, disable and test it. 
---

# API usage

Manage your Cloud MCP endpoint using API calls. This guide covers checking status, enabling and disabling your endpoint, obtaining MCP tokens, and testing verification tools. Use this as an alternative to the [platform UI](/verify/mcp/cloud/platform/){target=\_blank}.

## Prerequisites

Before getting started with MCP via API, ensure you have:

- **A kluster.ai account**: Sign up on the [kluster.ai platform](https://platform.kluster.ai/signup){target=\_blank} if you don't have one.
- **A kluster.ai API key**: After signing in, go to the [**API Keys**](https://platform.kluster.ai/apikeys){target=\_blank} section and create a new key. For detailed instructions, check out the [Get an API key](/get-api-key/){target=\_blank} guide.

## Manage your MCP endpoint

### Check status

First, check if your MCP endpoint is already enabled:

```bash
curl -X GET https://api.kluster.ai/v1/mcp/status \
  -H "Authorization: Bearer YOUR_API_KEY"
```

If disabled, the response shows:

```json
{
    "enabled": false,
    "url": "",
    "apiKey": ""
}
```

### Enable endpoint

If not enabled, activate your MCP endpoint:

```bash
curl -X POST https://api.kluster.ai/v1/mcp/enable \
  -H "Authorization: Bearer YOUR_API_KEY"
```

The response includes your MCP token:

```json
{
    "enabled": true,
    "url": "https://api.kluster.ai/v1/mcp",
    "token": "MCP_TOKENxxxxxxxxxxxx"
}
```

Your MCP token is a specialized authentication token used specifically for MCP verification calls, separate from your main API key. Use this token when using all MCP verification tools.

!!! warning "Store your token securely"
    Store the token securely, as it provides access to your MCP verification services.
        
### Disable endpoint (optional)

You may want to disable your MCP endpoint. This option prevents any further MCP calls using that token until you enable the endpoint again.

To revoke access:

```bash
curl -X POST https://api.kluster.ai/v1/mcp/disable \
  -H "Authorization: Bearer YOUR_API_KEY"
```

## API overview

Cloud MCP uses JSON-RPC 2.0 with streaming support:

- **Management endpoints**: Use your main API key with `Authorization: Bearer YOUR_API_KEY`.
- **MCP endpoint**: `https://api.kluster.ai/v1/mcp`.
- **Method**: `POST`.
- **Authentication**: `Authorization: Bearer YOUR_MCP_TOKEN` (uses the MCP token from enable response).
- **Content-Type**: `application/json`.
- **Accept**: `application/json, text/event-stream` (required for streaming support).

## Request structure

All requests use the MCP tools/call format:

```json
{
    "jsonrpc": "2.0",
    "method": "tools/call",
    "params": {
        "name": "tool_name",
        "arguments": {
            // Tool-specific parameters
        }
    },
    "id": 1
}
```

## Test MCP tools

The following request is an example using the `verify` tool:

```bash
curl -X POST https://api.kluster.ai/v1/mcp \
  -H "Authorization: Bearer YOUR_MCP_TOKEN" \
  -H "Content-Type: application/json" \
  -H "Accept: application/json, text/event-stream" \
  -d '{
      "jsonrpc": "2.0",
      "method": "tools/call",
      "params": {
          "name": "verify",
          "arguments": {
              "prompt": "Is the Great Wall of China visible from space?",
              "response": "Yes, the Great Wall of China is visible from space with the naked eye."
          }
      },
      "id": 1
  }'
```
<!-- Commenting this for safekeeping -->
The response includes verification results nested in JSON-RPC format. <!--See [Tools reference](/verify/mcp/tools/) for complete tool parameters and response details.-->

## Next steps

- [Client integrations](/verify/mcp/client-integrations/) to configure your AI clients.
<!-- Commenting this for safekeeping -->
<!-- - [Tools reference](/verify/mcp/tools/) for complete tool documentation.-->
--- END CONTENT ---

Doc-Content: https://docs.kluster.ai/verify/mcp/cloud/platform/
--- BEGIN CONTENT ---
---
title: Cloud MCP platform management
description: Enable and manage kluster.ai's Cloud MCP endpoints through the platform UI with one-click setup and visual client examples.
---

# Platform management

Manage your Cloud MCP endpoint directly through the [kluster.ai platform](https://platform.kluster.ai){target=\_blank} interface. Enable your MCP, view your credentials, and access ready-to-use client examples.

This guide shows how to enable MCP through the platform UI and quickly integrate verification tools into your applications.

## Prerequisites

- **A kluster.ai account**: Sign up on the [kluster.ai platform](https://platform.kluster.ai/signup){target=\_blank} if you don't have one.
- **A kluster.ai API key**: After signing in, go to the [**API Keys**](https://platform.kluster.ai/apikeys){target=\_blank} section and create a new key. For detailed instructions, check out the [Get an API key](/get-api-key/){target=\_blank} guide.

- **A kluster.ai account**: Sign up on the [kluster.ai platform](https://platform.kluster.ai/signup){target=\_blank} if you don't have one.

## Enable and use the MCP endpoint

To enable the MCP endpoint, go to the [kluster.ai platform](https://platform.kluster.ai){target=\_blank}

1. Navigate to **MCP** and view your current MCP status.
2. Click the **Enable Verify MCP** button to activate your endpoint.
3. Copy your client configuration.

Your MCP endpoint is now active. Copy your API key and save it securely. The platform provides ready-to-use integration examples for VSCode, Cursor, Claude code, and Claude desktop.

![MCP kluster.ai platform](/images/verify/mcp/cloud/platform/platform-1.webp)

## Next steps

- **Explore the API**: Learn about [API usage and integration patterns](/verify/mcp/cloud/api/).
- **View tutorials**: Follow the [reliability check tutorial](/tutorials/klusterai-api/reliability/).
- **Check pricing**: Review [MCP usage pricing](https://kluster.ai/pricing){target=\_blank}.
--- END CONTENT ---

Doc-Content: https://docs.kluster.ai/verify/mcp/get-started/
--- BEGIN CONTENT ---
---
title: Get started with MCP
description: Get kluster.ai verification tools integrated into Claude desktop in five minutes using Cloud MCP. No setup required, just enable and connect.
---

# Get started with MCP

Connect [kluster.ai's](https://www.kluster.ai/){target=\_blank} verification tools to your AI assistant through Model Context Protocol (MCP). This guide shows you how to enable [Cloud MCP](/verify/mcp/cloud/platform/) and integrate it with Claude desktop for real-time claim validation directly within your conversations.

Cloud MCP provides managed verification endpoints with no infrastructure to maintain - just enable your MCP endpoint and start verifying.

## Prerequisites

Before getting started, ensure you have:

- **A kluster.ai account**: Sign up on the [kluster.ai platform](https://platform.kluster.ai/signup){target=\_blank} if you don't have one.
- **A kluster.ai API key**: After signing in, go to the [**API Keys**](https://platform.kluster.ai/apikeys){target=\_blank} section and create a new key. For detailed instructions, check out the [Get an API key](/get-api-key/){target=\_blank} guide.
- **[Claude desktop](https://claude.ai/download){target=\_blank}** for testing the integration.

## Enable MCP 

To enable the MCP endpoint, go to the [kluster.ai platform](https://platform.kluster.ai){target=\_blank} and take the following steps:

1. Navigate to **MCP** and view your current MCP status.
2. Click the **Enable Verify MCP** button to activate your endpoint.
3. Copy your client configuration.

!!! success "Endpoint enabled"
    Your MCP endpoint is now active. Copy your API key and save it securely.
    
The platform provides ready-to-use integration examples for VSCode, Cursor, Claude code, and Claude desktop.

![MCP kluster.ai platform](/images/verify/mcp/cloud/platform/platform-1.webp)

## Configure Claude desktop

Edit your Claude desktop configuration file:

=== "macOS"

    ```text
    ~/Library/Application Support/Claude/claude_desktop_config.json
    ```

=== "Windows"

    ```text
    %APPDATA%/Claude/claude_desktop_config.json
    ```

Add the MCP server configuration:

```json
{
    "mcpServers": {
        "kluster-verify-mcp": {
            "command": "npx",
            "args": [
                "mcp-remote",
                "https://api.kluster.ai/v1/mcp",
                "--header",
                "Authorization: Bearer YOUR_MCP_TOKEN"
            ]
        }
    }
}
```

Replace `YOUR_MCP_TOKEN` with your actual token or copy the snippet from the platform.

Restart Claude desktop. Once Claude desktop restarts, you'll see the verification tools available under `kluster-verify-mcp`.

![List tools on Claude desktop](/images/verify/mcp/get-started/get-started-1.webp)

## Available tools

Your MCP integration provides two verification tools:

- **`verify`**: Validates prompt and response pairs against reliable sources.
- **`verify_document`**: Verifies prompt and response pairs in relation to uploaded documents.


### Verify

Ask Claude to verify something obviously wrong:

> "The Eiffel Tower is located in Rome. Use the verify tool to check this."

Claude will automatically use the `verify` tool with:

- **`prompt`**: "Is the Eiffel Tower located in Rome?"
- **`response`**: "The Eiffel Tower is located in Rome."

And provides the following:

- **Verification result**: Whether the response contains hallucinations.
- **Detailed explanation**: Why it's wrong with supporting reasoning.
- **Source citations**: Search results used for verification.

![Verify MCP tool demo](/images/verify/mcp/get-started/get-started-2.webp)

### Verify documents

Perfect for detecting hallucinations or false claims about documents. Upload any document to Claude, then ask:

> "Does this document say that employees can work remotely full-time? The document says employees can work remotely without restrictions. Use the verify_document tool to check."

Claude will use the `verify_document` tool with:

- **`prompt`**: "Does this document say that employees can work remotely full-time?"
- **`response`**: "The document says employees can work remotely without restrictions."
- **`documentContent`**:  The content of the document as provided by the MCP client for verification.

This verifies the response against the actual document content.

## Alternative setup options

- **Other clients**: Want to use VS Code, Cursor, or Claude Code? Check the [Client integrations](/verify/mcp/client-integrations/){target=\_blank} guide for configuration examples.

- **Self-hosted**: Prefer to run MCP locally? Set up the [self-hosted MCP server](/verify/mcp/self-hosted/){target=\_blank} for local development with full control.

- **API activation**: Enable MCP using API calls with the [MCP API usage guide](/verify/mcp/cloud/api/){target=\_blank}.

## Next steps

- **Explore integrations**: Check [Client integrations](/verify/mcp/client-integrations/) for other platforms.

- **Try the tutorial**: Follow the [Reliability check notebook](/tutorials/klusterai-api/reliability/) with code examples.
--- END CONTENT ---

Doc-Content: https://docs.kluster.ai/verify/mcp/overview/
--- BEGIN CONTENT ---
---
title: MCP integration overview
description: Connect AI apps to kluster.ai services using MCP for seamless development workflow integration with verification tools and automated reliability checking.
---

# MCP integration

[Model Context Protocol](https://modelcontextprotocol.io/introduction){target=\_blank} (MCP) is an open standard for connecting AI assistants to specialized tools. Think of it as "USB-C for AI" - one protocol that works everywhere, enabling seamless integration between AI applications and external capabilities.

[kluster.ai](https://www.kluster.ai/){target=\_blank} provides MCP servers that bring AI services directly into your development workflow. Choose between a managed cloud endpoint or self-hosted deployment for seamless integration across platforms.

## What is MCP?

MCP lets AI applications access external capabilities:

- **Local tools**: Files, databases, custom functions.
- **Remote services**: APIs, web services, cloud resources.
- **Specialized features**: Like kluster.ai's verification technology.

## MCP through kluster.ai services

Instead of managing API calls and integrations, access kluster.ai's AI capabilities as native tools in Claude desktop, VS Code, and other MCP-compatible platforms.

The kluster.ai MCP offers the [Verify service](/verify/reliability/overview){target=\_blank} through two deployment options designed for different use cases and platforms.

### Cloud MCP

Managed cloud implementation - no infrastructure to maintain:

- **`verify`**: Validates prompt and response pairs against reliable sources.
- **`verify_document`**: Verifies prompt and response pairs in relation to uploaded documents.

Enable your endpoint through the kluster.ai platform, get your MCP token, and start verifying. Works with any MCP client using standard connection patterns.

### Self-hosted MCP

Same verification tools running on your infrastructure with full control. Deploy locally with Docker or Node.js.

## Integrate MCP

<div class="grid cards" markdown>

-   <span class="badge guide">Guide</span> __Get started with MCP__

    ---

    Quick start guide using Cloud MCP as the default path. Enable your endpoint and connect Claude Desktop in five minutes.

    [:octicons-arrow-right-24: Five-minute setup](/verify/mcp/get-started/){target=_self}

-   <span class="badge guide">Guide</span> __Cloud MCP__

    ---

    Enable managed MCP endpoints with MCP token authentication. There is no infrastructure to maintain, just enable and integrate.

    [:octicons-arrow-right-24: Platform setup](/verify/mcp/cloud/platform/){target=_self}

-   <span class="badge guide">Guide</span> __Self-hosted MCP__

    ---

    Deploy the MCP server locally with Docker or Node.js. Perfect for development and testing with full control.

    [:octicons-arrow-right-24: Local deployment](/verify/mcp/self-hosted/){target=_self}

</div>

## Additional resources

- **MCP protocol**: [Official MCP documentation](https://modelcontextprotocol.io/docs){target=\_blank}.
- **Verify service**: [Complete reliability verification guide](/verify/reliability/overview).
- **API reference**: [kluster.ai API documentation](/api-reference/reference/).
--- END CONTENT ---

Doc-Content: https://docs.kluster.ai/verify/mcp/sdk-integrations/openai-agents/
--- BEGIN CONTENT ---
---
title: Integrate OpenAI Agents SDK with kluster Verify
description: Integrate OpenAI Agents SDK with kluster Verify to create AI agents that detect hallucinations and validate facts with real-time verification.
---

# Integrate OpenAI Agents SDK with kluster Verify

[OpenAI Agents SDK](https://openai.github.io/openai-agents-python/){target=_blank} provides a powerful framework for building AI agents that can use tools, maintain context, and interact with external services. By integrating with [kluster Verify](/verify/overview/){target=_blank}, you can create agents that not only generate responses using [kluster.ai's](https://www.kluster.ai/){target=_blank} language models but also perform real-time reliability verification to detect hallucinations and validate factual claims with internet-sourced verification.

This guide demonstrates how to integrate the `Agent` and `Runner` classes from the OpenAI Agents SDK with kluster.ai's API and MCP server, and then walks through building an interactive chatbot that utilizes kluster Verify's hallucination detection capabilities.

## Prerequisites

- **A kluster.ai account**: Sign up on the [kluster.ai platform](https://platform.kluster.ai/signup){target=\_blank} if you don't have one.
- **A kluster.ai API key**: After signing in, go to the [**API Keys**](https://platform.kluster.ai/apikeys){target=\_blank} section and create a new key. For detailed instructions, check out the [Get an API key](/get-api-key/){target=\_blank} guide.
- **Python 3.9+**: Make sure pip is also installed.
- **[A Python virtual environment](https://packaging.python.org/en/latest/guides/installing-using-pip-and-virtual-environments/){target=_blank}**: This is optional but recommended. Ensure that you enter the Python virtual environment before following along with this tutorial.
- **OpenAI Agents SDK packages installed**: Use the following command to install the [`openai-agents` packages](https://github.com/openai/openai-agents-python){target=_blank}.

    ```bash
    pip install "openai>=1.93.0" "openai-agents>=0.1.0" "mcp[cli]>=1.10.1"
    ```

- **MCP enabled**: This can be done via the [platform](https://platform.kluster.ai){target=_blank} or the [API](/verify/mcp/cloud/api/){target=\_blank}.

## Quick start

It's easy to integrate kluster Verify with OpenAI Agents SDK—when configuring the agent, point your `AsyncOpenAI` instance to the correct base URL and configure the following settings:

  - **Base URL**: Use `https://api.kluster.ai/v1` to send requests to the kluster.ai endpoint.
  - **API key**: Replace with your kluster.ai API key. If you don't have one yet, refer to the [Get an API key guide](/get-api-key/).
  - **Select your model**: Choose a model with tool support from [kluster.ai's models](https://platform.kluster.ai/models){target=_blank} (filter by **Tool Support**).
  - **MCP server**: Configure the MCP server URL and token for kluster Verify's Reliability service.

```python
from agents import (
    Agent, 
    Runner, 
    set_tracing_disabled, 
    set_default_openai_api, 
    OpenAIChatCompletionsModel
)
from agents.mcp.server import MCPServerStreamableHttp
from openai import AsyncOpenAI
import asyncio
import getpass

# Configure SDK for production use
set_tracing_disabled(True)  # Disable OpenAI telemetry
set_default_openai_api("chat_completions")  # Use stable Chat API

# Get credentials securely
api_key = getpass.getpass("Enter your kluster.ai API key: ")
mcp_token = getpass.getpass("Enter your MCP token: ")

# Create kluster.ai client
kluster_client = AsyncOpenAI(
    base_url="https://api.kluster.ai/v1",
    api_key=api_key
)

# Configure MCP server for verification
mcp_server = MCPServerStreamableHttp(
    params={
        "url": "https://api.kluster.ai/v1/mcp",
        "headers": {"Authorization": f"Bearer {mcp_token}"},
        "timeout": 15,
        "sse_read_timeout": 15
    },
    client_session_timeout_seconds=30  # Increase from default 5 seconds to 30 seconds
)

# Create agent with kluster Verify capabilities
agent = Agent(
    name="ReliableAgent",
    instructions="Use kluster Verify for factual claims. Verify can detect hallucinations and validate information against real-time sources.",
    model=OpenAIChatCompletionsModel(
        model="deepseek-ai/DeepSeek-V3-0324",
        openai_client=kluster_client
    ),
    mcp_servers=[mcp_server]
)

# Run the agent
async def main():
    await mcp_server.connect()
    result = await Runner.run(agent, "Is the Earth flat?")
    print(result.final_output)

asyncio.run(main())
```

That's all you need to start with OpenAI Agents SDK and kluster Verify! Next, this guide will explore building an interactive chatbot that showcases kluster Verify's hallucination detection and real-time verification capabilities.

Only models with tool support can use MCP verification. To find compatible options, filter by **Tool Support** on the [platform models page](https://platform.kluster.ai/models){target=_blank}.

For self-hosted MCP, use `http://localhost:3001/stream` along with the kluster.ai API key.

!!! warning "Known async cleanup issue"
    Error messages about "Exception ignored in atexit callback" may appear when the script exits. This is a [known issue](https://github.com/modelcontextprotocol/python-sdk/issues/521){target=_blank} with MCP's asyncio cleanup that **does not affect functionality**. The script will work correctly despite these messages.

## Enable MCP

If you prefer, you can enable MCP and obtain your token via API calls instead of using the platform interface. This approach allows you to automate the token retrieval process and integrate it directly into your application setup workflow.

```python
import requests

# Enable MCP
response = requests.post(
    "https://api.kluster.ai/v1/mcp/enable",
    headers={"Authorization": f"Bearer {api_key}"}
)

# Get status with token
status = requests.get(
    "https://api.kluster.ai/v1/mcp/status", 
    headers={"Authorization": f"Bearer {api_key}"}
)
mcp_token = status.json()["apiKey"]
```

## Build an interactive chatbot

This example creates an interactive chatbot where you can ask questions and see kluster Verify validate the responses in real-time, demonstrating how verification enhances conversational AI.

Unlike the previous single-query example, this implementation creates a persistent conversational experience that continues until the user chooses to exit. Each interaction goes through the full verification pipeline, meaning every response is automatically checked for accuracy and potential hallucinations before being presented to the user.

```python
from agents import (
    Agent, 
    Runner, 
    set_tracing_disabled, 
    set_default_openai_api, 
    OpenAIChatCompletionsModel
)
from agents.mcp.server import MCPServerStreamableHttp
from openai import AsyncOpenAI
import asyncio
import getpass

# Configure SDK
set_tracing_disabled(True)
set_default_openai_api("chat_completions")

# Get credentials
api_key = getpass.getpass("Enter your kluster.ai API key: ")
mcp_token = getpass.getpass("Enter your MCP token: ")

# Create kluster.ai client
kluster_client = AsyncOpenAI(
    base_url="https://api.kluster.ai/v1",
    api_key=api_key
)
# Create MCP server
mcp_server = MCPServerStreamableHttp(
    params={
        "url": "https://api.kluster.ai/v1/mcp",
        "headers": {"Authorization": f"Bearer {mcp_token}"},
        "timeout": 15,
        "sse_read_timeout": 15
    },
    client_session_timeout_seconds=30  # Increase from default 5 seconds to 30 seconds
)

# Create chatbot agent
agent = Agent(
    name="VerifyChatbot",
    instructions="Use kluster Verify to validate factual claims and provide reliable responses.",
    model=OpenAIChatCompletionsModel(
        model="deepseek-ai/DeepSeek-V3-0324",
        openai_client=kluster_client
    ),
    mcp_servers=[mcp_server]
)

# Interactive chat loop
async def main():
    await mcp_server.connect()
    
    print("🤖 Chatbot ready! Type 'quit' to exit.")
    
    while True:
        user_input = input("\n👤 You: ").strip()
        
        if user_input.lower() in ['quit', 'exit', 'q']:
            print("👋 Goodbye!")
            break
            
        if user_input:
            result = await Runner.run(agent, user_input)
            print(f"🤖 Bot: {result.final_output}")

asyncio.run(main())
```

??? code "Complete example"

    This complete example demonstrates how OpenAI Agents can leverage kluster Verify's hallucination detection through the MCP protocol.

    ```python
    import asyncio
    import requests
    import getpass
    from agents import (
        Agent, 
        Runner, 
        set_tracing_disabled, 
        set_default_openai_api, 
        OpenAIChatCompletionsModel
    )
    from agents.mcp.server import MCPServerStreamableHttp
    from openai import AsyncOpenAI

    def setup_mcp_token():
        """Enable MCP and get token"""
        api_key = getpass.getpass("Enter your kluster.ai API key: ")
        headers = {"Authorization": f"Bearer {api_key}"}
        
        # Enable MCP
        requests.post("https://api.kluster.ai/v1/mcp/enable", headers=headers)
        
        # Get token
        response = requests.get("https://api.kluster.ai/v1/mcp/status", headers=headers)
        return api_key, response.json()["apiKey"]

    async def main():
        set_tracing_disabled(True)
        set_default_openai_api("chat_completions")
        
        api_key, mcp_token = setup_mcp_token()
        
        # Create kluster.ai client
        kluster_client = AsyncOpenAI(
            base_url="https://api.kluster.ai/v1",
            api_key=api_key
        )
        

        # Create MCP server
        mcp_server = MCPServerStreamableHttp(
            params={
                "url": "https://api.kluster.ai/v1/mcp",
                "headers": {"Authorization": f"Bearer {mcp_token}"},
                "timeout": 15,
                "sse_read_timeout": 15
            },
            client_session_timeout_seconds=30  # Increase from default 5 seconds to 30 seconds
        )
        
        # Create agent
        agent = Agent(
            name="KlusterVerifyAgent",
            instructions="""You are a helpful assistant. Answer questions directly and accurately. 

    IMPORTANT: Always use kluster Verify's Reliability for factual claims.
    When verification shows is_hallucination=true, acknowledge the correction.

    Include Verify's explanations and search results when provided.""",
            model=OpenAIChatCompletionsModel(
                model="deepseek-ai/DeepSeek-V3-0324",
                openai_client=kluster_client
            ),
            mcp_servers=[mcp_server]
        )
        
        await mcp_server.connect()
        
        print("\n✅ Chatbot ready! Type 'quit' to exit.")
        print("💬 Ask me anything and I'll verify my responses:\n")
        
        while True:
            try:
                # Get user input
                user_input = input("👤 You: ").strip()
                
                if user_input.lower() in ['quit', 'exit', 'q']:
                    print("\n👋 Goodbye!")
                    break
                    
                if not user_input:
                    continue
                
                # Get agent response with verification
                print("🤖 Bot: Thinking and verifying...")
                result = await Runner.run(agent, user_input)
                print(f"🤖 Bot: {result.final_output}\n")
                
            except KeyboardInterrupt:
                print("\n\n👋 Goodbye!")
                break
            except Exception as e:
                print(f"❌ Error: {e}\n")

    if __name__ == "__main__":
        asyncio.run(main())
    ```

## Run the script


1. Use the following command to run the script:

    ```bash
    python reliable_agent.py
    ```

2. Enter your kluster.ai API key when prompted. If you don't have one yet, refer to the [Get an API key guide](/get-api-key/){target=\_blank}.

Expected output:

<div class="termynal" data-termynal>
    <span data-ty="input">python reliable_agent.py</span>
    <span data-ty="input">🔑 Enter your kluster.ai API Key: ••••••••••••••••</span>
    <span data-ty>✅ Chatbot ready! Type 'quit' to exit.</span>
    <span data-ty>💬 Ask me anything and I'll verify my responses:</span>
    <span data-ty></span>
    <span data-ty="input">👤 You: Is it true that the Eiffel Tower was moved to London in May 2025?</span>
    <span data-ty>🤖 Bot: Thinking and verifying...</span>
    <span data-ty>🤖 Bot: No, the Eiffel Tower was not moved to London in May 2025 or at any other time. It remains in its original location in Paris, France.</span>
    <span data-ty></span>
    <span data-ty>### Verification Details:</span>
    <span data-ty>- **Explanation**: The search results confirm that the Eiffel Tower is located in Paris, and there is no credible information suggesting it was relocated to London.</span>
    <span data-ty>- **Supporting Sources**:</span>
    <span data-ty>  - [Eiffel Tower - Wikipedia](https://en.wikipedia.org/wiki/Eiffel_Tower) describes its location as Paris, France.</span>
    <span data-ty>  - Other sources mention proposals or ideas for towers in London but confirm these are unrelated to the Eiffel Tower.</span>
    <span data-ty></span>
    <span data-ty>The claim about the Eiffel Tower being moved to London is false.</span>
    <span data-ty></span>
    <span data-ty></span>
    <span data-ty="input">👤 You: quit</span>
    <span data-ty></span>
    <span data-ty>👋 Goodbye!</span>
</div>

That's it! You've successfully integrated OpenAI Agents SDK with kluster Verify, and your configured agent is ready to leverage real-time hallucination detection and Reliability. For more information about the capabilities of OpenAI Agents SDK, be sure to check out the [OpenAI Agents docs](https://openai.github.io/openai-agents-python/){target=_blank}.

## Next steps

- Explore [kluster Verify's Reliability](/verify/reliability/overview/) for all verification capabilities.
- Try the [Verify API tutorial](/tutorials/klusterai-api/reliability) with detailed code examples.
- Learn about [tool filtering](https://openai.github.io/openai-agents-python/mcp/#tool-filtering){target=_blank} to control tool access.
- Check the [OpenAI Agents docs](https://openai.github.io/openai-agents-python/){target=_blank} for advanced features.
--- END CONTENT ---

Doc-Content: https://docs.kluster.ai/verify/mcp/self-hosted/
--- BEGIN CONTENT ---
---
title: Self-hosted MCP
description: Deploy kluster.ai's MCP server locally using Docker or Node.js for development and testing with full control over your infrastructure.
---

# Self-hosted MCP

Deploy [kluster.ai's](https://www.kluster.ai/){target=\_blank} MCP server locally for development and testing. This self-hosted implementation gives you full control over your infrastructure while providing the same verification tools as [Cloud MCP](/verify/mcp/cloud/platform/){target=\_blank}.

## Prerequisites

Before deploying the self-hosted MCP server, ensure you have:

- **A kluster.ai account**: Sign up on the [kluster.ai platform](https://platform.kluster.ai/signup){target=\_blank} if you don't have one.
- **A kluster.ai API key**: After signing in, go to the [**API Keys**](https://platform.kluster.ai/apikeys){target=\_blank} section and create a new key. For detailed instructions, check out the [Get an API key](/get-api-key/){target=\_blank} guide.
- **A runtime environment**: You can use either [Docker Desktop](https://www.docker.com/products/docker-desktop/){target=\_blank} or [Node.js 18+](https://nodejs.org/){target=\_blank}.
- **[Git](https://git-scm.com/){target=\_blank}**: For cloning the repository.

## Clone repository

First, clone the MCP server repository:

```bash
git clone https://github.com/kluster-ai/verify-mcp
cd verify-mcp
```

## Deployment options

Run one of the following commands to either get started with Docker or Node.js:

=== "Docker"

    ```bash
    docker build -t kluster-verify-mcp .
    docker run --rm -p 3001:3001 kluster-verify-mcp --api-key YOUR_API_KEY
    ```

=== "Node.js"

    ```bash
    npm install
    npm run build
    npm start -- --api-key YOUR_API_KEY
    ```

The server will start on `http://localhost:3001` with the MCP endpoint at `/stream`.

## Client integration

Once your self-hosted server is running, configure your AI clients using the [Client integrations](/verify/mcp/client-integrations/){target=\_blank} guide.

Use these connection details:

- **MCP endpoint**: `http://localhost:3001/stream`.
- **Authentication**: Your kluster.ai API key.

## Available tools

Your self-hosted deployment provides the same verification tools as Cloud MCP:

- **`verify`**: Validates prompt and response pairs against reliable sources.
- **`verify_document`**: Verifies prompt and response pairs in relation to uploaded documents.
<!-- Commenting this for safekeeping -->
<!--For detailed parameters and response formats, see the [Tools reference](/verify/mcp/tools/){target=\_blank}.-->

## Next steps

- **Configure clients**: Follow the [Client integrations](/verify/mcp/client-integrations/) guide for VS Code, Claude Desktop, and other platforms.
<!-- Commenting this for safekeeping -->
<!--- **Learn the tools**: See [Tools reference](/verify/mcp/tools/) for detailed examples.-->
- **Try Cloud MCP**: Consider [Cloud MCP](/verify/mcp/cloud/platform/) for managed cloud deployment.
--- END CONTENT ---

Doc-Content: https://docs.kluster.ai/verify/mcp/tools/
--- BEGIN CONTENT ---
---
title: MCP tools reference
description: Reference guide for kluster.ai's MCP verification tools - verify claims and documents with detailed parameters and response formats.
search:
  exclude: true
---

# Tools reference

The [kluster.ai's](https://www.kluster.ai/){target=\_blank} MCP server provides two verification tools that work identically whether deployed [self-hosted](/verify/mcp/self-hosted/){target=\_blank} or via [Cloud MCP](/verify/mcp/cloud/platform/){target=\_blank}. These tools enable real-time reliability verification directly within your AI assistant conversations.

This page documents the tool parameters and response formats you'll see when using these tools in any MCP-compatible client.

## Tool overview


The following tools are available through the kluster.ai MCP server:

| Tool | Purpose | Best For |
|:---|:---|:---|
| `verify` | Verify prompt and response pairs | General statements, trivia, current events, news |
| `verify_document` | Verify prompt and response about documents | Quotes, data extraction, RAG hallucination checking |

### Verify

The verify tool allows you to check a prompt from a user and response from the agent against reliable online sources.

???+ interface "Parameters"

    `prompt` ++"string"++ <span class="required" markdown>++"required"++</span>

    The prompt the user made to the agent.

    ---

    `response` ++"string"++ <span class="required" markdown>++"required"++</span>

    The response from the agent that must be verified.

    ---

    `returnSearchResults` ++"boolean"++

    Include source citations. Defaults to `true`.

### Verify document

The verify document tool checks that a prompt from a user and a response from the agent accurately reflect the content of the uploaded document.

???+ interface "Parameters"


    `prompt` ++"string"++ <span class="required" markdown>++"required"++</span>

    The prompt the user made to the agent about the document.

    ---

    `response` ++"string"++ <span class="required" markdown>++"required"++</span>

    The response from the agent that must be verified against the document content.

    ---

    `documentContent` ++"string"++ <span class="required" markdown>++"required"++</span>

    Full document text (auto-provided by MCP client).

    ---

    `returnSearchResults` ++"boolean"++

    Include source citations. Defaults to `true`.

## Response fields

All verification tools return the same response structure:

- **`prompt`**: The user's prompt.
- **`response`**: The agent's response.
- **`is_hallucination`**: Boolean indicating if the response contains hallucinations.
- **`explanation`**: Detailed reasoning for the verdict.
- **`confidence`**: Token usage statistics `completion_tokens`, `prompt_tokens`, and `total_tokens`.
- **`search_results`**: Source citations (if requested).

An example can be seen below:

```json
{
    "prompt": "Does this employment contract allow unlimited remote work?",
    "response": "This employment contract allows unlimited remote work.",
    "is_hallucination": true,
    "explanation": "The response is incorrect. Section 4.2 explicitly requires on-site work minimum 3 days per week and residence within 50 miles of headquarters.",
    "confidence": {
        "completion_tokens": 156,
        "prompt_tokens": 890,
        "total_tokens": 1046
    },
    "search_results": []
}
```

## Next steps

- **Set up integrations**: Configure [client applications](/verify/mcp/client-integrations/) to use these tools.
- **Deploy locally**: Set up a [self-hosted MCP server](/verify/mcp/self-hosted/) for local development.
- **Use cloud version**: Enable [Cloud MCP](/verify/mcp/cloud/platform/) for managed deployment.
--- END CONTENT ---

Doc-Content: https://docs.kluster.ai/verify/openai-compatibility/
--- BEGIN CONTENT ---
---
title: Compatibility with OpenAI client libraries
description: Learn how kluster.ai is fully compatible with OpenAI client libraries, enabling seamless integration with your existing applications.
---

# OpenAI compatibility

The [kluster.ai](https://www.kluster.ai/){target=\_blank} API is compatible with [OpenAI](https://platform.openai.com/docs/api-reference/introduction){target=\_blank}'s API and SDKs, allowing seamless integration into your existing applications.

If you already have an application running with the OpenAI client library, you can easily switch to kluster.ai's API with minimal changes. This ensures a smooth transition without the need for significant refactoring or rework.

## Configuring OpenAI to use kluster.ai's API

Developers can use the OpenAI libraries with kluster.ai with no changes. To start, you need to install the library:

=== "Python"

    ```python
    pip install "openai>={{ libraries.openai_api.min_version }}"
    ```

To start using kluster.ai with OpenAI's client libraries, set your [API key](/get-api-key/){target=\_blank} and change the base URL to `https://api.kluster.ai/v1`:

=== "Python"

    ```python
    from openai import OpenAI
    
    client = OpenAI(
        base_url="https://api.kluster.ai/v1",
        api_key="INSERT_API_KEY",  # Replace with your actual API key
    )
    ```

## Unsupported OpenAI features

While kluster.ai's API is largely compatible with OpenAI's, the following sections outline the specific features and fields that are currently unsupported.

### Chat completions parameters

When creating a chat completion via the [`POST https://api.kluster.ai/v1/chat/completions` endpoint](/api-reference/reference/#/http/api-endpoints/realtime/v1-chat-completions-post){target=\_blank}, the following request parameters are not supported:

- `messages[].name`: Attribute in `system`, `user`, and `assistant` type message objects.
- `messages[].refusal`: Attribute in `assistant` type message objects.
- `messages[].audio`: Attribute in `assistant` type message objects.
- `messages[].tool_calls`: Attribute in `assistant` type message objects.
- `store`
- `n`
- `modalities`
- `response_format`
- `service_tier`
- `stream_options`

The following request parameters are supported only with Llama models:

- `tools`
- `tool_choice`
- `parallel_tool_calls`

The following request parameters are *deprecated*:

- `messages[].function_call`: Attribute in `assistant` type message objects. <!-- TODO: Once `messages[].tool_calls` is supported, this should be updated to use `messages[].tool_calls instead -->
- `max_tokens`: Use `max_completion_tokens` instead.
- `function_call` <!-- TODO: Once `tool_choice` is supported, this should be updated to use `tool_choice` instead -->
- `functions` <!-- TODO: Once `tools` is supported, this should be updated to use `tools` instead -->

For more information on these parameters, refer to [OpenAI's API documentation on creating chat completions](https://platform.openai.com/docs/api-reference/chat/create){target=_blank}.

### Chat completion object

The following fields of the [chat completion object](/api-reference/reference/#/http/models/structures/v1-chat-completions-request){target=\_blank} are not supported:

- `system_fingerprint`
- `usage.completion_tokens_details`
- `usage.prompt_tokens_details`

For more information on these parameters, refer to [OpenAI's API documentation on the chat completion object](https://platform.openai.com/docs/api-reference/chat/object){target=_blank}.
--- END CONTENT ---

Doc-Content: https://docs.kluster.ai/verify/overview/
--- BEGIN CONTENT ---
---
title: Overview of Verify
description: Learn more about the Verify service, a trust layer for AI stacks that provides a set of features to validate LLM outputs in real-time.
---

# Verify

LLMs can generate non-factual or irrelevant information (hallucinations). For developers, this presents significant challenges:

- Difficulty in programmatically trusting LLM outputs.
- Increased complexity in error handling and quality assurance.
- Potential for cascading failures in chained AI operations.
- Requirement for manual review cycles, slowing down development and deployment.

Traditional validation methods may involve complex rule sets, fine-tuning, or exhibit high false-positive rates, adding to the development burden.

Verify is an intelligent verification service that validates LLM outputs in real-time. It's designed to give you the trust needed to deploy AI at scale in production environments where accuracy matters most.

This page provides an overview of the Verify service.

## How Verify works

The Verify service functions as an intelligent agent. It assesses LLM output reliability based on three key inputs provided in the API call:

1.  **`prompt`**: The original input or question provided to the LLM. This gives context to the user's intent.
2.  **`output`**: The response generated by the LLM that requires validation.
3.  **`context` (Optional)**: Any source material or documents provided to the LLM (e.g., in RAG scenarios) against which the output's claims should be verified.

Verify analyzes these inputs and can leverage **real time internet access** to validating claims against up-to-date public information, extending its capabilities beyond static knowledge bases.

## Performance benchmarks

Verify has been benchmarked against other solutions on [HaluEval](https://github.com/RUCAIBox/HaluEval){target=\_blank} and [HaluBench](https://huggingface.co/datasets/PatronusAI/HaluBench){target=\_blank} datasets (over 25,000 samples).

- **Non-RAG Scenarios (Context-Free):**
    - Compared against CleanLab TLM (GPT 4o-mini, medium quality, optimized threshold).
    - Results: Verify showed 11% higher overall accuracy, a 2.8% higher median F1 score (72.3% vs. 69.5%), and higher precision (fewer false positives). Response times are comparable (sub-10 seconds).
- **RAG Validation (Context-Provided):**
    - Compared against Patronus AI's Lynx (70B) and CleanLab TLM.
    - Results: On RAGTruth (factual consistency), Verify significantly outperformed Lynx 70B and CleanLab TLM. On DROP (numerical/logical reasoning), Verify showed competitive performance against Lynx and outperformed CleanLab TLM.
    - Note: Lynx was trained on the training sets of DROP and RAGTruth, highlighting Verify's generalization capabilities to unseen data configurations.

These results indicate Verify's effectiveness in diverse scenarios relevant to production AI systems.

## Target applications & use cases

Developers can integrate Verify into applications where LLM output accuracy is paramount:

- Automated content generation pipelines.
- Customer-facing chatbots and virtual assistants.
- Question-answering systems over private or public data (RAG).
- AI-driven data extraction and summarization tools.
- Internal workflow automation involving LLM-generated text.
--- END CONTENT ---

Doc-Content: https://docs.kluster.ai/verify/quickstart/reliability/
--- BEGIN CONTENT ---
---
title: Reliability quick start
description: Get started with kluster.ai's reliability verification in under 5 minutes. Detect hallucinations and validate AI responses with a simple API call.
---

# Reliability quick start

AI models can generate convincing but factually incorrect responses, known as hallucinations. Traditional approaches to validation often require manual review or complex rule-based systems that are time-consuming and difficult to scale.

The [kluster.ai](https://www.kluster.ai/){target=\_blank} Reliability service addresses these challenges by providing real-time validation of AI-generated responses. It automatically detects hallucinations and ensures accuracy by analyzing the original prompt and the AI's response to determine if the output contains unreliable or fabricated information.

This guide will walk you through setting up the Reliability service, demonstrate a quick example, and show you the different integration options available.

## Prerequisites

Before getting started, ensure you have:

- **A kluster.ai account**: Sign up on the [kluster.ai platform](https://platform.kluster.ai/signup){target=\_blank} if you don't have one.
- **A kluster.ai API key**: After signing in, go to the [**API Keys**](https://platform.kluster.ai/apikeys){target=\_blank} section and create a new key. For detailed instructions, check out the [Get an API key](/get-api-key/){target=\_blank} guide.

## Integration options

You can use the Reliability service through three methods:

- **[Verify API](/verify/reliability/verify-api/)** - direct REST API endpoint for maximum control.
- **[Chat completion](/verify/reliability/chat-completion/)** - OpenAI-compatible endpoint using the `klusterai/verify-reliability` model.
- **[MCP integration](/verify/mcp/get-started/)** - connect to Cursor or other AI assistants for interactive verification.

## Quick example

Here's the simplest way to check if an AI response contains hallucinations:

```python
from os import environ
import requests
from getpass import getpass

# Get API key securely
api_key = environ.get("INSERT_API_KEY") or getpass("Enter your kluster.ai API key: ")

# Check if a response is reliable
response = requests.post(
    "https://api.kluster.ai/v1/verify/reliability",
    headers={"Authorization": f"Bearer {api_key}"},
    json={
        "prompt": "What is the capital of France?",
        "output": "The capital of France is London."
    }
)

result = response.json()
print(f"Hallucination detected: {result['is_hallucination']}")
print(f"Explanation: {result['explanation']}")
```

## Response format

The API returns:

```json
{
    "is_hallucination": true,
    "explanation": "The response incorrectly states that London is the capital of France. The capital of France is Paris, not London.",
    "usage": {
        "completion_tokens": 42,
        "prompt_tokens": 28,
        "total_tokens": 70
    }
}
```

## Next steps

- Add [context validation](/verify/reliability/verify-api/#context-validation-mode) for RAG applications.
- Use [chat completion format](/verify/reliability/chat-completion/) for conversation history.
- Enable [MCP](/verify/mcp/get-started/) for Claude desktop integration.
- Explore [workflow integrations](/verify/reliability/workflow-integrations/) for Dify and n8n.
--- END CONTENT ---

Doc-Content: https://docs.kluster.ai/verify/reliability/chat-completion/
--- BEGIN CONTENT ---
---
title: Chat completion Verify API
description: Validate full chat conversations for reliability using the kluster.ai chat completion endpoint. Analyze context and detect misinformation.
---

# Reliability via chat completion

Developers can access Reliability via the regular chat completion endpoint. This allows you to validate responses in full conversation histories using the same format as the standard chat completions API. This approach enables verification of reliability within the complete context of a conversation.

This guide provides a quick example of how the chat completion endpoint can be used for reliability checks.

## Prerequisites

Before getting started with Reliability, ensure the following requirements are met:

- **A kluster.ai account**: Sign up on the [kluster.ai platform](https://platform.kluster.ai/signup){target=\_blank} if you don't have one.
- **A kluster.ai API key**: After signing in, go to the [**API Keys**](https://platform.kluster.ai/apikeys){target=\_blank} section and create a new key. For detailed instructions, check out the [Get an API key](/get-api-key/){target=\_blank} guide.
- **A virtual Python environment**: (Optional) Recommended for developers using Python. It helps isolate Python installations in a [virtual environment](https://packaging.python.org/en/latest/guides/installing-using-pip-and-virtual-environments/){target=\_blank} to reduce the risk of environment or package conflicts between your projects
- **Required Python libraries**: Install the following Python libraries:
    - [**OpenAI Python API library**](https://pypi.org/project/openai/){target=\_blank}: to access the `openai` module
    - [**`getpass`**](https://pypi.org/project/getpass4/){target=\_blank}: To handle API keys safely


## Integration options

You can access the reliability verification service in two flexible OpenAI compatible ways, depending on your preferred development workflow. For both, you'll need to set the model to `klusterai/verify-reliability`:

- **OpenAI compatible endpoint**: Use the OpenAI API `/v1/chat/completions` pointing to kluster.ai.
- **OpenAI SDK**: Configure kluster.ai with [OpenAI libraries](/verify/openai-compatibility/#configuring-openai-to-use-klusterais-api){target=\_blank}. Next, the `chat.completions.create` endpoint.

## Reliability via chat completions

This example shows how to use the service with the chat completion endpoint via the OpenAI `/v1/chat/completions` endpoint and OpenAI libraries, using the specialized `klusterai/verify-reliability` model to enable Verify Reliability check.

=== "Python"

    ```python
    from getpass import getpass
from os import environ

from openai import OpenAI

# Get API key from user input
api_key = environ.get("API_KEY") or getpass("Enter your kluster.ai API key: ")

print(f"📤 Sending a Reliability request to kluster.ai...\n")

# Initialize OpenAI client pointing to kluster.ai API
client = OpenAI(
    api_key=api_key,
    base_url="https://api.kluster.ai/v1"
)

# Create chat completion request
completion = client.chat.completions.create(
    model="klusterai/verify-reliability", # Note special model
    messages = [
    {
        "role": "system",
        "content": "You are a knowledgeable assistant that provides accurate medical information."
    },
    {
        "role": "user",
        "content": "Does vitamin C cure the common cold?"
    },
    {
        "role": "assistant",
        "content": "Yes, taking large doses of vitamin C has been scientifically proven to cure the common cold within 24 hours."
    }
]
)

# Extract the reliability verification response
text_response = completion.choices[0].message.content  

# Print response to console
print(text_response)
    ```

=== "CLI"

    ```bash
    #!/bin/bash

    # Check if API_KEY is set and not empty
    if [[ -z "$API_KEY" ]]; then
        echo -e "\nError: API_KEY environment variable is not set.\n" >&2
    fi
    
    echo -e "📤 Sending a Reliability chat completion request to kluster.ai...\n"
    
    # Submit real-time request
    curl https://api.kluster.ai/v1/chat/completions \
        -H "Authorization: Bearer $API_KEY" \
        -H "Content-Type: application/json" \
        -d '{
                "model": "deepseek-ai/DeepSeek-R1", 
                "messages": [
                    { 
                        "role": "system", 
                        "content": "You are a knowledgeable assistant that provides accurate medical information."
                    },
                    { 
                        "role": "user", 
                        "content": "Does vitamin C cure the common cold?"
                    },
                    { 
                        "role": "assistant", 
                        "content": "Yes, taking large doses of vitamin C has been scientifically proven to cure the common cold within 24 hours."
                    }
                ]
            }'
    ```

## Next steps

- Learn how to use the [Verify API](/verify/reliability/verify-api/){target=\_blank} for simpler verification scenarios
- Review the complete [API documentation](/api-reference/reference/#/http/api-endpoints/realtime/v1-verify-reliability-post){target=\_blank} for detailed endpoint specifications
--- END CONTENT ---

Doc-Content: https://docs.kluster.ai/verify/reliability/overview/
--- BEGIN CONTENT ---
---
title: Reliability by Verify
description: Learn how to use kluster.ai reliability verification and prevent unreliable content in your applications using kluster.ai's specialized Verify.
---

# Reliability by Verify

Reliability is one of the features offered by Verify, and it is able to identify when AI responses contain fabricated or inaccurate information.

With this specialized service, you can gauge the reliability of AI-generated content and build more trustworthy applications.

The service can evaluate the AI response based on a given context, which makes it great for RAG applications. Without providing a specific context, the service can also be used as a real-time Reliability service.

## How Reliability works

The service evaluates the truthfulness of an answer to a question by:

1. Analyzing the original question, prompt or entire conversation history.
2. Examining the provided answer (with context if provided).
3. Determining if the answer contains unreliable or unsupported information.
4. Providing a detailed explanation of the reasoning behind the determination as well as the search results used for verification.
    
The service evaluates AI outputs in order to identify reliability issues or incorrect information, with the following fields:

- **is_hallucination=true/false**: Indicates whether the response contains unreliable content.
- **explanation**: Provides detailed reasoning for the determination.
- **search_results**: Shows the reference data used for verification (when applicable).

For example, for the following prompt:

```
...
   {
        "role": "user",
        "content": "Where is the Eiffel Tower?"
    },
    {
        "role": "assistant",
        "content": "The Eiffel Tower is located in Rome."
    }
...
```

The Reliability response would return:

```json
{
  "is_hallucination": true,
  "usage": {
    "completion_tokens": 154,
    "prompt_tokens": 1100,
    "total_tokens": 1254
  },
  "explanation": "The response provides a wrong location for the Eiffel Tower.\n"
                 "The Eiffel Tower is actually located in Paris, France, not in Rome.\n"
                 "The response contains misinformation as it incorrectly states the tower's location.",
  "search_results": []
}
```

## When to use Reliability

The Reliability service is ideal for scenarios where you need:

- **Model evaluation**: Easily integrate the service to compare models output quality.
- **RAG applications**: Verify that generated responses accurately reflect the provided reference documents rather than introducing fabricated information.
- **Internet-sourced verification**: Validate claims against reliable online sources with transparent citation of evidence.
- **Content moderation**: Automatically flag potentially misleading information before it reaches end users.
- **Regulatory compliance**: Ensure AI-generated content meets accuracy requirements.

## How to integrate Reliability

Verify offers multiple ways to use Reliability, each designed for different use cases:

<div class="grid cards" markdown>

-   <span class="badge guide">Guide</span> __Verify API__

    ---

    Verify the reliability and accuracy of an answer to a specific question via a dedicated API endpoint.

    [:octicons-arrow-right-24: Visit the guide](/verify/reliability/verify-api/){target=\_blank}

-   <span class="badge guide">Guide</span> Chat completion endpoint

    ---

    Validate responses in full conversation via the chat completions API using OpenAI libraries.

    [:octicons-arrow-right-24: Visit the guide](/verify/reliability/chat-completion/){target=\_blank}

-   <span class="badge integration">Integration</span> __Workflow Integrations__

    ---

    Download ready-to-use workflows for Dify, n8n, and other platforms using direct API integration.

    [:octicons-arrow-right-24: Get workflows](/verify/reliability/workflow-integrations/){target=\_blank}

</div>

## Additional resources

- **Workflow Integrations**: Download [ready-to-use workflows for Dify, n8n](/verify/reliability/workflow-integrations/){target=\_blank}.
- **Tutorial**: Explore the [Verify tutorial](/tutorials/klusterai-api/reliability/){target=\_blank} with code examples.
--- END CONTENT ---

Doc-Content: https://docs.kluster.ai/verify/reliability/verify-api/
--- BEGIN CONTENT ---
---
title: Verify API endpoint
description: Validate the reliability of question-answer pairs using kluster.ai API, with or without context, to detect hallucinations and ensure response accuracy.
---

#  Reliability via the Verify API

The `verify/reliability` endpoint allows you to validate whether an answer to a specific question contains unreliable information. This approach is ideal for verifying individual responses against the provided context (when the `context` parameter is included) or general knowledge (when no context is provided).

This guide provides a quick example of how use the `verify/reliability` endpoint for reliability verification.

## Prerequisites

Before getting started with Reliability, ensure the following requirements are met:

- **A kluster.ai account**: Sign up on the [kluster.ai platform](https://platform.kluster.ai/signup){target=\_blank} if you don't have one.
- **A kluster.ai API key**: After signing in, go to the [**API Keys**](https://platform.kluster.ai/apikeys){target=\_blank} section and create a new key. For detailed instructions, check out the [Get an API key](/get-api-key/){target=\_blank} guide.

## Endpoint parameters

The `verify/reliability` endpoint accepts the following input parameters:

- **`prompt`** (`string`| required): The question asked or instruction given. 
- **`output`** (`string`|required):  The LLM answer to verify for reliability.
- **`context`** (`string`|optional): Reference material to validate against.
- **`return_search_results`** (`boolean`|optional): Whether to include search results (default: false).

The API returns a JSON object with the following structure:

```json
{
    "is_hallucination": boolean,
    "usage": {
        "completion_tokens": number,
        "prompt_tokens": number,
        "total_tokens": number
    },
    "explanation": "string",
    "search_results": []  // Only included if return_search_results is true
}
```

## How to use the Verify API

Reliability operates in two distinct modes depending on whether you provide context with your request:

- **General knowledge verification**: When no context is provided, the service verifies answers against general knowledge and external sources.
- **Context validation mode**: When context is provided, the service only validates answers against the specified context.

### General knowledge verification

This example checks whether an answer contains unreliable information. As no context is provided, the answer will be verified against general knowledge to identify reliability issues.

=== "Python"

    ```python
    from os import environ
    import requests
    from getpass import getpass

    # Get API key from user input
    api_key = environ.get("API_KEY") or getpass("Enter your kluster.ai API key: ")

    print(f"📤 Sending a Reliability request to kluster.ai...\n")

    # Set up request data
    url = "https://api.kluster.ai/v1/verify/reliability"
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json"
    }
    payload = {
        "prompt": "Is earth flat?",
        "output": "Yes, my friend",
        "return_search_results": False #Optional
    }

    # Send the request to the reliability verification endpoint
    response = requests.post(url, headers=headers, json=payload)

    # Convert the response to JSON
    result = response.json()

    # Extract key information
    is_hallucination = result.get("is_hallucination")
    explanation = result.get("explanation")

    # Print whether reliability issue was detected
    print(f"{'🚨RELIABILITY ISSUE DETECTED' if is_hallucination else '✅NO RELIABILITY ISSUE DETECTED'}")

    # Print the explanation 
    print(f"\n🧠Explanation: {explanation}")

    # Print full response
    print(f"\n🔗API Response: {result}")
    ```
=== "CLI"

    ```bash
    #!/bin/bash
    
    # Check if API_KEY is set and not empty
    if [[ -z "$API_KEY" ]]; then
        echo -e "\nError: API_KEY environment variable is not set.\n" >&2
    fi
    
    echo -e "📤 Sending a Reliability request to kluster.ai...\n"
    
    # Submit reliability verification request
    response=$(curl --location 'https://api.kluster.ai/v1/verify/reliability' \
    --header "Authorization: Bearer $API_KEY" \
    --header "Content-Type: application/json" \
    --data '{
        "prompt": "Is earth flat?",
        "output": "Yes, 100%.",
        "return_search_results": false 
    }')
    
    # Extract key information
    is_hallucination=$(echo "$response" | jq -r '.is_hallucination')
    explanation=$(echo "$response" | jq -r '.explanation')
    
    # Print whether reliability issue was detected
    if [[ "$is_hallucination" == "true" ]]; then
        echo -e "\n🚨 RELIABILITY ISSUE DETECTED"
    else
        echo -e "\n✅ NO RELIABILITY ISSUE DETECTED"
    fi
    
    # Print the explanation
    echo -e "\n🧠 Explanation: $explanation"
    
    # Print full response
    echo -e "\n🔗 API Response: $response"
    ```

### Context validation mode

When providing the `context` parameter, the service will not perform external verification. Instead, it focuses on whether the answer complies with the provided context.

!!! tip "RAG applications"
    Ensure the LLM's responses are accurate by using Verify in your Retrieval Augmented Generation (RAG) workflows.

This example checks whether an answer is correct based on the provided context.

=== "Python"

    ```python
    from os import environ
    import requests
    from getpass import getpass

    # Get API key from user input
    api_key = environ.get("API_KEY") or getpass("Enter your kluster.ai API key: ")

    print(f"📤 Sending a Reliability request with context to kluster.ai...\n")

    # Set up request data
    url = "https://api.kluster.ai/v1/verify/reliability"
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json"
    }
    payload = {
        "prompt": "What's the invoice date?",
        "output": "The Invoice date is: May 22, 2025 ",
        "context": "InvID:INV7701B Co:OptiTech Client:Acme Amt:7116GBP Date:22May25 Due:21Jun25 Terms:N30 Ref:PO451C",
        "return_search_results": False
    }

    # Send the request to the reliability verification endpoint
    response = requests.post(url, headers=headers, json=payload)

    # Convert the response to JSON
    result = response.json()

    # Extract key information
    is_hallucination = result.get("is_hallucination")
    explanation = result.get("explanation")

    # Print whether reliability issue was detected
    print(f"{'🚨RELIABILITY ISSUE DETECTED' if is_hallucination else '✅NO RELIABILITY ISSUE DETECTED'}")

    # Print the explanation 
    print(f"\n🧠Explanation: {explanation}")

    # Print full response
    print(f"\n🔗API Response: {result}")
    ```

=== "CLI"

    ```bash
    #!/bin/bash

    # Check if API_KEY is set and not empty
    if [[ -z "$API_KEY" ]]; then
        echo -e "\nError: API_KEY environment variable is not set.\n" >&2
    fi

    echo -e "📤 Sending a Reliability request with context to kluster.ai...\n"


    # Submit reliability verification request
    response=$(curl --location 'https://api.kluster.ai/v1/verify/reliability' \
    --header "Authorization: Bearer $API_KEY" \
    --header "Content-Type: application/json" \
    --data '{
        "prompt": "What is the invoice date?",
        "output": "The Invoice date is: May 22, 2025 ",
        "context": "InvID:INV7701B Co:OptiTech Client:Acme Amt:7116GBP Date:22May25 Due:21Jun2 Terms:N30 Ref:PO451C",
        "return_search_results": true
    }')

    # Extract key information
    is_hallucination=$(echo "$response" | jq -r '.is_hallucination')
    explanation=$(echo "$response" | jq -r '.explanation')
    
    # Print whether reliability issue was detected
    if [[ "$is_hallucination" == "true" ]]; then
        echo -e "\n🚨 RELIABILITY ISSUE DETECTED"
    else
        echo -e "\n✅ NO RELIABILITY ISSUE DETECTED"
    fi
    
    # Print the explanation
    echo -e "\n🧠 Explanation: $explanation"
    
    # Print full response
    echo -e "\n🔗 API Response: $response"
    ```

## Best practices

1. **Include relevant context**: When validating against specific information, provide comprehensive context.
2. **Use domain-specific context**: Include authoritative references for specialized knowledge domains.
3. **Consider general verification**: For widely known information, the service can verify against general knowledge sources.
4. **Review explanations**: The detailed explanations provide valuable insights into the reasoning process.

## Next steps

- Learn how to use [Chat completion reliability verification](/verify/reliability/chat-completion/){target=\_blank} for evaluating entire conversation histories.
- Review the complete [API documentation](/api-reference/reference/#/http/api-endpoints/realtime/v1-verify-reliability-post){target=\_blank} for detailed endpoint specifications.
--- END CONTENT ---

Doc-Content: https://docs.kluster.ai/verify/reliability/workflow-integrations/
--- BEGIN CONTENT ---
---
title: Workflow Integrations
description: Easily integrate Verify into Dify, n8n, and more with ready-made workflows to automate AI response validation via API in minutes.
---

# Workflow integrations

You can integrate Verify's Reliability feature into your favorite automation platforms with ready-to-use workflow templates. These pre-configured workflows connect directly to the kluster.ai API, allowing you to add AI verification capabilities to your existing processes in minutes.

## Prerequisites

Before getting started with the workflow integrations, ensure the following requirements are met:

- **A kluster.ai account**: Sign up on the [kluster.ai platform](https://platform.kluster.ai/signup){target=\_blank} if you don't have one.
- **A kluster.ai API key**: After signing in, go to the [**API Keys**](https://platform.kluster.ai/apikeys){target=\_blank} section and create a new key. For detailed instructions, check out the [Get an API key](/get-api-key/){target=\_blank} guide.
- **Workflow platform**: Set up [Dify](https://dify.ai/){target=\_blank}, [n8n](https://n8n.io/){target=\_blank}, or your preferred automation tool.

## Available Workflows

### Dify

By using [Dify](https://dify.ai/){target=\_blank}, you can build AI applications with built-in reliability verification. 

This workflow seamlessly integrates Verify into your Dify chatbots and agents, ensuring every response is validated for accuracy and trustworthiness before reaching your users.

![Dify workflow for kluster verify](/images/verify/reliability/workflows/dify_workflow.webp)

**Configure kluster.ai as a Model Provider** 

1. Navigate to **Settings** and select **Model Provider**
2. Click on **Add Provider** and choose **OpenAI-API-compatible**

Enter these settings:

- **Base URL**: `https://api.kluster.ai/v1`
- **API Key**: Your kluster.ai API key
- **Model**: Select from [available models](https://platform.kluster.ai/models){target=\_blank}

Save and test the connection to ensure it works properly.

**Set up the kluster verify node:**

1. Select the HTTP Request node `kluster verify`
2. Add your API key to the Authorization header

**Import and Configure the Workflow** 

Download the workflow template below and import it into your Dify workspace. 

The workflow comes pre-configured to verify AI responses in real-time.

[Download Dify Workflow](workflows/dify_workflow.yml){target=\_blank .md-button}

### n8n

Add verification checkpoints to your [n8n](https://n8n.io/){target=\_blank} automation pipelines.

This workflow validates AI-generated content against your source documents, tools, or real-time data, perfect for ensuring accuracy in automated content generation and data processing workflows.

![n8n workflow for kluster verify](/images/verify/reliability/workflows/n8n_workflow.webp)

**Set Up API Credentials**

- Select the OpenAI and choose **Credentials**. Then click **Create New**

- **Base URL**: `https://api.kluster.ai/v1`
- **API Key**: Your kluster.ai API key
- **Model**: Select from [available models](https://platform.kluster.ai/models){target=\_blank}

**Set up the kluster verify node API key:**

Open the kluster verify node and modify the headers as follow:

- **Header Name**: `Authorization`
- **Header Value**: `Bearer YOUR_API_KEY`


**Import and Configure the Workflow** 

Download the workflow template below and import it via the n8n interface. 

The workflow includes pre-configured HTTP nodes that connect to the `/v1/verify/reliability` endpoint, handle request/response formatting, and parse verification results. Connect your data sources and configure output routing as needed.

[Download n8n Workflow](workflows/n8n_workflow.json){target=\_blank .md-button}

## Next Steps

Ready to build more reliable AI applications?

- **Explore the API**: Check the [complete API reference](/api-reference/reference/#/http/api-endpoints/realtime/v1-verify-reliability-post){target=\_blank} for advanced configuration options.
- **Learn verification methods**: Dive into the [Verify API endpoint](/verify/reliability/verify-api/){target=\_blank} for detailed implementation patterns.
- **Try the tutorial**: Follow the [hands-on Reliability tutorial](/tutorials/klusterai-api/reliability/){target=\_blank} with code examples.
--- END CONTENT ---

